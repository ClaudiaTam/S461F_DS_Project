{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Augmentation"
      ],
      "metadata": {
        "id": "QYAo84CmbY9R"
      },
      "id": "QYAo84CmbY9R"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import random\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,)),\n",
        "])\n",
        "\n",
        "# Load the MNIST dataset with the transformation\n",
        "dataset = datasets.MNIST('../data', train=True, download=True, transform=transform)\n",
        "\n",
        "# Retrieve an image from the dataset\n",
        "image, label = dataset[0]  # Get the first image and its label\n",
        "\n",
        "# Convert the tensor to a numpy array and remove the batch dimension\n",
        "image = image.squeeze().numpy()\n",
        "\n",
        "# Display the image\n",
        "plt.imshow(image, cmap='gray')\n",
        "plt.title(f'Label: {label}')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "J_3E_Ky6bWax",
        "outputId": "d1bd7307-5f76-4056-db41-6b1afb2b154a"
      },
      "id": "J_3E_Ky6bWax",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGzCAYAAABpdMNsAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAIH5JREFUeJzt3XtwVPX5x/HPEmG5mCwGyI2bBBREbhYhUhFBIkmqjCB2vE6hdbBgcFAqKLYCtrXxig6KyEwtaBVQWwGlDlaBhFoDNFxkqEoJEwpIEhCb3RAkIPn+/mDcnysJcMKGJwnv18x3JnvO99nz5HjMh7Nn96zPOecEAMA51sS6AQDA+YkAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACztKuXbvk8/n0zDPPRO05c3Nz5fP5lJubG7XnBOobAgjnpYULF8rn86mgoMC6lToxa9Ys+Xy+k0bz5s2tWwPCLrBuAEDdmTdvni688MLw45iYGMNugEgEENCI3XLLLWrbtq11G0C1eAkOqMHRo0c1Y8YM9e/fX4FAQK1atdI111yjNWvW1Fjz3HPPqXPnzmrRooWuvfZabdu27aQ5X3zxhW655RbFx8erefPmuvLKK/Xuu++etp/Dhw/riy++0FdffXXGv4NzTqFQSNz0HvURAQTUIBQK6Y9//KOGDh2qJ598UrNmzdKBAweUkZGhLVu2nDT/tdde05w5c5Sdna3p06dr27Ztuu6661RaWhqe8+9//1tXXXWVPv/8cz388MN69tln1apVK40aNUpLly49ZT8bNmzQZZddphdffPGMf4fU1FQFAgHFxsbqrrvuiugFsMZLcEANLrroIu3atUvNmjULLxs/frx69OihF154Qa+88krE/MLCQu3YsUPt27eXJGVmZiotLU1PPvmkZs+eLUmaPHmyOnXqpH/961/y+/2SpHvvvVeDBw/WQw89pNGjR0et90mTJmnQoEHy+/36xz/+oblz52rDhg0qKChQXFxcVLYDnA0CCKhBTExM+KJ9VVWVysrKVFVVpSuvvFKbNm06af6oUaPC4SNJAwcOVFpamt5//33Nnj1bX3/9tVavXq3f/va3Ki8vV3l5eXhuRkaGZs6cqS+//DLiOb5v6NChZ/xS2uTJkyMejxkzRgMHDtSdd96pl156SQ8//PAZPQ9Ql3gJDjiFV199VX369FHz5s3Vpk0btWvXTn/7298UDAZPmnvJJZectOzSSy/Vrl27JJ04Q3LO6dFHH1W7du0ixsyZMyVJ+/fvr7Pf5Y477lBSUpI++uijOtsG4AVnQEANXn/9dY0bN06jRo3S1KlTlZCQoJiYGOXk5Gjnzp2en6+qqkqS9OCDDyojI6PaOd26dTurnk+nY8eO+vrrr+t0G8CZIoCAGvzlL39Ramqq3nnnHfl8vvDy785WfmjHjh0nLfvPf/6jiy++WNKJNwRIUtOmTZWenh79hk/DOaddu3bpiiuuOOfbBqrDS3BADb67/vP96y7r169Xfn5+tfOXLVumL7/8Mvx4w4YNWr9+vbKysiRJCQkJGjp0qObPn6/i4uKT6g8cOHDKfry8Dbu655o3b54OHDigzMzM09YD5wJnQDiv/elPf9LKlStPWj558mTdeOONeueddzR69GjdcMMNKioq0ssvv6yePXvq0KFDJ9V069ZNgwcP1sSJE1VZWannn39ebdq00bRp08Jz5s6dq8GDB6t3794aP368UlNTVVpaqvz8fO3du1effvppjb1u2LBBw4YN08yZMzVr1qxT/l6dO3fWrbfeqt69e6t58+b6+OOPtWTJEvXr10+//OUvz3wHAXWIAMJ5bd68edUuHzdunMaNG6eSkhLNnz9fH3zwgXr27KnXX39db7/9drU3Cf3Zz36mJk2a6Pnnn9f+/fs1cOBAvfjii0pOTg7P6dmzpwoKCvTYY49p4cKFOnjwoBISEnTFFVdoxowZUfu97rzzTn3yySf661//qiNHjqhz586aNm2afv3rX6tly5ZR2w5wNnyOj0gDAAxwDQgAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmKh3nwOqqqrSvn37FBsbG3H7EwBAw+CcU3l5uVJSUtSkSc3nOfUugPbt26eOHTtatwEAOEt79uxRhw4dalxf716Ci42NtW4BABAFp/t7XmcBNHfuXF188cVq3ry50tLStGHDhjOq42U3AGgcTvf3vE4C6M0339SUKVM0c+ZMbdq0SX379lVGRkadftkWAKCBcXVg4MCBLjs7O/z4+PHjLiUlxeXk5Jy2NhgMOkkMBoPBaOAjGAye8u991M+Ajh49qo0bN0Z84VaTJk2Unp5e7feoVFZWKhQKRQwAQOMX9QD66quvdPz4cSUmJkYsT0xMVElJyUnzc3JyFAgEwoN3wAHA+cH8XXDTp09XMBgMjz179li3BAA4B6L+OaC2bdsqJiZGpaWlEctLS0uVlJR00ny/3y+/3x/tNgAA9VzUz4CaNWum/v37a9WqVeFlVVVVWrVqlQYNGhTtzQEAGqg6uRPClClTNHbsWF155ZUaOHCgnn/+eVVUVOjnP/95XWwOANAA1UkA3XrrrTpw4IBmzJihkpIS9evXTytXrjzpjQkAgPOXzznnrJv4vlAopEAgYN0GAOAsBYNBxcXF1bje/F1wAIDzEwEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATF1g3ANQnMTExnmsCgUAddBIdkyZNqlVdy5YtPdd0797dc012drbnmmeeecZzze233+65RpKOHDniueaJJ57wXPPYY495rmkMOAMCAJgggAAAJqIeQLNmzZLP54sYPXr0iPZmAAANXJ1cA7r88sv10Ucf/f9GLuBSEwAgUp0kwwUXXKCkpKS6eGoAQCNRJ9eAduzYoZSUFKWmpurOO+/U7t27a5xbWVmpUCgUMQAAjV/UAygtLU0LFy7UypUrNW/ePBUVFemaa65ReXl5tfNzcnIUCATCo2PHjtFuCQBQD0U9gLKysvTTn/5Uffr0UUZGht5//32VlZXprbfeqnb+9OnTFQwGw2PPnj3RbgkAUA/V+bsDWrdurUsvvVSFhYXVrvf7/fL7/XXdBgCgnqnzzwEdOnRIO3fuVHJycl1vCgDQgEQ9gB588EHl5eVp165d+uSTTzR69GjFxMTU+lYYAIDGKeovwe3du1e33367Dh48qHbt2mnw4MFat26d2rVrF+1NAQAasKgH0JIlS6L9lKinOnXq5LmmWbNmnmt+/OMfe64ZPHiw5xrpxDVLr8aMGVOrbTU2e/fu9VwzZ84czzWjR4/2XFPTu3BP59NPP/Vck5eXV6ttnY+4FxwAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATPuecs27i+0KhkAKBgHUb55V+/frVqm716tWea/hv2zBUVVV5rvnFL37huebQoUOea2qjuLi4VnX/+9//PNds3769VttqjILBoOLi4mpczxkQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMDEBdYNwN7u3btrVXfw4EHPNdwN+4T169d7rikrK/NcM2zYMM81knT06FHPNX/+859rtS2cvzgDAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIKbkUJff/11reqmTp3quebGG2/0XLN582bPNXPmzPFcU1tbtmzxXHP99dd7rqmoqPBcc/nll3uukaTJkyfXqg7wgjMgAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJnzOOWfdxPeFQiEFAgHrNlBH4uLiPNeUl5d7rpk/f77nGkm6++67PdfcddddnmsWL17suQZoaILB4Cn/n+cMCABgggACAJjwHEBr167VyJEjlZKSIp/Pp2XLlkWsd85pxowZSk5OVosWLZSenq4dO3ZEq18AQCPhOYAqKirUt29fzZ07t9r1Tz31lObMmaOXX35Z69evV6tWrZSRkaEjR46cdbMAgMbD8zeiZmVlKSsrq9p1zjk9//zz+s1vfqObbrpJkvTaa68pMTFRy5Yt02233XZ23QIAGo2oXgMqKipSSUmJ0tPTw8sCgYDS0tKUn59fbU1lZaVCoVDEAAA0flENoJKSEklSYmJixPLExMTwuh/KyclRIBAIj44dO0azJQBAPWX+Lrjp06crGAyGx549e6xbAgCcA1ENoKSkJElSaWlpxPLS0tLwuh/y+/2Ki4uLGACAxi+qAdSlSxclJSVp1apV4WWhUEjr16/XoEGDorkpAEAD5/ldcIcOHVJhYWH4cVFRkbZs2aL4+Hh16tRJ999/v37/+9/rkksuUZcuXfToo48qJSVFo0aNimbfAIAGznMAFRQUaNiwYeHHU6ZMkSSNHTtWCxcu1LRp01RRUaF77rlHZWVlGjx4sFauXKnmzZtHr2sAQIPHzUjRKD399NO1qvvuH1Re5OXlea75/kcVzlRVVZXnGsASNyMFANRLBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAAT3A0bjVKrVq1qVffee+95rrn22ms912RlZXmu+fvf/+65BrDE3bABAPUSAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAE9yMFPierl27eq7ZtGmT55qysjLPNWvWrPFcU1BQ4LlGkubOneu5pp79KUE9wM1IAQD1EgEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABPcjBQ4S6NHj/Zcs2DBAs81sbGxnmtq65FHHvFc89prr3muKS4u9lyDhoObkQIA6iUCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmuBkpYKBXr16ea2bPnu25Zvjw4Z5ramv+/Pmeax5//HHPNV9++aXnGtjgZqQAgHqJAAIAmPAcQGvXrtXIkSOVkpIin8+nZcuWRawfN26cfD5fxMjMzIxWvwCARsJzAFVUVKhv376aO3dujXMyMzNVXFwcHosXLz6rJgEAjc8FXguysrKUlZV1yjl+v19JSUm1bgoA0PjVyTWg3NxcJSQkqHv37po4caIOHjxY49zKykqFQqGIAQBo/KIeQJmZmXrttde0atUqPfnkk8rLy1NWVpaOHz9e7fycnBwFAoHw6NixY7RbAgDUQ55fgjud2267Lfxz79691adPH3Xt2lW5ubnVfiZh+vTpmjJlSvhxKBQihADgPFDnb8NOTU1V27ZtVVhYWO16v9+vuLi4iAEAaPzqPID27t2rgwcPKjk5ua43BQBoQDy/BHfo0KGIs5mioiJt2bJF8fHxio+P12OPPaYxY8YoKSlJO3fu1LRp09StWzdlZGREtXEAQMPmOYAKCgo0bNiw8OPvrt+MHTtW8+bN09atW/Xqq6+qrKxMKSkpGjFihH73u9/J7/dHr2sAQIPHzUiBBqJ169aea0aOHFmrbS1YsMBzjc/n81yzevVqzzXXX3+95xrY4GakAIB6iQACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABggrthAzhJZWWl55oLLvD87S769ttvPdfU5rvFcnNzPdfg7HE3bABAvUQAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMCE97sHAjhrffr08Vxzyy23eK4ZMGCA5xqpdjcWrY3PPvvMc83atWvroBNY4AwIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACW5GCnxP9+7dPddMmjTJc83NN9/suSYpKclzzbl0/PhxzzXFxcWea6qqqjzXoH7iDAgAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJbkaKeq82N+G8/fbba7Wt2txY9OKLL67VtuqzgoICzzWPP/6455p3333Xcw0aD86AAAAmCCAAgAlPAZSTk6MBAwYoNjZWCQkJGjVqlLZv3x4x58iRI8rOzlabNm104YUXasyYMSotLY1q0wCAhs9TAOXl5Sk7O1vr1q3Thx9+qGPHjmnEiBGqqKgIz3nggQf03nvv6e2331ZeXp727dtXqy/fAgA0bp7ehLBy5cqIxwsXLlRCQoI2btyoIUOGKBgM6pVXXtGiRYt03XXXSZIWLFigyy67TOvWrdNVV10Vvc4BAA3aWV0DCgaDkqT4+HhJ0saNG3Xs2DGlp6eH5/To0UOdOnVSfn5+tc9RWVmpUCgUMQAAjV+tA6iqqkr333+/rr76avXq1UuSVFJSombNmql169YRcxMTE1VSUlLt8+Tk5CgQCIRHx44da9sSAKABqXUAZWdna9u2bVqyZMlZNTB9+nQFg8Hw2LNnz1k9HwCgYajVB1EnTZqkFStWaO3aterQoUN4eVJSko4ePaqysrKIs6DS0tIaP0zo9/vl9/tr0wYAoAHzdAbknNOkSZO0dOlSrV69Wl26dIlY379/fzVt2lSrVq0KL9u+fbt2796tQYMGRadjAECj4OkMKDs7W4sWLdLy5csVGxsbvq4TCATUokULBQIB3X333ZoyZYri4+MVFxen++67T4MGDeIdcACACJ4CaN68eZKkoUOHRixfsGCBxo0bJ0l67rnn1KRJE40ZM0aVlZXKyMjQSy+9FJVmAQCNh88556yb+L5QKKRAIGDdBs5AYmKi55qePXt6rnnxxRc91/To0cNzTX23fv16zzVPP/10rba1fPlyzzVVVVW12hYar2AwqLi4uBrXcy84AIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAICJWn0jKuqv+Ph4zzXz58+v1bb69evnuSY1NbVW26rPPvnkE881zz77rOeaDz74wHPNN99847kGOFc4AwIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCm5GeI2lpaZ5rpk6d6rlm4MCBnmvat2/vuaa+O3z4cK3q5syZ47nmD3/4g+eaiooKzzVAY8MZEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABPcjPQcGT169DmpOZc+++wzzzUrVqzwXPPtt996rnn22Wc910hSWVlZreoAeMcZEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABM+55yzbuL7QqGQAoGAdRsAgLMUDAYVFxdX43rOgAAAJgggAIAJTwGUk5OjAQMGKDY2VgkJCRo1apS2b98eMWfo0KHy+XwRY8KECVFtGgDQ8HkKoLy8PGVnZ2vdunX68MMPdezYMY0YMUIVFRUR88aPH6/i4uLweOqpp6LaNACg4fP0jagrV66MeLxw4UIlJCRo48aNGjJkSHh5y5YtlZSUFJ0OAQCN0lldAwoGg5Kk+Pj4iOVvvPGG2rZtq169emn69Ok6fPhwjc9RWVmpUCgUMQAA5wFXS8ePH3c33HCDu/rqqyOWz58/361cudJt3brVvf766659+/Zu9OjRNT7PzJkznSQGg8FgNLIRDAZPmSO1DqAJEya4zp07uz179pxy3qpVq5wkV1hYWO36I0eOuGAwGB579uwx32kMBoPBOPtxugDydA3oO5MmTdKKFSu0du1adejQ4ZRz09LSJEmFhYXq2rXrSev9fr/8fn9t2gAANGCeAsg5p/vuu09Lly5Vbm6uunTpctqaLVu2SJKSk5Nr1SAAoHHyFEDZ2dlatGiRli9frtjYWJWUlEiSAoGAWrRooZ07d2rRokX6yU9+ojZt2mjr1q164IEHNGTIEPXp06dOfgEAQAPl5bqPanidb8GCBc4553bv3u2GDBni4uPjnd/vd926dXNTp0497euA3xcMBs1ft2QwGAzG2Y/T/e3nZqQAgDrBzUgBAPUSAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMBEvQsg55x1CwCAKDjd3/N6F0Dl5eXWLQAAouB0f899rp6dclRVVWnfvn2KjY2Vz+eLWBcKhdSxY0ft2bNHcXFxRh3aYz+cwH44gf1wAvvhhPqwH5xzKi8vV0pKipo0qfk854Jz2NMZadKkiTp06HDKOXFxcef1AfYd9sMJ7IcT2A8nsB9OsN4PgUDgtHPq3UtwAIDzAwEEADDRoALI7/dr5syZ8vv91q2YYj+cwH44gf1wAvvhhIa0H+rdmxAAAOeHBnUGBABoPAggAIAJAggAYIIAAgCYIIAAACYaTADNnTtXF198sZo3b660tDRt2LDBuqVzbtasWfL5fBGjR48e1m3VubVr12rkyJFKSUmRz+fTsmXLItY75zRjxgwlJyerRYsWSk9P144dO2yarUOn2w/jxo076fjIzMy0abaO5OTkaMCAAYqNjVVCQoJGjRql7du3R8w5cuSIsrOz1aZNG1144YUaM2aMSktLjTquG2eyH4YOHXrS8TBhwgSjjqvXIALozTff1JQpUzRz5kxt2rRJffv2VUZGhvbv32/d2jl3+eWXq7i4ODw+/vhj65bqXEVFhfr27au5c+dWu/6pp57SnDlz9PLLL2v9+vVq1aqVMjIydOTIkXPcad063X6QpMzMzIjjY/Hixeeww7qXl5en7OxsrVu3Th9++KGOHTumESNGqKKiIjzngQce0Hvvvae3335beXl52rdvn26++WbDrqPvTPaDJI0fPz7ieHjqqaeMOq6BawAGDhzosrOzw4+PHz/uUlJSXE5OjmFX597MmTNd3759rdswJcktXbo0/LiqqsolJSW5p59+OrysrKzM+f1+t3jxYoMOz40f7gfnnBs7dqy76aabTPqxsn//fifJ5eXlOedO/Ldv2rSpe/vtt8NzPv/8cyfJ5efnW7VZ5364H5xz7tprr3WTJ0+2a+oM1PszoKNHj2rjxo1KT08PL2vSpInS09OVn59v2JmNHTt2KCUlRampqbrzzju1e/du65ZMFRUVqaSkJOL4CAQCSktLOy+Pj9zcXCUkJKh79+6aOHGiDh48aN1SnQoGg5Kk+Ph4SdLGjRt17NixiOOhR48e6tSpU6M+Hn64H77zxhtvqG3bturVq5emT5+uw4cPW7RXo3p3N+wf+uqrr3T8+HElJiZGLE9MTNQXX3xh1JWNtLQ0LVy4UN27d1dxcbEee+wxXXPNNdq2bZtiY2Ot2zNRUlIiSdUeH9+tO19kZmbq5ptvVpcuXbRz50498sgjysrKUn5+vmJiYqzbi7qqqirdf//9uvrqq9WrVy9JJ46HZs2aqXXr1hFzG/PxUN1+kKQ77rhDnTt3VkpKirZu3aqHHnpI27dv1zvvvGPYbaR6H0D4f1lZWeGf+/Tpo7S0NHXu3FlvvfWW7r77bsPOUB/cdttt4Z979+6tPn36qGvXrsrNzdXw4cMNO6sb2dnZ2rZt23lxHfRUatoP99xzT/jn3r17Kzk5WcOHD9fOnTvVtWvXc91mter9S3Bt27ZVTEzMSe9iKS0tVVJSklFX9UPr1q116aWXqrCw0LoVM98dAxwfJ0tNTVXbtm0b5fExadIkrVixQmvWrIn4/rCkpCQdPXpUZWVlEfMb6/FQ036oTlpamiTVq+Oh3gdQs2bN1L9/f61atSq8rKqqSqtWrdKgQYMMO7N36NAh7dy5U8nJydatmOnSpYuSkpIijo9QKKT169ef98fH3r17dfDgwUZ1fDjnNGnSJC1dulSrV69Wly5dItb3799fTZs2jTgetm/frt27dzeq4+F0+6E6W7ZskaT6dTxYvwviTCxZssT5/X63cOFC99lnn7l77rnHtW7d2pWUlFi3dk796le/crm5ua6oqMj985//dOnp6a5t27Zu//791q3VqfLycrd582a3efNmJ8nNnj3bbd682f33v/91zjn3xBNPuNatW7vly5e7rVu3uptuusl16dLFffPNN8adR9ep9kN5ebl78MEHXX5+visqKnIfffSR+9GPfuQuueQSd+TIEevWo2bixIkuEAi43NxcV1xcHB6HDx8Oz5kwYYLr1KmTW716tSsoKHCDBg1ygwYNMuw6+k63HwoLC91vf/tbV1BQ4IqKitzy5ctdamqqGzJkiHHnkRpEADnn3AsvvOA6derkmjVr5gYOHOjWrVtn3dI5d+utt7rk5GTXrFkz1759e3frrbe6wsJC67bq3Jo1a5ykk8bYsWOdcyfeiv3oo4+6xMRE5/f73fDhw9327dttm64Dp9oPhw8fdiNGjHDt2rVzTZs2dZ07d3bjx49vdP9Iq+73l+QWLFgQnvPNN9+4e++911100UWuZcuWbvTo0a64uNiu6Tpwuv2we/duN2TIEBcfH+/8fr/r1q2bmzp1qgsGg7aN/wDfBwQAMFHvrwEBABonAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJj4P4+ugj9xwbmpAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import random\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "# Custom transformation to add Gaussian noise\n",
        "class AddGaussianNoise:\n",
        "    def __init__(self, mean=0., std=0.1):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n",
        "\n",
        "# Define the augmentation pipeline with thinning and Gaussian noise\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Convert to tensor\n",
        "    transforms.Normalize((0.1307,), (0.3081,)),  # Normalize\n",
        "    transforms.RandomAffine(degrees=(-5,5), translate=(0.2, 0.2), scale=(0.7, 1.3), shear=10),  # Random affine\n",
        "    transforms.RandomApply([transforms.GaussianBlur(kernel_size=1)], p=0.3),  # Gaussian blur\n",
        "    transforms.RandomApply([transforms.ColorJitter(brightness=0.1, contrast=0.1)], p=0.3),\n",
        "    transforms.RandomApply([AddGaussianNoise(mean=0., std=0.1)], p=0.2)  # Add Gaussian noise\n",
        "])\n",
        "\n",
        "# Load the MNIST dataset with the transformation\n",
        "dataset = datasets.MNIST('../data', train=True, download=True, transform=transform)\n",
        "\n",
        "# Retrieve an image from the dataset\n",
        "image, label = dataset[4]  # Get the first image and its label\n",
        "\n",
        "# Convert the tensor to a numpy array and remove the batch dimension\n",
        "image = image * 0.3081 + 0.1307  # Reverse the normalization\n",
        "image = image.squeeze().numpy()\n",
        "\n",
        "# Display the image\n",
        "plt.imshow(image, cmap='gray')\n",
        "plt.title(f'Label: {label}')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "382Ifm9_bu-5",
        "outputId": "c548632b-9537-45b7-b54f-85600df0f184"
      },
      "id": "382Ifm9_bu-5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Model"
      ],
      "metadata": {
        "id": "IhVzQHC4cMhA"
      },
      "id": "IhVzQHC4cMhA"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import sys\n",
        "import time\n",
        "import random\n",
        "import argparse\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # Increased number of filters in convolutional layers\n",
        "        self.conv1 = nn.Conv2d(1, 64, 3, 1)  # Input channels: 1, Output channels: 64\n",
        "        self.conv2 = nn.Conv2d(64, 128, 3, 1)  # Output channels: 128\n",
        "        self.conv3 = nn.Conv2d(128, 256, 3, 1)  # Added a third convolutional layer\n",
        "        self.dropout1 = nn.Dropout(0.25)\n",
        "        self.dropout2 = nn.Dropout(0.4)\n",
        "        self.fc1 = nn.Linear(256 * 5 * 5, 512)  # Adjusted input size for the new conv layer\n",
        "        self.fc2 = nn.Linear(512, 256)  # Added an additional fully connected layer\n",
        "        self.fc3 = nn.Linear(256, 10)  # Output layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = self.conv3(x)  # Added the third convolutional layer\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = self.dropout1(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc2(x)  # Added the additional fully connected layer\n",
        "        x = F.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "        return output\n",
        "\n",
        "# Custom transformation to add Gaussian noise\n",
        "class AddGaussianNoise:\n",
        "    def __init__(self, mean=0., std=0.1):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n",
        "\n",
        "# Training Function\n",
        "def train(args, model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = torch.nn.functional.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        pred = output.argmax(dim=1, keepdim=True)\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "        if batch_idx % args.log_interval == 0:\n",
        "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} ({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
        "\n",
        "    train_loss /= len(train_loader)\n",
        "    accuracy = 100. * correct / len(train_loader.dataset)\n",
        "    return train_loss, accuracy\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += torch.nn.functional.nll_loss(output, target, reduction='sum').item()\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    accuracy = 100. * correct / len(test_loader.dataset)\n",
        "\n",
        "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({accuracy:.0f}%)\\n')\n",
        "\n",
        "    return test_loss, accuracy\n",
        "\n",
        "# Train and Evaluate\n",
        "def train_and_evaluate(args, model, device, train_loader, test_loader, optimizer, scheduler):\n",
        "    test_losses = []\n",
        "    test_accuracies = []\n",
        "    train_losses = []\n",
        "    train_accuracies = []\n",
        "\n",
        "    best_test_loss = float('inf')  # Initialize with a very high value\n",
        "    best_test_accuracy = float('inf')  # Initialize with a very high value\n",
        "\n",
        "    patience = 10  # Number of epochs to wait for improvement\n",
        "    no_improvement_count = 0  # Counter for epochs without improvement\n",
        "\n",
        "    # Create the \"MNIST_Model\" directory if it doesn't exist\n",
        "    model_dir = f\"MNIST_Model_seed_{args.seed}\"\n",
        "    if not os.path.exists(model_dir):\n",
        "        os.makedirs(model_dir)\n",
        "\n",
        "    for epoch in range(1, args.epochs + 1):\n",
        "        train_loss, train_accuracy = train(args, model, device, train_loader, optimizer, epoch)\n",
        "        test_loss, test_accuracy = test(model, device, test_loader)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        train_accuracies.append(train_accuracy)\n",
        "        test_losses.append(test_loss)\n",
        "        test_accuracies.append(test_accuracy)\n",
        "\n",
        "        # Check if the current test loss is the best so far\n",
        "        if test_loss < best_test_loss or test_accuracy > best_test_accuracy:\n",
        "            best_test_loss = test_loss\n",
        "            no_improvement_count = 0  # Reset the counter since we have improvement\n",
        "            if args.save_model and epoch > 4:\n",
        "                model_filename = f\"mnist_cnn_epoch:{epoch}_test-accuracy:{test_accuracy:.4f}_test-loss:{test_loss:.4f}.pt\"\n",
        "                model_path = os.path.join(model_dir, model_filename)  # Save model in the \"MNIST_Model\" directory\n",
        "                try:\n",
        "                    torch.save(model.state_dict(), model_path)\n",
        "                    print(f\"Model saved with new best test loss: {best_test_loss:.4f} \\n\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Error saving model: {e}\")\n",
        "        else:\n",
        "            no_improvement_count += 1  # Increment the counter since there's no improvement\n",
        "\n",
        "        # Early stopping check\n",
        "        if no_improvement_count >= patience:\n",
        "            print(f\"\\nEarly stopping triggered after {epoch} epochs. No improvement in test loss for {patience} consecutive epochs.\")\n",
        "            break\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    return train_losses, train_accuracies, test_losses, test_accuracies\n",
        "\n",
        "# Plot graphs\n",
        "def plot_results(train_losses, train_accuracies, test_losses, test_accuracies):\n",
        "    epochs = range(1, len(train_losses) + 1)\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    # Plot Train Loss\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, train_losses, 'o-', label='Train Loss')\n",
        "    plt.plot(epochs, test_losses, 'o-', label='Test Loss')\n",
        "    plt.title('Loss vs. Epoch')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot Accuracy\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, train_accuracies, 'o-', label='Train Accuracy')\n",
        "    plt.plot(epochs, test_accuracies, 'o-', label='Test Accuracy')\n",
        "    plt.title('Accuracy vs. Epoch')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy (%)')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    # Generate a random seed\n",
        "    random_seed = random.randint(0, 100000)\n",
        "    print(f\"Using random seed: {random_seed}\")\n",
        "\n",
        "    # Set the seed for reproducibility\n",
        "    torch.manual_seed(random_seed)\n",
        "    random.seed(random_seed)\n",
        "\n",
        "    # Running in a Jupyter notebook\n",
        "    args = argparse.Namespace(\n",
        "        batch_size=64,\n",
        "        test_batch_size=128,\n",
        "        epochs=500,\n",
        "        lr=1,\n",
        "        gamma=0.9, # Factor for adjusting the learning rate in the scheduler, reducing it over time.\n",
        "        no_cuda=False, # can use the GPU if available\n",
        "        no_mps=False, #  can use the MPS if available\n",
        "        dry_run=False, # If True, performs a quick single pass to test the setup.\n",
        "        seed=random_seed,\n",
        "        log_interval=10, # Determines how often to log training progress (e.g., every 10 batches).\n",
        "        save_model=True\n",
        "    )\n",
        "\n",
        "    # Device Setup\n",
        "    use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
        "    use_mps = not args.no_mps and torch.backends.mps.is_available()\n",
        "\n",
        "    torch.manual_seed(args.seed)\n",
        "\n",
        "    if use_cuda:\n",
        "        device = torch.device(\"cuda\")\n",
        "    elif use_mps:\n",
        "        device = torch.device(\"mps\")\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "\n",
        "    # Data Loading\n",
        "    train_kwargs = {'batch_size': args.batch_size}\n",
        "    test_kwargs = {'batch_size': args.test_batch_size}\n",
        "\n",
        "    if use_cuda:\n",
        "        cuda_kwargs = {'num_workers': 1,\n",
        "                       'pin_memory': True,\n",
        "                       'shuffle': True}\n",
        "        train_kwargs.update(cuda_kwargs)\n",
        "        test_kwargs.update(cuda_kwargs)\n",
        "\n",
        "    # Data Loading with Augmentation for Training\n",
        "    transform_train = transforms.Compose([\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize((0.1307,), (0.3081,)),\n",
        "      transforms.RandomAffine(degrees=(-5,5), translate=(0.1, 0.1), scale=(0.6, 1.3), shear=10),\n",
        "      transforms.RandomApply([AddGaussianNoise(mean=0., std=0.1)], p=0.2),  # Add Gaussian noise\n",
        "  ])\n",
        "\n",
        "    # Transform for testing (no augmentation)\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])\n",
        "\n",
        "    # Dataset and DataLoader\n",
        "    dataset1 = datasets.MNIST('../data', train=True, download=True,\n",
        "                       transform=transform_train)\n",
        "    dataset2 = datasets.MNIST('../data', train=False,\n",
        "                       transform=transform_test)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs)\n",
        "    test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)\n",
        "\n",
        "    # Model and Optimizer Initialization\n",
        "    model = Net().to(device)\n",
        "    optimizer = optim.Adadelta(model.parameters(), lr=args.lr) # optimizer: Adadelta / SGD / Adam\n",
        "    scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)\n",
        "\n",
        "    # Train and Evaluate\n",
        "    train_losses, train_accuracies, test_losses, test_accuracies = train_and_evaluate(args, model, device, train_loader, test_loader, optimizer, scheduler)\n",
        "\n",
        "    # Plot Results\n",
        "    plot_results(train_losses, train_accuracies, test_losses, test_accuracies)\n",
        "\n",
        "    # Compress the folder into a zip file\n",
        "    #shutil.make_archive(model_dir, 'zip', model_dir)  # Use the same folder name\n",
        "\n",
        "    # Download the zip file in Google Colab\n",
        "    #files.download(f'{model_dir}.zip')  # Download the zip file with the correct name\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ggENXZXJcOH4",
        "outputId": "59574b28-ed7d-4e19-dea8-0392d0d903e0"
      },
      "id": "ggENXZXJcOH4",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using random seed: 83082\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 17.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 505kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.43MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 3.92MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
            "\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.308583\n",
            "Train Epoch: 1 [640/60000 (1%)]\tLoss: 2.274996\n",
            "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 2.089018\n",
            "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 2.246872\n",
            "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 1.846370\n",
            "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 1.733736\n",
            "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 4.286676\n",
            "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 1.378864\n",
            "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.887166\n",
            "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 0.647081\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.613334\n",
            "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 0.852770\n",
            "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.655159\n",
            "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.754405\n",
            "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 1.190839\n",
            "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.727065\n",
            "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.893471\n",
            "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.435999\n",
            "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.398488\n",
            "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.358127\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.639751\n",
            "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.475351\n",
            "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.298346\n",
            "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.295180\n",
            "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.274081\n",
            "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.512857\n",
            "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.806147\n",
            "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.447715\n",
            "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.632065\n",
            "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.338653\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.303256\n",
            "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.226999\n",
            "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.630601\n",
            "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.233324\n",
            "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.169764\n",
            "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.152985\n",
            "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.253764\n",
            "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.220741\n",
            "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.262443\n",
            "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.144702\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.403804\n",
            "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.223734\n",
            "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.213641\n",
            "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.248120\n",
            "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.111253\n",
            "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.126366\n",
            "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.505289\n",
            "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.220997\n",
            "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.477728\n",
            "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.118916\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.356437\n",
            "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.133275\n",
            "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.252855\n",
            "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.255665\n",
            "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.176533\n",
            "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.170516\n",
            "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.182826\n",
            "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.191122\n",
            "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.146478\n",
            "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.191589\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.292179\n",
            "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.368854\n",
            "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.309903\n",
            "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.251858\n",
            "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.093087\n",
            "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.114160\n",
            "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.086805\n",
            "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.137319\n",
            "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.121842\n",
            "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.254963\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.033075\n",
            "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.069100\n",
            "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.034607\n",
            "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.052273\n",
            "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.085341\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.229089\n",
            "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.319275\n",
            "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.245061\n",
            "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.143164\n",
            "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.144090\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.157652\n",
            "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.284739\n",
            "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.101143\n",
            "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.149478\n",
            "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.281620\n",
            "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.032983\n",
            "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.273423\n",
            "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.118735\n",
            "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.131062\n",
            "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.131055\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.119536\n",
            "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.134282\n",
            "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.112183\n",
            "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.142708\n",
            "\n",
            "Test set: Average loss: 0.0342, Accuracy: 9896/10000 (99%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.096773\n",
            "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.157415\n",
            "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.144724\n",
            "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.139929\n",
            "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.134593\n",
            "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.104368\n",
            "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.114219\n",
            "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.014390\n",
            "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.039442\n",
            "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.130356\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.082182\n",
            "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.127064\n",
            "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.108880\n",
            "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.105246\n",
            "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.124948\n",
            "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.015896\n",
            "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.142031\n",
            "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.117245\n",
            "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.174470\n",
            "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.139639\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.065108\n",
            "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.046571\n",
            "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.114186\n",
            "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.155905\n",
            "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.169121\n",
            "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.039878\n",
            "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.030045\n",
            "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.075087\n",
            "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.164190\n",
            "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.242200\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.085811\n",
            "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.066150\n",
            "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.092110\n",
            "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.218314\n",
            "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.126265\n",
            "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.092430\n",
            "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.037663\n",
            "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.220460\n",
            "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.185324\n",
            "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.037859\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.095085\n",
            "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.114836\n",
            "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.139728\n",
            "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.111204\n",
            "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.061964\n",
            "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.096686\n",
            "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.285968\n",
            "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.226344\n",
            "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.216274\n",
            "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.112738\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.181033\n",
            "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.125773\n",
            "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.125965\n",
            "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.146044\n",
            "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.014234\n",
            "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.375116\n",
            "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.043807\n",
            "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.043547\n",
            "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.131582\n",
            "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.106844\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.057657\n",
            "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.082322\n",
            "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.105019\n",
            "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.153506\n",
            "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.192512\n",
            "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.110994\n",
            "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.115929\n",
            "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.339260\n",
            "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.011024\n",
            "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.219894\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.153828\n",
            "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.010994\n",
            "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.059262\n",
            "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.079758\n",
            "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.045311\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.112077\n",
            "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.044480\n",
            "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.035131\n",
            "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.063531\n",
            "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.150781\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.066972\n",
            "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.092593\n",
            "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.009754\n",
            "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.037319\n",
            "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.194495\n",
            "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.130701\n",
            "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.067862\n",
            "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.051951\n",
            "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.101469\n",
            "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.046802\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.054236\n",
            "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.098453\n",
            "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.076409\n",
            "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.049455\n",
            "\n",
            "Test set: Average loss: 0.0244, Accuracy: 9925/10000 (99%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.019936\n",
            "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.023727\n",
            "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.105985\n",
            "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.106020\n",
            "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.100768\n",
            "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.218713\n",
            "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.129010\n",
            "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.065877\n",
            "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.144049\n",
            "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.160955\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.067783\n",
            "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.164566\n",
            "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.014154\n",
            "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.054105\n",
            "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.078241\n",
            "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.122162\n",
            "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.093660\n",
            "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.025372\n",
            "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.184650\n",
            "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.034122\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.056272\n",
            "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.013765\n",
            "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.145528\n",
            "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.113807\n",
            "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.029745\n",
            "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.044355\n",
            "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.039396\n",
            "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.003932\n",
            "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.143667\n",
            "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.133053\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.130827\n",
            "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.045816\n",
            "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.086954\n",
            "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.194592\n",
            "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.032103\n",
            "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.029108\n",
            "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.013135\n",
            "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.074330\n",
            "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.073713\n",
            "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.008718\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.080925\n",
            "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.268535\n",
            "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.122370\n",
            "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.071415\n",
            "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.062595\n",
            "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.109710\n",
            "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.092704\n",
            "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.009492\n",
            "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.021425\n",
            "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.084832\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.195818\n",
            "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.011714\n",
            "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.124123\n",
            "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.048345\n",
            "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.049920\n",
            "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.157467\n",
            "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.108447\n",
            "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.052419\n",
            "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.090600\n",
            "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.032165\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.023004\n",
            "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.129428\n",
            "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.187341\n",
            "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.080145\n",
            "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.029487\n",
            "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.090716\n",
            "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.059401\n",
            "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.018789\n",
            "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.107344\n",
            "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.065510\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.016662\n",
            "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.071388\n",
            "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.032173\n",
            "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.139157\n",
            "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.112644\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.108674\n",
            "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.029314\n",
            "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.064860\n",
            "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.030951\n",
            "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.025284\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.100624\n",
            "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.026694\n",
            "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.072266\n",
            "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.090191\n",
            "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.241883\n",
            "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.074846\n",
            "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.064477\n",
            "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.264812\n",
            "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.041422\n",
            "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.020385\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.018821\n",
            "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.024429\n",
            "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.014280\n",
            "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.011159\n",
            "\n",
            "Test set: Average loss: 0.0250, Accuracy: 9923/10000 (99%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.052870\n",
            "Train Epoch: 4 [640/60000 (1%)]\tLoss: 0.043408\n",
            "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 0.077471\n",
            "Train Epoch: 4 [1920/60000 (3%)]\tLoss: 0.020967\n",
            "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 0.104599\n",
            "Train Epoch: 4 [3200/60000 (5%)]\tLoss: 0.057071\n",
            "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 0.121239\n",
            "Train Epoch: 4 [4480/60000 (7%)]\tLoss: 0.039336\n",
            "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 0.138931\n",
            "Train Epoch: 4 [5760/60000 (10%)]\tLoss: 0.012547\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.014185\n",
            "Train Epoch: 4 [7040/60000 (12%)]\tLoss: 0.062521\n",
            "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 0.239398\n",
            "Train Epoch: 4 [8320/60000 (14%)]\tLoss: 0.039854\n",
            "Train Epoch: 4 [8960/60000 (15%)]\tLoss: 0.007807\n",
            "Train Epoch: 4 [9600/60000 (16%)]\tLoss: 0.011184\n",
            "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 0.052895\n",
            "Train Epoch: 4 [10880/60000 (18%)]\tLoss: 0.088748\n",
            "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 0.026691\n",
            "Train Epoch: 4 [12160/60000 (20%)]\tLoss: 0.055691\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.047793\n",
            "Train Epoch: 4 [13440/60000 (22%)]\tLoss: 0.003841\n",
            "Train Epoch: 4 [14080/60000 (23%)]\tLoss: 0.112442\n",
            "Train Epoch: 4 [14720/60000 (25%)]\tLoss: 0.139192\n",
            "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 0.106317\n",
            "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.105057\n",
            "Train Epoch: 4 [16640/60000 (28%)]\tLoss: 0.161417\n",
            "Train Epoch: 4 [17280/60000 (29%)]\tLoss: 0.013139\n",
            "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 0.034542\n",
            "Train Epoch: 4 [18560/60000 (31%)]\tLoss: 0.064902\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.143277\n",
            "Train Epoch: 4 [19840/60000 (33%)]\tLoss: 0.178670\n",
            "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.139727\n",
            "Train Epoch: 4 [21120/60000 (35%)]\tLoss: 0.016220\n",
            "Train Epoch: 4 [21760/60000 (36%)]\tLoss: 0.122268\n",
            "Train Epoch: 4 [22400/60000 (37%)]\tLoss: 0.148803\n",
            "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 0.008018\n",
            "Train Epoch: 4 [23680/60000 (39%)]\tLoss: 0.159858\n",
            "Train Epoch: 4 [24320/60000 (41%)]\tLoss: 0.011241\n",
            "Train Epoch: 4 [24960/60000 (42%)]\tLoss: 0.030457\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.030154\n",
            "Train Epoch: 4 [26240/60000 (44%)]\tLoss: 0.044543\n",
            "Train Epoch: 4 [26880/60000 (45%)]\tLoss: 0.016021\n",
            "Train Epoch: 4 [27520/60000 (46%)]\tLoss: 0.048074\n",
            "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 0.231924\n",
            "Train Epoch: 4 [28800/60000 (48%)]\tLoss: 0.058858\n",
            "Train Epoch: 4 [29440/60000 (49%)]\tLoss: 0.057236\n",
            "Train Epoch: 4 [30080/60000 (50%)]\tLoss: 0.173180\n",
            "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 0.007415\n",
            "Train Epoch: 4 [31360/60000 (52%)]\tLoss: 0.023113\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.032890\n",
            "Train Epoch: 4 [32640/60000 (54%)]\tLoss: 0.055873\n",
            "Train Epoch: 4 [33280/60000 (55%)]\tLoss: 0.091488\n",
            "Train Epoch: 4 [33920/60000 (57%)]\tLoss: 0.028294\n",
            "Train Epoch: 4 [34560/60000 (58%)]\tLoss: 0.034752\n",
            "Train Epoch: 4 [35200/60000 (59%)]\tLoss: 0.105887\n",
            "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 0.042688\n",
            "Train Epoch: 4 [36480/60000 (61%)]\tLoss: 0.102522\n",
            "Train Epoch: 4 [37120/60000 (62%)]\tLoss: 0.065761\n",
            "Train Epoch: 4 [37760/60000 (63%)]\tLoss: 0.003943\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.137011\n",
            "Train Epoch: 4 [39040/60000 (65%)]\tLoss: 0.016541\n",
            "Train Epoch: 4 [39680/60000 (66%)]\tLoss: 0.176045\n",
            "Train Epoch: 4 [40320/60000 (67%)]\tLoss: 0.061171\n",
            "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.066396\n",
            "Train Epoch: 4 [41600/60000 (69%)]\tLoss: 0.098341\n",
            "Train Epoch: 4 [42240/60000 (70%)]\tLoss: 0.068531\n",
            "Train Epoch: 4 [42880/60000 (71%)]\tLoss: 0.050638\n",
            "Train Epoch: 4 [43520/60000 (72%)]\tLoss: 0.062960\n",
            "Train Epoch: 4 [44160/60000 (74%)]\tLoss: 0.185164\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.031971\n",
            "Train Epoch: 4 [45440/60000 (76%)]\tLoss: 0.021663\n",
            "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 0.027639\n",
            "Train Epoch: 4 [46720/60000 (78%)]\tLoss: 0.071972\n",
            "Train Epoch: 4 [47360/60000 (79%)]\tLoss: 0.024703\n",
            "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.153356\n",
            "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 0.185384\n",
            "Train Epoch: 4 [49280/60000 (82%)]\tLoss: 0.014141\n",
            "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 0.028432\n",
            "Train Epoch: 4 [50560/60000 (84%)]\tLoss: 0.078829\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.043978\n",
            "Train Epoch: 4 [51840/60000 (86%)]\tLoss: 0.025925\n",
            "Train Epoch: 4 [52480/60000 (87%)]\tLoss: 0.114282\n",
            "Train Epoch: 4 [53120/60000 (88%)]\tLoss: 0.060650\n",
            "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 0.041572\n",
            "Train Epoch: 4 [54400/60000 (91%)]\tLoss: 0.017064\n",
            "Train Epoch: 4 [55040/60000 (92%)]\tLoss: 0.075022\n",
            "Train Epoch: 4 [55680/60000 (93%)]\tLoss: 0.020798\n",
            "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 0.198769\n",
            "Train Epoch: 4 [56960/60000 (95%)]\tLoss: 0.099166\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.077651\n",
            "Train Epoch: 4 [58240/60000 (97%)]\tLoss: 0.011323\n",
            "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 0.079678\n",
            "Train Epoch: 4 [59520/60000 (99%)]\tLoss: 0.089292\n",
            "\n",
            "Test set: Average loss: 0.0215, Accuracy: 9939/10000 (99%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.070668\n",
            "Train Epoch: 5 [640/60000 (1%)]\tLoss: 0.009415\n",
            "Train Epoch: 5 [1280/60000 (2%)]\tLoss: 0.095803\n",
            "Train Epoch: 5 [1920/60000 (3%)]\tLoss: 0.007634\n",
            "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 0.095432\n",
            "Train Epoch: 5 [3200/60000 (5%)]\tLoss: 0.210002\n",
            "Train Epoch: 5 [3840/60000 (6%)]\tLoss: 0.050103\n",
            "Train Epoch: 5 [4480/60000 (7%)]\tLoss: 0.132856\n",
            "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 0.232804\n",
            "Train Epoch: 5 [5760/60000 (10%)]\tLoss: 0.041264\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.143915\n",
            "Train Epoch: 5 [7040/60000 (12%)]\tLoss: 0.057583\n",
            "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 0.066560\n",
            "Train Epoch: 5 [8320/60000 (14%)]\tLoss: 0.132765\n",
            "Train Epoch: 5 [8960/60000 (15%)]\tLoss: 0.058960\n",
            "Train Epoch: 5 [9600/60000 (16%)]\tLoss: 0.003547\n",
            "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 0.051529\n",
            "Train Epoch: 5 [10880/60000 (18%)]\tLoss: 0.253925\n",
            "Train Epoch: 5 [11520/60000 (19%)]\tLoss: 0.018266\n",
            "Train Epoch: 5 [12160/60000 (20%)]\tLoss: 0.044081\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.018549\n",
            "Train Epoch: 5 [13440/60000 (22%)]\tLoss: 0.035432\n",
            "Train Epoch: 5 [14080/60000 (23%)]\tLoss: 0.111912\n",
            "Train Epoch: 5 [14720/60000 (25%)]\tLoss: 0.002460\n",
            "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 0.092342\n",
            "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.037034\n",
            "Train Epoch: 5 [16640/60000 (28%)]\tLoss: 0.006107\n",
            "Train Epoch: 5 [17280/60000 (29%)]\tLoss: 0.077785\n",
            "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 0.004080\n",
            "Train Epoch: 5 [18560/60000 (31%)]\tLoss: 0.104353\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.004278\n",
            "Train Epoch: 5 [19840/60000 (33%)]\tLoss: 0.032519\n",
            "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.007421\n",
            "Train Epoch: 5 [21120/60000 (35%)]\tLoss: 0.016395\n",
            "Train Epoch: 5 [21760/60000 (36%)]\tLoss: 0.024750\n",
            "Train Epoch: 5 [22400/60000 (37%)]\tLoss: 0.053755\n",
            "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 0.337142\n",
            "Train Epoch: 5 [23680/60000 (39%)]\tLoss: 0.209601\n",
            "Train Epoch: 5 [24320/60000 (41%)]\tLoss: 0.012812\n",
            "Train Epoch: 5 [24960/60000 (42%)]\tLoss: 0.013179\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.063619\n",
            "Train Epoch: 5 [26240/60000 (44%)]\tLoss: 0.055642\n",
            "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 0.065406\n",
            "Train Epoch: 5 [27520/60000 (46%)]\tLoss: 0.083275\n",
            "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 0.015198\n",
            "Train Epoch: 5 [28800/60000 (48%)]\tLoss: 0.009277\n",
            "Train Epoch: 5 [29440/60000 (49%)]\tLoss: 0.178630\n",
            "Train Epoch: 5 [30080/60000 (50%)]\tLoss: 0.039664\n",
            "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.075285\n",
            "Train Epoch: 5 [31360/60000 (52%)]\tLoss: 0.043376\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.090813\n",
            "Train Epoch: 5 [32640/60000 (54%)]\tLoss: 0.016338\n",
            "Train Epoch: 5 [33280/60000 (55%)]\tLoss: 0.003443\n",
            "Train Epoch: 5 [33920/60000 (57%)]\tLoss: 0.200162\n",
            "Train Epoch: 5 [34560/60000 (58%)]\tLoss: 0.034430\n",
            "Train Epoch: 5 [35200/60000 (59%)]\tLoss: 0.071116\n",
            "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 0.098352\n",
            "Train Epoch: 5 [36480/60000 (61%)]\tLoss: 0.090426\n",
            "Train Epoch: 5 [37120/60000 (62%)]\tLoss: 0.092540\n",
            "Train Epoch: 5 [37760/60000 (63%)]\tLoss: 0.002620\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.045905\n",
            "Train Epoch: 5 [39040/60000 (65%)]\tLoss: 0.117529\n",
            "Train Epoch: 5 [39680/60000 (66%)]\tLoss: 0.058345\n",
            "Train Epoch: 5 [40320/60000 (67%)]\tLoss: 0.040086\n",
            "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.028264\n",
            "Train Epoch: 5 [41600/60000 (69%)]\tLoss: 0.087957\n",
            "Train Epoch: 5 [42240/60000 (70%)]\tLoss: 0.003206\n",
            "Train Epoch: 5 [42880/60000 (71%)]\tLoss: 0.071035\n",
            "Train Epoch: 5 [43520/60000 (72%)]\tLoss: 0.087678\n",
            "Train Epoch: 5 [44160/60000 (74%)]\tLoss: 0.029390\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.003004\n",
            "Train Epoch: 5 [45440/60000 (76%)]\tLoss: 0.099689\n",
            "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 0.102848\n",
            "Train Epoch: 5 [46720/60000 (78%)]\tLoss: 0.179137\n",
            "Train Epoch: 5 [47360/60000 (79%)]\tLoss: 0.086834\n",
            "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.238723\n",
            "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 0.023621\n",
            "Train Epoch: 5 [49280/60000 (82%)]\tLoss: 0.009816\n",
            "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 0.088463\n",
            "Train Epoch: 5 [50560/60000 (84%)]\tLoss: 0.172494\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.003700\n",
            "Train Epoch: 5 [51840/60000 (86%)]\tLoss: 0.028779\n",
            "Train Epoch: 5 [52480/60000 (87%)]\tLoss: 0.041917\n",
            "Train Epoch: 5 [53120/60000 (88%)]\tLoss: 0.020705\n",
            "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 0.013184\n",
            "Train Epoch: 5 [54400/60000 (91%)]\tLoss: 0.117222\n",
            "Train Epoch: 5 [55040/60000 (92%)]\tLoss: 0.017772\n",
            "Train Epoch: 5 [55680/60000 (93%)]\tLoss: 0.058612\n",
            "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 0.018077\n",
            "Train Epoch: 5 [56960/60000 (95%)]\tLoss: 0.029738\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.011175\n",
            "Train Epoch: 5 [58240/60000 (97%)]\tLoss: 0.040931\n",
            "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 0.017037\n",
            "Train Epoch: 5 [59520/60000 (99%)]\tLoss: 0.054713\n",
            "\n",
            "Test set: Average loss: 0.0188, Accuracy: 9946/10000 (99%)\n",
            "\n",
            "Model saved with new best test loss: 0.0188 \n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.052494\n",
            "Train Epoch: 6 [640/60000 (1%)]\tLoss: 0.091755\n",
            "Train Epoch: 6 [1280/60000 (2%)]\tLoss: 0.034423\n",
            "Train Epoch: 6 [1920/60000 (3%)]\tLoss: 0.072719\n",
            "Train Epoch: 6 [2560/60000 (4%)]\tLoss: 0.011410\n",
            "Train Epoch: 6 [3200/60000 (5%)]\tLoss: 0.043586\n",
            "Train Epoch: 6 [3840/60000 (6%)]\tLoss: 0.007295\n",
            "Train Epoch: 6 [4480/60000 (7%)]\tLoss: 0.112109\n",
            "Train Epoch: 6 [5120/60000 (9%)]\tLoss: 0.034395\n",
            "Train Epoch: 6 [5760/60000 (10%)]\tLoss: 0.038547\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.004184\n",
            "Train Epoch: 6 [7040/60000 (12%)]\tLoss: 0.051610\n",
            "Train Epoch: 6 [7680/60000 (13%)]\tLoss: 0.061396\n",
            "Train Epoch: 6 [8320/60000 (14%)]\tLoss: 0.077647\n",
            "Train Epoch: 6 [8960/60000 (15%)]\tLoss: 0.024482\n",
            "Train Epoch: 6 [9600/60000 (16%)]\tLoss: 0.106227\n",
            "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 0.122790\n",
            "Train Epoch: 6 [10880/60000 (18%)]\tLoss: 0.100103\n",
            "Train Epoch: 6 [11520/60000 (19%)]\tLoss: 0.040160\n",
            "Train Epoch: 6 [12160/60000 (20%)]\tLoss: 0.074870\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.094533\n",
            "Train Epoch: 6 [13440/60000 (22%)]\tLoss: 0.046735\n",
            "Train Epoch: 6 [14080/60000 (23%)]\tLoss: 0.006567\n",
            "Train Epoch: 6 [14720/60000 (25%)]\tLoss: 0.002131\n",
            "Train Epoch: 6 [15360/60000 (26%)]\tLoss: 0.195736\n",
            "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.038993\n",
            "Train Epoch: 6 [16640/60000 (28%)]\tLoss: 0.010036\n",
            "Train Epoch: 6 [17280/60000 (29%)]\tLoss: 0.025569\n",
            "Train Epoch: 6 [17920/60000 (30%)]\tLoss: 0.275675\n",
            "Train Epoch: 6 [18560/60000 (31%)]\tLoss: 0.117645\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.100767\n",
            "Train Epoch: 6 [19840/60000 (33%)]\tLoss: 0.075674\n",
            "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 0.014331\n",
            "Train Epoch: 6 [21120/60000 (35%)]\tLoss: 0.128987\n",
            "Train Epoch: 6 [21760/60000 (36%)]\tLoss: 0.018156\n",
            "Train Epoch: 6 [22400/60000 (37%)]\tLoss: 0.001527\n",
            "Train Epoch: 6 [23040/60000 (38%)]\tLoss: 0.045628\n",
            "Train Epoch: 6 [23680/60000 (39%)]\tLoss: 0.093861\n",
            "Train Epoch: 6 [24320/60000 (41%)]\tLoss: 0.052333\n",
            "Train Epoch: 6 [24960/60000 (42%)]\tLoss: 0.051729\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.037295\n",
            "Train Epoch: 6 [26240/60000 (44%)]\tLoss: 0.014670\n",
            "Train Epoch: 6 [26880/60000 (45%)]\tLoss: 0.039172\n",
            "Train Epoch: 6 [27520/60000 (46%)]\tLoss: 0.149129\n",
            "Train Epoch: 6 [28160/60000 (47%)]\tLoss: 0.006647\n",
            "Train Epoch: 6 [28800/60000 (48%)]\tLoss: 0.027536\n",
            "Train Epoch: 6 [29440/60000 (49%)]\tLoss: 0.033042\n",
            "Train Epoch: 6 [30080/60000 (50%)]\tLoss: 0.008658\n",
            "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 0.086149\n",
            "Train Epoch: 6 [31360/60000 (52%)]\tLoss: 0.008527\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.281294\n",
            "Train Epoch: 6 [32640/60000 (54%)]\tLoss: 0.037688\n",
            "Train Epoch: 6 [33280/60000 (55%)]\tLoss: 0.004769\n",
            "Train Epoch: 6 [33920/60000 (57%)]\tLoss: 0.022598\n",
            "Train Epoch: 6 [34560/60000 (58%)]\tLoss: 0.009557\n",
            "Train Epoch: 6 [35200/60000 (59%)]\tLoss: 0.038535\n",
            "Train Epoch: 6 [35840/60000 (60%)]\tLoss: 0.008551\n",
            "Train Epoch: 6 [36480/60000 (61%)]\tLoss: 0.094730\n",
            "Train Epoch: 6 [37120/60000 (62%)]\tLoss: 0.065216\n",
            "Train Epoch: 6 [37760/60000 (63%)]\tLoss: 0.002704\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.032959\n",
            "Train Epoch: 6 [39040/60000 (65%)]\tLoss: 0.179653\n",
            "Train Epoch: 6 [39680/60000 (66%)]\tLoss: 0.010181\n",
            "Train Epoch: 6 [40320/60000 (67%)]\tLoss: 0.033261\n",
            "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 0.181794\n",
            "Train Epoch: 6 [41600/60000 (69%)]\tLoss: 0.109254\n",
            "Train Epoch: 6 [42240/60000 (70%)]\tLoss: 0.004946\n",
            "Train Epoch: 6 [42880/60000 (71%)]\tLoss: 0.007580\n",
            "Train Epoch: 6 [43520/60000 (72%)]\tLoss: 0.034699\n",
            "Train Epoch: 6 [44160/60000 (74%)]\tLoss: 0.074323\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.062110\n",
            "Train Epoch: 6 [45440/60000 (76%)]\tLoss: 0.050928\n",
            "Train Epoch: 6 [46080/60000 (77%)]\tLoss: 0.010077\n",
            "Train Epoch: 6 [46720/60000 (78%)]\tLoss: 0.007404\n",
            "Train Epoch: 6 [47360/60000 (79%)]\tLoss: 0.003592\n",
            "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.007657\n",
            "Train Epoch: 6 [48640/60000 (81%)]\tLoss: 0.034103\n",
            "Train Epoch: 6 [49280/60000 (82%)]\tLoss: 0.094350\n",
            "Train Epoch: 6 [49920/60000 (83%)]\tLoss: 0.014270\n",
            "Train Epoch: 6 [50560/60000 (84%)]\tLoss: 0.267872\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.018869\n",
            "Train Epoch: 6 [51840/60000 (86%)]\tLoss: 0.008000\n",
            "Train Epoch: 6 [52480/60000 (87%)]\tLoss: 0.053668\n",
            "Train Epoch: 6 [53120/60000 (88%)]\tLoss: 0.132257\n",
            "Train Epoch: 6 [53760/60000 (90%)]\tLoss: 0.019675\n",
            "Train Epoch: 6 [54400/60000 (91%)]\tLoss: 0.006660\n",
            "Train Epoch: 6 [55040/60000 (92%)]\tLoss: 0.006772\n",
            "Train Epoch: 6 [55680/60000 (93%)]\tLoss: 0.015313\n",
            "Train Epoch: 6 [56320/60000 (94%)]\tLoss: 0.074974\n",
            "Train Epoch: 6 [56960/60000 (95%)]\tLoss: 0.001257\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.008603\n",
            "Train Epoch: 6 [58240/60000 (97%)]\tLoss: 0.025225\n",
            "Train Epoch: 6 [58880/60000 (98%)]\tLoss: 0.053217\n",
            "Train Epoch: 6 [59520/60000 (99%)]\tLoss: 0.147540\n",
            "\n",
            "Test set: Average loss: 0.0169, Accuracy: 9950/10000 (100%)\n",
            "\n",
            "Model saved with new best test loss: 0.0169 \n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.028365\n",
            "Train Epoch: 7 [640/60000 (1%)]\tLoss: 0.084224\n",
            "Train Epoch: 7 [1280/60000 (2%)]\tLoss: 0.143070\n",
            "Train Epoch: 7 [1920/60000 (3%)]\tLoss: 0.012482\n",
            "Train Epoch: 7 [2560/60000 (4%)]\tLoss: 0.079328\n",
            "Train Epoch: 7 [3200/60000 (5%)]\tLoss: 0.023013\n",
            "Train Epoch: 7 [3840/60000 (6%)]\tLoss: 0.006560\n",
            "Train Epoch: 7 [4480/60000 (7%)]\tLoss: 0.011757\n",
            "Train Epoch: 7 [5120/60000 (9%)]\tLoss: 0.060500\n",
            "Train Epoch: 7 [5760/60000 (10%)]\tLoss: 0.004661\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.021915\n",
            "Train Epoch: 7 [7040/60000 (12%)]\tLoss: 0.065558\n",
            "Train Epoch: 7 [7680/60000 (13%)]\tLoss: 0.043308\n",
            "Train Epoch: 7 [8320/60000 (14%)]\tLoss: 0.010055\n",
            "Train Epoch: 7 [8960/60000 (15%)]\tLoss: 0.093587\n",
            "Train Epoch: 7 [9600/60000 (16%)]\tLoss: 0.038325\n",
            "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 0.015327\n",
            "Train Epoch: 7 [10880/60000 (18%)]\tLoss: 0.014942\n",
            "Train Epoch: 7 [11520/60000 (19%)]\tLoss: 0.059206\n",
            "Train Epoch: 7 [12160/60000 (20%)]\tLoss: 0.063964\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.067584\n",
            "Train Epoch: 7 [13440/60000 (22%)]\tLoss: 0.066964\n",
            "Train Epoch: 7 [14080/60000 (23%)]\tLoss: 0.090535\n",
            "Train Epoch: 7 [14720/60000 (25%)]\tLoss: 0.074479\n",
            "Train Epoch: 7 [15360/60000 (26%)]\tLoss: 0.058265\n",
            "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.004745\n",
            "Train Epoch: 7 [16640/60000 (28%)]\tLoss: 0.026464\n",
            "Train Epoch: 7 [17280/60000 (29%)]\tLoss: 0.138551\n",
            "Train Epoch: 7 [17920/60000 (30%)]\tLoss: 0.055584\n",
            "Train Epoch: 7 [18560/60000 (31%)]\tLoss: 0.080258\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.080175\n",
            "Train Epoch: 7 [19840/60000 (33%)]\tLoss: 0.006693\n",
            "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 0.011398\n",
            "Train Epoch: 7 [21120/60000 (35%)]\tLoss: 0.006068\n",
            "Train Epoch: 7 [21760/60000 (36%)]\tLoss: 0.109485\n",
            "Train Epoch: 7 [22400/60000 (37%)]\tLoss: 0.081936\n",
            "Train Epoch: 7 [23040/60000 (38%)]\tLoss: 0.013695\n",
            "Train Epoch: 7 [23680/60000 (39%)]\tLoss: 0.051686\n",
            "Train Epoch: 7 [24320/60000 (41%)]\tLoss: 0.018361\n",
            "Train Epoch: 7 [24960/60000 (42%)]\tLoss: 0.149952\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.115079\n",
            "Train Epoch: 7 [26240/60000 (44%)]\tLoss: 0.045191\n",
            "Train Epoch: 7 [26880/60000 (45%)]\tLoss: 0.010931\n",
            "Train Epoch: 7 [27520/60000 (46%)]\tLoss: 0.092960\n",
            "Train Epoch: 7 [28160/60000 (47%)]\tLoss: 0.036138\n",
            "Train Epoch: 7 [28800/60000 (48%)]\tLoss: 0.007238\n",
            "Train Epoch: 7 [29440/60000 (49%)]\tLoss: 0.071235\n",
            "Train Epoch: 7 [30080/60000 (50%)]\tLoss: 0.003348\n",
            "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 0.098681\n",
            "Train Epoch: 7 [31360/60000 (52%)]\tLoss: 0.050985\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.013226\n",
            "Train Epoch: 7 [32640/60000 (54%)]\tLoss: 0.067497\n",
            "Train Epoch: 7 [33280/60000 (55%)]\tLoss: 0.132037\n",
            "Train Epoch: 7 [33920/60000 (57%)]\tLoss: 0.078016\n",
            "Train Epoch: 7 [34560/60000 (58%)]\tLoss: 0.153836\n",
            "Train Epoch: 7 [35200/60000 (59%)]\tLoss: 0.011112\n",
            "Train Epoch: 7 [35840/60000 (60%)]\tLoss: 0.014653\n",
            "Train Epoch: 7 [36480/60000 (61%)]\tLoss: 0.001687\n",
            "Train Epoch: 7 [37120/60000 (62%)]\tLoss: 0.141095\n",
            "Train Epoch: 7 [37760/60000 (63%)]\tLoss: 0.036087\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.068848\n",
            "Train Epoch: 7 [39040/60000 (65%)]\tLoss: 0.045139\n",
            "Train Epoch: 7 [39680/60000 (66%)]\tLoss: 0.113831\n",
            "Train Epoch: 7 [40320/60000 (67%)]\tLoss: 0.067342\n",
            "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 0.011539\n",
            "Train Epoch: 7 [41600/60000 (69%)]\tLoss: 0.031383\n",
            "Train Epoch: 7 [42240/60000 (70%)]\tLoss: 0.039184\n",
            "Train Epoch: 7 [42880/60000 (71%)]\tLoss: 0.031445\n",
            "Train Epoch: 7 [43520/60000 (72%)]\tLoss: 0.004229\n",
            "Train Epoch: 7 [44160/60000 (74%)]\tLoss: 0.206982\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.007353\n",
            "Train Epoch: 7 [45440/60000 (76%)]\tLoss: 0.006533\n",
            "Train Epoch: 7 [46080/60000 (77%)]\tLoss: 0.007420\n",
            "Train Epoch: 7 [46720/60000 (78%)]\tLoss: 0.083327\n",
            "Train Epoch: 7 [47360/60000 (79%)]\tLoss: 0.009744\n",
            "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.021690\n",
            "Train Epoch: 7 [48640/60000 (81%)]\tLoss: 0.017092\n",
            "Train Epoch: 7 [49280/60000 (82%)]\tLoss: 0.037790\n",
            "Train Epoch: 7 [49920/60000 (83%)]\tLoss: 0.074736\n",
            "Train Epoch: 7 [50560/60000 (84%)]\tLoss: 0.010240\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.141859\n",
            "Train Epoch: 7 [51840/60000 (86%)]\tLoss: 0.000961\n",
            "Train Epoch: 7 [52480/60000 (87%)]\tLoss: 0.127500\n",
            "Train Epoch: 7 [53120/60000 (88%)]\tLoss: 0.030624\n",
            "Train Epoch: 7 [53760/60000 (90%)]\tLoss: 0.072558\n",
            "Train Epoch: 7 [54400/60000 (91%)]\tLoss: 0.010918\n",
            "Train Epoch: 7 [55040/60000 (92%)]\tLoss: 0.021445\n",
            "Train Epoch: 7 [55680/60000 (93%)]\tLoss: 0.015639\n",
            "Train Epoch: 7 [56320/60000 (94%)]\tLoss: 0.138528\n",
            "Train Epoch: 7 [56960/60000 (95%)]\tLoss: 0.084742\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.055800\n",
            "Train Epoch: 7 [58240/60000 (97%)]\tLoss: 0.068294\n",
            "Train Epoch: 7 [58880/60000 (98%)]\tLoss: 0.044849\n",
            "Train Epoch: 7 [59520/60000 (99%)]\tLoss: 0.025929\n",
            "\n",
            "Test set: Average loss: 0.0194, Accuracy: 9949/10000 (99%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.027346\n",
            "Train Epoch: 8 [640/60000 (1%)]\tLoss: 0.030287\n",
            "Train Epoch: 8 [1280/60000 (2%)]\tLoss: 0.015721\n",
            "Train Epoch: 8 [1920/60000 (3%)]\tLoss: 0.000905\n",
            "Train Epoch: 8 [2560/60000 (4%)]\tLoss: 0.033249\n",
            "Train Epoch: 8 [3200/60000 (5%)]\tLoss: 0.025306\n",
            "Train Epoch: 8 [3840/60000 (6%)]\tLoss: 0.015547\n",
            "Train Epoch: 8 [4480/60000 (7%)]\tLoss: 0.015141\n",
            "Train Epoch: 8 [5120/60000 (9%)]\tLoss: 0.106075\n",
            "Train Epoch: 8 [5760/60000 (10%)]\tLoss: 0.042641\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.014526\n",
            "Train Epoch: 8 [7040/60000 (12%)]\tLoss: 0.120497\n",
            "Train Epoch: 8 [7680/60000 (13%)]\tLoss: 0.001006\n",
            "Train Epoch: 8 [8320/60000 (14%)]\tLoss: 0.087242\n",
            "Train Epoch: 8 [8960/60000 (15%)]\tLoss: 0.092020\n",
            "Train Epoch: 8 [9600/60000 (16%)]\tLoss: 0.003507\n",
            "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 0.158007\n",
            "Train Epoch: 8 [10880/60000 (18%)]\tLoss: 0.004266\n",
            "Train Epoch: 8 [11520/60000 (19%)]\tLoss: 0.135233\n",
            "Train Epoch: 8 [12160/60000 (20%)]\tLoss: 0.056328\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.001555\n",
            "Train Epoch: 8 [13440/60000 (22%)]\tLoss: 0.053369\n",
            "Train Epoch: 8 [14080/60000 (23%)]\tLoss: 0.081361\n",
            "Train Epoch: 8 [14720/60000 (25%)]\tLoss: 0.112861\n",
            "Train Epoch: 8 [15360/60000 (26%)]\tLoss: 0.070535\n",
            "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.045187\n",
            "Train Epoch: 8 [16640/60000 (28%)]\tLoss: 0.007414\n",
            "Train Epoch: 8 [17280/60000 (29%)]\tLoss: 0.010786\n",
            "Train Epoch: 8 [17920/60000 (30%)]\tLoss: 0.014502\n",
            "Train Epoch: 8 [18560/60000 (31%)]\tLoss: 0.090201\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.057560\n",
            "Train Epoch: 8 [19840/60000 (33%)]\tLoss: 0.019224\n",
            "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 0.038265\n",
            "Train Epoch: 8 [21120/60000 (35%)]\tLoss: 0.026143\n",
            "Train Epoch: 8 [21760/60000 (36%)]\tLoss: 0.080510\n",
            "Train Epoch: 8 [22400/60000 (37%)]\tLoss: 0.010872\n",
            "Train Epoch: 8 [23040/60000 (38%)]\tLoss: 0.005192\n",
            "Train Epoch: 8 [23680/60000 (39%)]\tLoss: 0.088463\n",
            "Train Epoch: 8 [24320/60000 (41%)]\tLoss: 0.004663\n",
            "Train Epoch: 8 [24960/60000 (42%)]\tLoss: 0.018127\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.109864\n",
            "Train Epoch: 8 [26240/60000 (44%)]\tLoss: 0.022415\n",
            "Train Epoch: 8 [26880/60000 (45%)]\tLoss: 0.043813\n",
            "Train Epoch: 8 [27520/60000 (46%)]\tLoss: 0.101618\n",
            "Train Epoch: 8 [28160/60000 (47%)]\tLoss: 0.122566\n",
            "Train Epoch: 8 [28800/60000 (48%)]\tLoss: 0.106525\n",
            "Train Epoch: 8 [29440/60000 (49%)]\tLoss: 0.085986\n",
            "Train Epoch: 8 [30080/60000 (50%)]\tLoss: 0.021659\n",
            "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 0.070348\n",
            "Train Epoch: 8 [31360/60000 (52%)]\tLoss: 0.032375\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.058264\n",
            "Train Epoch: 8 [32640/60000 (54%)]\tLoss: 0.000977\n",
            "Train Epoch: 8 [33280/60000 (55%)]\tLoss: 0.048627\n",
            "Train Epoch: 8 [33920/60000 (57%)]\tLoss: 0.236458\n",
            "Train Epoch: 8 [34560/60000 (58%)]\tLoss: 0.008258\n",
            "Train Epoch: 8 [35200/60000 (59%)]\tLoss: 0.008214\n",
            "Train Epoch: 8 [35840/60000 (60%)]\tLoss: 0.005722\n",
            "Train Epoch: 8 [36480/60000 (61%)]\tLoss: 0.011942\n",
            "Train Epoch: 8 [37120/60000 (62%)]\tLoss: 0.019402\n",
            "Train Epoch: 8 [37760/60000 (63%)]\tLoss: 0.059278\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.068111\n",
            "Train Epoch: 8 [39040/60000 (65%)]\tLoss: 0.002890\n",
            "Train Epoch: 8 [39680/60000 (66%)]\tLoss: 0.002795\n",
            "Train Epoch: 8 [40320/60000 (67%)]\tLoss: 0.051238\n",
            "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 0.060781\n",
            "Train Epoch: 8 [41600/60000 (69%)]\tLoss: 0.032104\n",
            "Train Epoch: 8 [42240/60000 (70%)]\tLoss: 0.004259\n",
            "Train Epoch: 8 [42880/60000 (71%)]\tLoss: 0.063164\n",
            "Train Epoch: 8 [43520/60000 (72%)]\tLoss: 0.089370\n",
            "Train Epoch: 8 [44160/60000 (74%)]\tLoss: 0.133844\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.097568\n",
            "Train Epoch: 8 [45440/60000 (76%)]\tLoss: 0.037216\n",
            "Train Epoch: 8 [46080/60000 (77%)]\tLoss: 0.246061\n",
            "Train Epoch: 8 [46720/60000 (78%)]\tLoss: 0.003044\n",
            "Train Epoch: 8 [47360/60000 (79%)]\tLoss: 0.127782\n",
            "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.050303\n",
            "Train Epoch: 8 [48640/60000 (81%)]\tLoss: 0.272463\n",
            "Train Epoch: 8 [49280/60000 (82%)]\tLoss: 0.206875\n",
            "Train Epoch: 8 [49920/60000 (83%)]\tLoss: 0.138155\n",
            "Train Epoch: 8 [50560/60000 (84%)]\tLoss: 0.014238\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.061086\n",
            "Train Epoch: 8 [51840/60000 (86%)]\tLoss: 0.056346\n",
            "Train Epoch: 8 [52480/60000 (87%)]\tLoss: 0.078504\n",
            "Train Epoch: 8 [53120/60000 (88%)]\tLoss: 0.010179\n",
            "Train Epoch: 8 [53760/60000 (90%)]\tLoss: 0.046697\n",
            "Train Epoch: 8 [54400/60000 (91%)]\tLoss: 0.090897\n",
            "Train Epoch: 8 [55040/60000 (92%)]\tLoss: 0.012918\n",
            "Train Epoch: 8 [55680/60000 (93%)]\tLoss: 0.039595\n",
            "Train Epoch: 8 [56320/60000 (94%)]\tLoss: 0.033982\n",
            "Train Epoch: 8 [56960/60000 (95%)]\tLoss: 0.074422\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.235133\n",
            "Train Epoch: 8 [58240/60000 (97%)]\tLoss: 0.009673\n",
            "Train Epoch: 8 [58880/60000 (98%)]\tLoss: 0.009474\n",
            "Train Epoch: 8 [59520/60000 (99%)]\tLoss: 0.034776\n",
            "\n",
            "Test set: Average loss: 0.0177, Accuracy: 9943/10000 (99%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.073783\n",
            "Train Epoch: 9 [640/60000 (1%)]\tLoss: 0.029191\n",
            "Train Epoch: 9 [1280/60000 (2%)]\tLoss: 0.126702\n",
            "Train Epoch: 9 [1920/60000 (3%)]\tLoss: 0.345468\n",
            "Train Epoch: 9 [2560/60000 (4%)]\tLoss: 0.019830\n",
            "Train Epoch: 9 [3200/60000 (5%)]\tLoss: 0.090645\n",
            "Train Epoch: 9 [3840/60000 (6%)]\tLoss: 0.146287\n",
            "Train Epoch: 9 [4480/60000 (7%)]\tLoss: 0.001569\n",
            "Train Epoch: 9 [5120/60000 (9%)]\tLoss: 0.007294\n",
            "Train Epoch: 9 [5760/60000 (10%)]\tLoss: 0.311458\n",
            "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.049000\n",
            "Train Epoch: 9 [7040/60000 (12%)]\tLoss: 0.002120\n",
            "Train Epoch: 9 [7680/60000 (13%)]\tLoss: 0.005933\n",
            "Train Epoch: 9 [8320/60000 (14%)]\tLoss: 0.001441\n",
            "Train Epoch: 9 [8960/60000 (15%)]\tLoss: 0.077675\n",
            "Train Epoch: 9 [9600/60000 (16%)]\tLoss: 0.002650\n",
            "Train Epoch: 9 [10240/60000 (17%)]\tLoss: 0.042846\n",
            "Train Epoch: 9 [10880/60000 (18%)]\tLoss: 0.086346\n",
            "Train Epoch: 9 [11520/60000 (19%)]\tLoss: 0.111491\n",
            "Train Epoch: 9 [12160/60000 (20%)]\tLoss: 0.054222\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.059462\n",
            "Train Epoch: 9 [13440/60000 (22%)]\tLoss: 0.042374\n",
            "Train Epoch: 9 [14080/60000 (23%)]\tLoss: 0.150328\n",
            "Train Epoch: 9 [14720/60000 (25%)]\tLoss: 0.130868\n",
            "Train Epoch: 9 [15360/60000 (26%)]\tLoss: 0.006224\n",
            "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 0.011343\n",
            "Train Epoch: 9 [16640/60000 (28%)]\tLoss: 0.007516\n",
            "Train Epoch: 9 [17280/60000 (29%)]\tLoss: 0.012972\n",
            "Train Epoch: 9 [17920/60000 (30%)]\tLoss: 0.038113\n",
            "Train Epoch: 9 [18560/60000 (31%)]\tLoss: 0.123822\n",
            "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.003737\n",
            "Train Epoch: 9 [19840/60000 (33%)]\tLoss: 0.066053\n",
            "Train Epoch: 9 [20480/60000 (34%)]\tLoss: 0.027701\n",
            "Train Epoch: 9 [21120/60000 (35%)]\tLoss: 0.035579\n",
            "Train Epoch: 9 [21760/60000 (36%)]\tLoss: 0.080857\n",
            "Train Epoch: 9 [22400/60000 (37%)]\tLoss: 0.095034\n",
            "Train Epoch: 9 [23040/60000 (38%)]\tLoss: 0.101014\n",
            "Train Epoch: 9 [23680/60000 (39%)]\tLoss: 0.108534\n",
            "Train Epoch: 9 [24320/60000 (41%)]\tLoss: 0.044171\n",
            "Train Epoch: 9 [24960/60000 (42%)]\tLoss: 0.129813\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.037183\n",
            "Train Epoch: 9 [26240/60000 (44%)]\tLoss: 0.034084\n",
            "Train Epoch: 9 [26880/60000 (45%)]\tLoss: 0.015854\n",
            "Train Epoch: 9 [27520/60000 (46%)]\tLoss: 0.110780\n",
            "Train Epoch: 9 [28160/60000 (47%)]\tLoss: 0.018025\n",
            "Train Epoch: 9 [28800/60000 (48%)]\tLoss: 0.031824\n",
            "Train Epoch: 9 [29440/60000 (49%)]\tLoss: 0.001343\n",
            "Train Epoch: 9 [30080/60000 (50%)]\tLoss: 0.066354\n",
            "Train Epoch: 9 [30720/60000 (51%)]\tLoss: 0.026088\n",
            "Train Epoch: 9 [31360/60000 (52%)]\tLoss: 0.014497\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.062846\n",
            "Train Epoch: 9 [32640/60000 (54%)]\tLoss: 0.073285\n",
            "Train Epoch: 9 [33280/60000 (55%)]\tLoss: 0.046105\n",
            "Train Epoch: 9 [33920/60000 (57%)]\tLoss: 0.030081\n",
            "Train Epoch: 9 [34560/60000 (58%)]\tLoss: 0.088679\n",
            "Train Epoch: 9 [35200/60000 (59%)]\tLoss: 0.002996\n",
            "Train Epoch: 9 [35840/60000 (60%)]\tLoss: 0.115509\n",
            "Train Epoch: 9 [36480/60000 (61%)]\tLoss: 0.209442\n",
            "Train Epoch: 9 [37120/60000 (62%)]\tLoss: 0.004330\n",
            "Train Epoch: 9 [37760/60000 (63%)]\tLoss: 0.022938\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.093580\n",
            "Train Epoch: 9 [39040/60000 (65%)]\tLoss: 0.005933\n",
            "Train Epoch: 9 [39680/60000 (66%)]\tLoss: 0.002869\n",
            "Train Epoch: 9 [40320/60000 (67%)]\tLoss: 0.003259\n",
            "Train Epoch: 9 [40960/60000 (68%)]\tLoss: 0.020128\n",
            "Train Epoch: 9 [41600/60000 (69%)]\tLoss: 0.012846\n",
            "Train Epoch: 9 [42240/60000 (70%)]\tLoss: 0.036865\n",
            "Train Epoch: 9 [42880/60000 (71%)]\tLoss: 0.064478\n",
            "Train Epoch: 9 [43520/60000 (72%)]\tLoss: 0.000761\n",
            "Train Epoch: 9 [44160/60000 (74%)]\tLoss: 0.004586\n",
            "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.106283\n",
            "Train Epoch: 9 [45440/60000 (76%)]\tLoss: 0.104202\n",
            "Train Epoch: 9 [46080/60000 (77%)]\tLoss: 0.007270\n",
            "Train Epoch: 9 [46720/60000 (78%)]\tLoss: 0.036853\n",
            "Train Epoch: 9 [47360/60000 (79%)]\tLoss: 0.124225\n",
            "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.028628\n",
            "Train Epoch: 9 [48640/60000 (81%)]\tLoss: 0.074456\n",
            "Train Epoch: 9 [49280/60000 (82%)]\tLoss: 0.143341\n",
            "Train Epoch: 9 [49920/60000 (83%)]\tLoss: 0.020158\n",
            "Train Epoch: 9 [50560/60000 (84%)]\tLoss: 0.030627\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.019296\n",
            "Train Epoch: 9 [51840/60000 (86%)]\tLoss: 0.108868\n",
            "Train Epoch: 9 [52480/60000 (87%)]\tLoss: 0.058594\n",
            "Train Epoch: 9 [53120/60000 (88%)]\tLoss: 0.022142\n",
            "Train Epoch: 9 [53760/60000 (90%)]\tLoss: 0.020595\n",
            "Train Epoch: 9 [54400/60000 (91%)]\tLoss: 0.014178\n",
            "Train Epoch: 9 [55040/60000 (92%)]\tLoss: 0.043389\n",
            "Train Epoch: 9 [55680/60000 (93%)]\tLoss: 0.025498\n",
            "Train Epoch: 9 [56320/60000 (94%)]\tLoss: 0.045018\n",
            "Train Epoch: 9 [56960/60000 (95%)]\tLoss: 0.003692\n",
            "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.053588\n",
            "Train Epoch: 9 [58240/60000 (97%)]\tLoss: 0.016597\n",
            "Train Epoch: 9 [58880/60000 (98%)]\tLoss: 0.136079\n",
            "Train Epoch: 9 [59520/60000 (99%)]\tLoss: 0.026789\n",
            "\n",
            "Test set: Average loss: 0.0146, Accuracy: 9953/10000 (100%)\n",
            "\n",
            "Model saved with new best test loss: 0.0146 \n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.007360\n",
            "Train Epoch: 10 [640/60000 (1%)]\tLoss: 0.030353\n",
            "Train Epoch: 10 [1280/60000 (2%)]\tLoss: 0.011086\n",
            "Train Epoch: 10 [1920/60000 (3%)]\tLoss: 0.179648\n",
            "Train Epoch: 10 [2560/60000 (4%)]\tLoss: 0.037377\n",
            "Train Epoch: 10 [3200/60000 (5%)]\tLoss: 0.021588\n",
            "Train Epoch: 10 [3840/60000 (6%)]\tLoss: 0.095871\n",
            "Train Epoch: 10 [4480/60000 (7%)]\tLoss: 0.047975\n",
            "Train Epoch: 10 [5120/60000 (9%)]\tLoss: 0.013313\n",
            "Train Epoch: 10 [5760/60000 (10%)]\tLoss: 0.290659\n",
            "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.137126\n",
            "Train Epoch: 10 [7040/60000 (12%)]\tLoss: 0.055981\n",
            "Train Epoch: 10 [7680/60000 (13%)]\tLoss: 0.025620\n",
            "Train Epoch: 10 [8320/60000 (14%)]\tLoss: 0.000963\n",
            "Train Epoch: 10 [8960/60000 (15%)]\tLoss: 0.008239\n",
            "Train Epoch: 10 [9600/60000 (16%)]\tLoss: 0.154816\n",
            "Train Epoch: 10 [10240/60000 (17%)]\tLoss: 0.005797\n",
            "Train Epoch: 10 [10880/60000 (18%)]\tLoss: 0.001402\n",
            "Train Epoch: 10 [11520/60000 (19%)]\tLoss: 0.222250\n",
            "Train Epoch: 10 [12160/60000 (20%)]\tLoss: 0.073836\n",
            "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.003550\n",
            "Train Epoch: 10 [13440/60000 (22%)]\tLoss: 0.009690\n",
            "Train Epoch: 10 [14080/60000 (23%)]\tLoss: 0.048436\n",
            "Train Epoch: 10 [14720/60000 (25%)]\tLoss: 0.089763\n",
            "Train Epoch: 10 [15360/60000 (26%)]\tLoss: 0.025814\n",
            "Train Epoch: 10 [16000/60000 (27%)]\tLoss: 0.001474\n",
            "Train Epoch: 10 [16640/60000 (28%)]\tLoss: 0.005594\n",
            "Train Epoch: 10 [17280/60000 (29%)]\tLoss: 0.008343\n",
            "Train Epoch: 10 [17920/60000 (30%)]\tLoss: 0.075015\n",
            "Train Epoch: 10 [18560/60000 (31%)]\tLoss: 0.033848\n",
            "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.015912\n",
            "Train Epoch: 10 [19840/60000 (33%)]\tLoss: 0.026350\n",
            "Train Epoch: 10 [20480/60000 (34%)]\tLoss: 0.032776\n",
            "Train Epoch: 10 [21120/60000 (35%)]\tLoss: 0.024493\n",
            "Train Epoch: 10 [21760/60000 (36%)]\tLoss: 0.006824\n",
            "Train Epoch: 10 [22400/60000 (37%)]\tLoss: 0.016596\n",
            "Train Epoch: 10 [23040/60000 (38%)]\tLoss: 0.020541\n",
            "Train Epoch: 10 [23680/60000 (39%)]\tLoss: 0.085608\n",
            "Train Epoch: 10 [24320/60000 (41%)]\tLoss: 0.050418\n",
            "Train Epoch: 10 [24960/60000 (42%)]\tLoss: 0.077947\n",
            "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.129721\n",
            "Train Epoch: 10 [26240/60000 (44%)]\tLoss: 0.009200\n",
            "Train Epoch: 10 [26880/60000 (45%)]\tLoss: 0.040817\n",
            "Train Epoch: 10 [27520/60000 (46%)]\tLoss: 0.027540\n",
            "Train Epoch: 10 [28160/60000 (47%)]\tLoss: 0.020708\n",
            "Train Epoch: 10 [28800/60000 (48%)]\tLoss: 0.015859\n",
            "Train Epoch: 10 [29440/60000 (49%)]\tLoss: 0.081601\n",
            "Train Epoch: 10 [30080/60000 (50%)]\tLoss: 0.092970\n",
            "Train Epoch: 10 [30720/60000 (51%)]\tLoss: 0.036177\n",
            "Train Epoch: 10 [31360/60000 (52%)]\tLoss: 0.094513\n",
            "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.035433\n",
            "Train Epoch: 10 [32640/60000 (54%)]\tLoss: 0.109970\n",
            "Train Epoch: 10 [33280/60000 (55%)]\tLoss: 0.010046\n",
            "Train Epoch: 10 [33920/60000 (57%)]\tLoss: 0.012675\n",
            "Train Epoch: 10 [34560/60000 (58%)]\tLoss: 0.091746\n",
            "Train Epoch: 10 [35200/60000 (59%)]\tLoss: 0.017826\n",
            "Train Epoch: 10 [35840/60000 (60%)]\tLoss: 0.073115\n",
            "Train Epoch: 10 [36480/60000 (61%)]\tLoss: 0.004694\n",
            "Train Epoch: 10 [37120/60000 (62%)]\tLoss: 0.015519\n",
            "Train Epoch: 10 [37760/60000 (63%)]\tLoss: 0.027148\n",
            "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.002474\n",
            "Train Epoch: 10 [39040/60000 (65%)]\tLoss: 0.004757\n",
            "Train Epoch: 10 [39680/60000 (66%)]\tLoss: 0.003959\n",
            "Train Epoch: 10 [40320/60000 (67%)]\tLoss: 0.105407\n",
            "Train Epoch: 10 [40960/60000 (68%)]\tLoss: 0.049126\n",
            "Train Epoch: 10 [41600/60000 (69%)]\tLoss: 0.116677\n",
            "Train Epoch: 10 [42240/60000 (70%)]\tLoss: 0.048023\n",
            "Train Epoch: 10 [42880/60000 (71%)]\tLoss: 0.156494\n",
            "Train Epoch: 10 [43520/60000 (72%)]\tLoss: 0.028440\n",
            "Train Epoch: 10 [44160/60000 (74%)]\tLoss: 0.070341\n",
            "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.034547\n",
            "Train Epoch: 10 [45440/60000 (76%)]\tLoss: 0.009566\n",
            "Train Epoch: 10 [46080/60000 (77%)]\tLoss: 0.003103\n",
            "Train Epoch: 10 [46720/60000 (78%)]\tLoss: 0.080175\n",
            "Train Epoch: 10 [47360/60000 (79%)]\tLoss: 0.093839\n",
            "Train Epoch: 10 [48000/60000 (80%)]\tLoss: 0.012584\n",
            "Train Epoch: 10 [48640/60000 (81%)]\tLoss: 0.028075\n",
            "Train Epoch: 10 [49280/60000 (82%)]\tLoss: 0.127205\n",
            "Train Epoch: 10 [49920/60000 (83%)]\tLoss: 0.011758\n",
            "Train Epoch: 10 [50560/60000 (84%)]\tLoss: 0.114468\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.012055\n",
            "Train Epoch: 10 [51840/60000 (86%)]\tLoss: 0.004745\n",
            "Train Epoch: 10 [52480/60000 (87%)]\tLoss: 0.005577\n",
            "Train Epoch: 10 [53120/60000 (88%)]\tLoss: 0.009116\n",
            "Train Epoch: 10 [53760/60000 (90%)]\tLoss: 0.073641\n",
            "Train Epoch: 10 [54400/60000 (91%)]\tLoss: 0.000465\n",
            "Train Epoch: 10 [55040/60000 (92%)]\tLoss: 0.018188\n",
            "Train Epoch: 10 [55680/60000 (93%)]\tLoss: 0.005270\n",
            "Train Epoch: 10 [56320/60000 (94%)]\tLoss: 0.002761\n",
            "Train Epoch: 10 [56960/60000 (95%)]\tLoss: 0.056398\n",
            "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.004241\n",
            "Train Epoch: 10 [58240/60000 (97%)]\tLoss: 0.046242\n",
            "Train Epoch: 10 [58880/60000 (98%)]\tLoss: 0.016148\n",
            "Train Epoch: 10 [59520/60000 (99%)]\tLoss: 0.034738\n",
            "\n",
            "Test set: Average loss: 0.0178, Accuracy: 9949/10000 (99%)\n",
            "\n",
            "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.014782\n",
            "Train Epoch: 11 [640/60000 (1%)]\tLoss: 0.034975\n",
            "Train Epoch: 11 [1280/60000 (2%)]\tLoss: 0.059642\n",
            "Train Epoch: 11 [1920/60000 (3%)]\tLoss: 0.008279\n",
            "Train Epoch: 11 [2560/60000 (4%)]\tLoss: 0.017341\n",
            "Train Epoch: 11 [3200/60000 (5%)]\tLoss: 0.029386\n",
            "Train Epoch: 11 [3840/60000 (6%)]\tLoss: 0.019905\n",
            "Train Epoch: 11 [4480/60000 (7%)]\tLoss: 0.036141\n",
            "Train Epoch: 11 [5120/60000 (9%)]\tLoss: 0.001780\n",
            "Train Epoch: 11 [5760/60000 (10%)]\tLoss: 0.018923\n",
            "Train Epoch: 11 [6400/60000 (11%)]\tLoss: 0.025848\n",
            "Train Epoch: 11 [7040/60000 (12%)]\tLoss: 0.005490\n",
            "Train Epoch: 11 [7680/60000 (13%)]\tLoss: 0.006143\n",
            "Train Epoch: 11 [8320/60000 (14%)]\tLoss: 0.007579\n",
            "Train Epoch: 11 [8960/60000 (15%)]\tLoss: 0.016824\n",
            "Train Epoch: 11 [9600/60000 (16%)]\tLoss: 0.058709\n",
            "Train Epoch: 11 [10240/60000 (17%)]\tLoss: 0.011090\n",
            "Train Epoch: 11 [10880/60000 (18%)]\tLoss: 0.002919\n",
            "Train Epoch: 11 [11520/60000 (19%)]\tLoss: 0.002725\n",
            "Train Epoch: 11 [12160/60000 (20%)]\tLoss: 0.039771\n",
            "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 0.002679\n",
            "Train Epoch: 11 [13440/60000 (22%)]\tLoss: 0.006626\n",
            "Train Epoch: 11 [14080/60000 (23%)]\tLoss: 0.072089\n",
            "Train Epoch: 11 [14720/60000 (25%)]\tLoss: 0.020544\n",
            "Train Epoch: 11 [15360/60000 (26%)]\tLoss: 0.058298\n",
            "Train Epoch: 11 [16000/60000 (27%)]\tLoss: 0.039595\n",
            "Train Epoch: 11 [16640/60000 (28%)]\tLoss: 0.029893\n",
            "Train Epoch: 11 [17280/60000 (29%)]\tLoss: 0.003122\n",
            "Train Epoch: 11 [17920/60000 (30%)]\tLoss: 0.066344\n",
            "Train Epoch: 11 [18560/60000 (31%)]\tLoss: 0.008216\n",
            "Train Epoch: 11 [19200/60000 (32%)]\tLoss: 0.030925\n",
            "Train Epoch: 11 [19840/60000 (33%)]\tLoss: 0.051779\n",
            "Train Epoch: 11 [20480/60000 (34%)]\tLoss: 0.058555\n",
            "Train Epoch: 11 [21120/60000 (35%)]\tLoss: 0.017982\n",
            "Train Epoch: 11 [21760/60000 (36%)]\tLoss: 0.024945\n",
            "Train Epoch: 11 [22400/60000 (37%)]\tLoss: 0.154277\n",
            "Train Epoch: 11 [23040/60000 (38%)]\tLoss: 0.098378\n",
            "Train Epoch: 11 [23680/60000 (39%)]\tLoss: 0.010128\n",
            "Train Epoch: 11 [24320/60000 (41%)]\tLoss: 0.066980\n",
            "Train Epoch: 11 [24960/60000 (42%)]\tLoss: 0.162123\n",
            "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.010835\n",
            "Train Epoch: 11 [26240/60000 (44%)]\tLoss: 0.002874\n",
            "Train Epoch: 11 [26880/60000 (45%)]\tLoss: 0.039190\n",
            "Train Epoch: 11 [27520/60000 (46%)]\tLoss: 0.016730\n",
            "Train Epoch: 11 [28160/60000 (47%)]\tLoss: 0.014246\n",
            "Train Epoch: 11 [28800/60000 (48%)]\tLoss: 0.010957\n",
            "Train Epoch: 11 [29440/60000 (49%)]\tLoss: 0.007254\n",
            "Train Epoch: 11 [30080/60000 (50%)]\tLoss: 0.000531\n",
            "Train Epoch: 11 [30720/60000 (51%)]\tLoss: 0.001824\n",
            "Train Epoch: 11 [31360/60000 (52%)]\tLoss: 0.082294\n",
            "Train Epoch: 11 [32000/60000 (53%)]\tLoss: 0.008616\n",
            "Train Epoch: 11 [32640/60000 (54%)]\tLoss: 0.010824\n",
            "Train Epoch: 11 [33280/60000 (55%)]\tLoss: 0.067196\n",
            "Train Epoch: 11 [33920/60000 (57%)]\tLoss: 0.013289\n",
            "Train Epoch: 11 [34560/60000 (58%)]\tLoss: 0.022445\n",
            "Train Epoch: 11 [35200/60000 (59%)]\tLoss: 0.011960\n",
            "Train Epoch: 11 [35840/60000 (60%)]\tLoss: 0.002162\n",
            "Train Epoch: 11 [36480/60000 (61%)]\tLoss: 0.031594\n",
            "Train Epoch: 11 [37120/60000 (62%)]\tLoss: 0.002587\n",
            "Train Epoch: 11 [37760/60000 (63%)]\tLoss: 0.004099\n",
            "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.006930\n",
            "Train Epoch: 11 [39040/60000 (65%)]\tLoss: 0.045806\n",
            "Train Epoch: 11 [39680/60000 (66%)]\tLoss: 0.008650\n",
            "Train Epoch: 11 [40320/60000 (67%)]\tLoss: 0.066110\n",
            "Train Epoch: 11 [40960/60000 (68%)]\tLoss: 0.032273\n",
            "Train Epoch: 11 [41600/60000 (69%)]\tLoss: 0.020675\n",
            "Train Epoch: 11 [42240/60000 (70%)]\tLoss: 0.007588\n",
            "Train Epoch: 11 [42880/60000 (71%)]\tLoss: 0.096761\n",
            "Train Epoch: 11 [43520/60000 (72%)]\tLoss: 0.012587\n",
            "Train Epoch: 11 [44160/60000 (74%)]\tLoss: 0.044762\n",
            "Train Epoch: 11 [44800/60000 (75%)]\tLoss: 0.023408\n",
            "Train Epoch: 11 [45440/60000 (76%)]\tLoss: 0.010391\n",
            "Train Epoch: 11 [46080/60000 (77%)]\tLoss: 0.029109\n",
            "Train Epoch: 11 [46720/60000 (78%)]\tLoss: 0.170403\n",
            "Train Epoch: 11 [47360/60000 (79%)]\tLoss: 0.055273\n",
            "Train Epoch: 11 [48000/60000 (80%)]\tLoss: 0.017719\n",
            "Train Epoch: 11 [48640/60000 (81%)]\tLoss: 0.025907\n",
            "Train Epoch: 11 [49280/60000 (82%)]\tLoss: 0.024911\n",
            "Train Epoch: 11 [49920/60000 (83%)]\tLoss: 0.011773\n",
            "Train Epoch: 11 [50560/60000 (84%)]\tLoss: 0.084696\n",
            "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.009310\n",
            "Train Epoch: 11 [51840/60000 (86%)]\tLoss: 0.028247\n",
            "Train Epoch: 11 [52480/60000 (87%)]\tLoss: 0.038398\n",
            "Train Epoch: 11 [53120/60000 (88%)]\tLoss: 0.039095\n",
            "Train Epoch: 11 [53760/60000 (90%)]\tLoss: 0.005560\n",
            "Train Epoch: 11 [54400/60000 (91%)]\tLoss: 0.027468\n",
            "Train Epoch: 11 [55040/60000 (92%)]\tLoss: 0.004560\n",
            "Train Epoch: 11 [55680/60000 (93%)]\tLoss: 0.024711\n",
            "Train Epoch: 11 [56320/60000 (94%)]\tLoss: 0.029430\n",
            "Train Epoch: 11 [56960/60000 (95%)]\tLoss: 0.077915\n",
            "Train Epoch: 11 [57600/60000 (96%)]\tLoss: 0.008556\n",
            "Train Epoch: 11 [58240/60000 (97%)]\tLoss: 0.020270\n",
            "Train Epoch: 11 [58880/60000 (98%)]\tLoss: 0.088933\n",
            "Train Epoch: 11 [59520/60000 (99%)]\tLoss: 0.009108\n",
            "\n",
            "Test set: Average loss: 0.0161, Accuracy: 9949/10000 (99%)\n",
            "\n",
            "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.007135\n",
            "Train Epoch: 12 [640/60000 (1%)]\tLoss: 0.019504\n",
            "Train Epoch: 12 [1280/60000 (2%)]\tLoss: 0.099372\n",
            "Train Epoch: 12 [1920/60000 (3%)]\tLoss: 0.034661\n",
            "Train Epoch: 12 [2560/60000 (4%)]\tLoss: 0.006054\n",
            "Train Epoch: 12 [3200/60000 (5%)]\tLoss: 0.180215\n",
            "Train Epoch: 12 [3840/60000 (6%)]\tLoss: 0.018238\n",
            "Train Epoch: 12 [4480/60000 (7%)]\tLoss: 0.027179\n",
            "Train Epoch: 12 [5120/60000 (9%)]\tLoss: 0.065101\n",
            "Train Epoch: 12 [5760/60000 (10%)]\tLoss: 0.015855\n",
            "Train Epoch: 12 [6400/60000 (11%)]\tLoss: 0.034103\n",
            "Train Epoch: 12 [7040/60000 (12%)]\tLoss: 0.048462\n",
            "Train Epoch: 12 [7680/60000 (13%)]\tLoss: 0.050517\n",
            "Train Epoch: 12 [8320/60000 (14%)]\tLoss: 0.030392\n",
            "Train Epoch: 12 [8960/60000 (15%)]\tLoss: 0.020387\n",
            "Train Epoch: 12 [9600/60000 (16%)]\tLoss: 0.023837\n",
            "Train Epoch: 12 [10240/60000 (17%)]\tLoss: 0.061340\n",
            "Train Epoch: 12 [10880/60000 (18%)]\tLoss: 0.009641\n",
            "Train Epoch: 12 [11520/60000 (19%)]\tLoss: 0.103410\n",
            "Train Epoch: 12 [12160/60000 (20%)]\tLoss: 0.020509\n",
            "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 0.021896\n",
            "Train Epoch: 12 [13440/60000 (22%)]\tLoss: 0.004152\n",
            "Train Epoch: 12 [14080/60000 (23%)]\tLoss: 0.073769\n",
            "Train Epoch: 12 [14720/60000 (25%)]\tLoss: 0.008687\n",
            "Train Epoch: 12 [15360/60000 (26%)]\tLoss: 0.089343\n",
            "Train Epoch: 12 [16000/60000 (27%)]\tLoss: 0.030474\n",
            "Train Epoch: 12 [16640/60000 (28%)]\tLoss: 0.052811\n",
            "Train Epoch: 12 [17280/60000 (29%)]\tLoss: 0.276262\n",
            "Train Epoch: 12 [17920/60000 (30%)]\tLoss: 0.012742\n",
            "Train Epoch: 12 [18560/60000 (31%)]\tLoss: 0.031105\n",
            "Train Epoch: 12 [19200/60000 (32%)]\tLoss: 0.060230\n",
            "Train Epoch: 12 [19840/60000 (33%)]\tLoss: 0.003768\n",
            "Train Epoch: 12 [20480/60000 (34%)]\tLoss: 0.047272\n",
            "Train Epoch: 12 [21120/60000 (35%)]\tLoss: 0.003464\n",
            "Train Epoch: 12 [21760/60000 (36%)]\tLoss: 0.138549\n",
            "Train Epoch: 12 [22400/60000 (37%)]\tLoss: 0.017299\n",
            "Train Epoch: 12 [23040/60000 (38%)]\tLoss: 0.003379\n",
            "Train Epoch: 12 [23680/60000 (39%)]\tLoss: 0.091502\n",
            "Train Epoch: 12 [24320/60000 (41%)]\tLoss: 0.039686\n",
            "Train Epoch: 12 [24960/60000 (42%)]\tLoss: 0.002601\n",
            "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 0.086162\n",
            "Train Epoch: 12 [26240/60000 (44%)]\tLoss: 0.024060\n",
            "Train Epoch: 12 [26880/60000 (45%)]\tLoss: 0.089617\n",
            "Train Epoch: 12 [27520/60000 (46%)]\tLoss: 0.019068\n",
            "Train Epoch: 12 [28160/60000 (47%)]\tLoss: 0.006945\n",
            "Train Epoch: 12 [28800/60000 (48%)]\tLoss: 0.064522\n",
            "Train Epoch: 12 [29440/60000 (49%)]\tLoss: 0.010748\n",
            "Train Epoch: 12 [30080/60000 (50%)]\tLoss: 0.061216\n",
            "Train Epoch: 12 [30720/60000 (51%)]\tLoss: 0.005133\n",
            "Train Epoch: 12 [31360/60000 (52%)]\tLoss: 0.011136\n",
            "Train Epoch: 12 [32000/60000 (53%)]\tLoss: 0.004701\n",
            "Train Epoch: 12 [32640/60000 (54%)]\tLoss: 0.031814\n",
            "Train Epoch: 12 [33280/60000 (55%)]\tLoss: 0.012669\n",
            "Train Epoch: 12 [33920/60000 (57%)]\tLoss: 0.026733\n",
            "Train Epoch: 12 [34560/60000 (58%)]\tLoss: 0.006479\n",
            "Train Epoch: 12 [35200/60000 (59%)]\tLoss: 0.170222\n",
            "Train Epoch: 12 [35840/60000 (60%)]\tLoss: 0.096866\n",
            "Train Epoch: 12 [36480/60000 (61%)]\tLoss: 0.240399\n",
            "Train Epoch: 12 [37120/60000 (62%)]\tLoss: 0.020993\n",
            "Train Epoch: 12 [37760/60000 (63%)]\tLoss: 0.016482\n",
            "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.003929\n",
            "Train Epoch: 12 [39040/60000 (65%)]\tLoss: 0.010293\n",
            "Train Epoch: 12 [39680/60000 (66%)]\tLoss: 0.036701\n",
            "Train Epoch: 12 [40320/60000 (67%)]\tLoss: 0.000379\n",
            "Train Epoch: 12 [40960/60000 (68%)]\tLoss: 0.012721\n",
            "Train Epoch: 12 [41600/60000 (69%)]\tLoss: 0.004287\n",
            "Train Epoch: 12 [42240/60000 (70%)]\tLoss: 0.001231\n",
            "Train Epoch: 12 [42880/60000 (71%)]\tLoss: 0.014356\n",
            "Train Epoch: 12 [43520/60000 (72%)]\tLoss: 0.001039\n",
            "Train Epoch: 12 [44160/60000 (74%)]\tLoss: 0.003466\n",
            "Train Epoch: 12 [44800/60000 (75%)]\tLoss: 0.009572\n",
            "Train Epoch: 12 [45440/60000 (76%)]\tLoss: 0.036914\n",
            "Train Epoch: 12 [46080/60000 (77%)]\tLoss: 0.028052\n",
            "Train Epoch: 12 [46720/60000 (78%)]\tLoss: 0.100489\n",
            "Train Epoch: 12 [47360/60000 (79%)]\tLoss: 0.084387\n",
            "Train Epoch: 12 [48000/60000 (80%)]\tLoss: 0.004759\n",
            "Train Epoch: 12 [48640/60000 (81%)]\tLoss: 0.047982\n",
            "Train Epoch: 12 [49280/60000 (82%)]\tLoss: 0.032028\n",
            "Train Epoch: 12 [49920/60000 (83%)]\tLoss: 0.154634\n",
            "Train Epoch: 12 [50560/60000 (84%)]\tLoss: 0.107883\n",
            "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.009325\n",
            "Train Epoch: 12 [51840/60000 (86%)]\tLoss: 0.008544\n",
            "Train Epoch: 12 [52480/60000 (87%)]\tLoss: 0.060799\n",
            "Train Epoch: 12 [53120/60000 (88%)]\tLoss: 0.007385\n",
            "Train Epoch: 12 [53760/60000 (90%)]\tLoss: 0.055090\n",
            "Train Epoch: 12 [54400/60000 (91%)]\tLoss: 0.006076\n",
            "Train Epoch: 12 [55040/60000 (92%)]\tLoss: 0.067395\n",
            "Train Epoch: 12 [55680/60000 (93%)]\tLoss: 0.097701\n",
            "Train Epoch: 12 [56320/60000 (94%)]\tLoss: 0.029455\n",
            "Train Epoch: 12 [56960/60000 (95%)]\tLoss: 0.009233\n",
            "Train Epoch: 12 [57600/60000 (96%)]\tLoss: 0.024503\n",
            "Train Epoch: 12 [58240/60000 (97%)]\tLoss: 0.146610\n",
            "Train Epoch: 12 [58880/60000 (98%)]\tLoss: 0.003182\n",
            "Train Epoch: 12 [59520/60000 (99%)]\tLoss: 0.044346\n",
            "\n",
            "Test set: Average loss: 0.0159, Accuracy: 9953/10000 (100%)\n",
            "\n",
            "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.000457\n",
            "Train Epoch: 13 [640/60000 (1%)]\tLoss: 0.057013\n",
            "Train Epoch: 13 [1280/60000 (2%)]\tLoss: 0.005057\n",
            "Train Epoch: 13 [1920/60000 (3%)]\tLoss: 0.037293\n",
            "Train Epoch: 13 [2560/60000 (4%)]\tLoss: 0.019895\n",
            "Train Epoch: 13 [3200/60000 (5%)]\tLoss: 0.007405\n",
            "Train Epoch: 13 [3840/60000 (6%)]\tLoss: 0.043901\n",
            "Train Epoch: 13 [4480/60000 (7%)]\tLoss: 0.022786\n",
            "Train Epoch: 13 [5120/60000 (9%)]\tLoss: 0.003391\n",
            "Train Epoch: 13 [5760/60000 (10%)]\tLoss: 0.009700\n",
            "Train Epoch: 13 [6400/60000 (11%)]\tLoss: 0.000727\n",
            "Train Epoch: 13 [7040/60000 (12%)]\tLoss: 0.007647\n",
            "Train Epoch: 13 [7680/60000 (13%)]\tLoss: 0.023472\n",
            "Train Epoch: 13 [8320/60000 (14%)]\tLoss: 0.103212\n",
            "Train Epoch: 13 [8960/60000 (15%)]\tLoss: 0.009486\n",
            "Train Epoch: 13 [9600/60000 (16%)]\tLoss: 0.014659\n",
            "Train Epoch: 13 [10240/60000 (17%)]\tLoss: 0.007879\n",
            "Train Epoch: 13 [10880/60000 (18%)]\tLoss: 0.085253\n",
            "Train Epoch: 13 [11520/60000 (19%)]\tLoss: 0.003860\n",
            "Train Epoch: 13 [12160/60000 (20%)]\tLoss: 0.001695\n",
            "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 0.007663\n",
            "Train Epoch: 13 [13440/60000 (22%)]\tLoss: 0.003501\n",
            "Train Epoch: 13 [14080/60000 (23%)]\tLoss: 0.012694\n",
            "Train Epoch: 13 [14720/60000 (25%)]\tLoss: 0.029659\n",
            "Train Epoch: 13 [15360/60000 (26%)]\tLoss: 0.012801\n",
            "Train Epoch: 13 [16000/60000 (27%)]\tLoss: 0.036188\n",
            "Train Epoch: 13 [16640/60000 (28%)]\tLoss: 0.000473\n",
            "Train Epoch: 13 [17280/60000 (29%)]\tLoss: 0.003333\n",
            "Train Epoch: 13 [17920/60000 (30%)]\tLoss: 0.045384\n",
            "Train Epoch: 13 [18560/60000 (31%)]\tLoss: 0.019528\n",
            "Train Epoch: 13 [19200/60000 (32%)]\tLoss: 0.014626\n",
            "Train Epoch: 13 [19840/60000 (33%)]\tLoss: 0.045562\n",
            "Train Epoch: 13 [20480/60000 (34%)]\tLoss: 0.040621\n",
            "Train Epoch: 13 [21120/60000 (35%)]\tLoss: 0.005647\n",
            "Train Epoch: 13 [21760/60000 (36%)]\tLoss: 0.028727\n",
            "Train Epoch: 13 [22400/60000 (37%)]\tLoss: 0.003338\n",
            "Train Epoch: 13 [23040/60000 (38%)]\tLoss: 0.008038\n",
            "Train Epoch: 13 [23680/60000 (39%)]\tLoss: 0.082108\n",
            "Train Epoch: 13 [24320/60000 (41%)]\tLoss: 0.010524\n",
            "Train Epoch: 13 [24960/60000 (42%)]\tLoss: 0.027792\n",
            "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 0.059773\n",
            "Train Epoch: 13 [26240/60000 (44%)]\tLoss: 0.015155\n",
            "Train Epoch: 13 [26880/60000 (45%)]\tLoss: 0.013797\n",
            "Train Epoch: 13 [27520/60000 (46%)]\tLoss: 0.117837\n",
            "Train Epoch: 13 [28160/60000 (47%)]\tLoss: 0.012016\n",
            "Train Epoch: 13 [28800/60000 (48%)]\tLoss: 0.075940\n",
            "Train Epoch: 13 [29440/60000 (49%)]\tLoss: 0.102731\n",
            "Train Epoch: 13 [30080/60000 (50%)]\tLoss: 0.035627\n",
            "Train Epoch: 13 [30720/60000 (51%)]\tLoss: 0.017712\n",
            "Train Epoch: 13 [31360/60000 (52%)]\tLoss: 0.002650\n",
            "Train Epoch: 13 [32000/60000 (53%)]\tLoss: 0.193206\n",
            "Train Epoch: 13 [32640/60000 (54%)]\tLoss: 0.012169\n",
            "Train Epoch: 13 [33280/60000 (55%)]\tLoss: 0.105624\n",
            "Train Epoch: 13 [33920/60000 (57%)]\tLoss: 0.082843\n",
            "Train Epoch: 13 [34560/60000 (58%)]\tLoss: 0.016643\n",
            "Train Epoch: 13 [35200/60000 (59%)]\tLoss: 0.105444\n",
            "Train Epoch: 13 [35840/60000 (60%)]\tLoss: 0.229822\n",
            "Train Epoch: 13 [36480/60000 (61%)]\tLoss: 0.042512\n",
            "Train Epoch: 13 [37120/60000 (62%)]\tLoss: 0.007993\n",
            "Train Epoch: 13 [37760/60000 (63%)]\tLoss: 0.018819\n",
            "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 0.017716\n",
            "Train Epoch: 13 [39040/60000 (65%)]\tLoss: 0.017930\n",
            "Train Epoch: 13 [39680/60000 (66%)]\tLoss: 0.000952\n",
            "Train Epoch: 13 [40320/60000 (67%)]\tLoss: 0.002116\n",
            "Train Epoch: 13 [40960/60000 (68%)]\tLoss: 0.158742\n",
            "Train Epoch: 13 [41600/60000 (69%)]\tLoss: 0.065273\n",
            "Train Epoch: 13 [42240/60000 (70%)]\tLoss: 0.032986\n",
            "Train Epoch: 13 [42880/60000 (71%)]\tLoss: 0.013635\n",
            "Train Epoch: 13 [43520/60000 (72%)]\tLoss: 0.057631\n",
            "Train Epoch: 13 [44160/60000 (74%)]\tLoss: 0.004734\n",
            "Train Epoch: 13 [44800/60000 (75%)]\tLoss: 0.027652\n",
            "Train Epoch: 13 [45440/60000 (76%)]\tLoss: 0.123719\n",
            "Train Epoch: 13 [46080/60000 (77%)]\tLoss: 0.059417\n",
            "Train Epoch: 13 [46720/60000 (78%)]\tLoss: 0.001245\n",
            "Train Epoch: 13 [47360/60000 (79%)]\tLoss: 0.022617\n",
            "Train Epoch: 13 [48000/60000 (80%)]\tLoss: 0.005812\n",
            "Train Epoch: 13 [48640/60000 (81%)]\tLoss: 0.017628\n",
            "Train Epoch: 13 [49280/60000 (82%)]\tLoss: 0.012001\n",
            "Train Epoch: 13 [49920/60000 (83%)]\tLoss: 0.055226\n",
            "Train Epoch: 13 [50560/60000 (84%)]\tLoss: 0.004137\n",
            "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.002527\n",
            "Train Epoch: 13 [51840/60000 (86%)]\tLoss: 0.008350\n",
            "Train Epoch: 13 [52480/60000 (87%)]\tLoss: 0.011686\n",
            "Train Epoch: 13 [53120/60000 (88%)]\tLoss: 0.049897\n",
            "Train Epoch: 13 [53760/60000 (90%)]\tLoss: 0.003767\n",
            "Train Epoch: 13 [54400/60000 (91%)]\tLoss: 0.101038\n",
            "Train Epoch: 13 [55040/60000 (92%)]\tLoss: 0.079834\n",
            "Train Epoch: 13 [55680/60000 (93%)]\tLoss: 0.007829\n",
            "Train Epoch: 13 [56320/60000 (94%)]\tLoss: 0.126464\n",
            "Train Epoch: 13 [56960/60000 (95%)]\tLoss: 0.071177\n",
            "Train Epoch: 13 [57600/60000 (96%)]\tLoss: 0.003885\n",
            "Train Epoch: 13 [58240/60000 (97%)]\tLoss: 0.007751\n",
            "Train Epoch: 13 [58880/60000 (98%)]\tLoss: 0.051661\n",
            "Train Epoch: 13 [59520/60000 (99%)]\tLoss: 0.080854\n",
            "\n",
            "Test set: Average loss: 0.0153, Accuracy: 9949/10000 (99%)\n",
            "\n",
            "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.017964\n",
            "Train Epoch: 14 [640/60000 (1%)]\tLoss: 0.026980\n",
            "Train Epoch: 14 [1280/60000 (2%)]\tLoss: 0.092279\n",
            "Train Epoch: 14 [1920/60000 (3%)]\tLoss: 0.032170\n",
            "Train Epoch: 14 [2560/60000 (4%)]\tLoss: 0.010365\n",
            "Train Epoch: 14 [3200/60000 (5%)]\tLoss: 0.009463\n",
            "Train Epoch: 14 [3840/60000 (6%)]\tLoss: 0.007014\n",
            "Train Epoch: 14 [4480/60000 (7%)]\tLoss: 0.000775\n",
            "Train Epoch: 14 [5120/60000 (9%)]\tLoss: 0.020867\n",
            "Train Epoch: 14 [5760/60000 (10%)]\tLoss: 0.067088\n",
            "Train Epoch: 14 [6400/60000 (11%)]\tLoss: 0.015755\n",
            "Train Epoch: 14 [7040/60000 (12%)]\tLoss: 0.235970\n",
            "Train Epoch: 14 [7680/60000 (13%)]\tLoss: 0.011249\n",
            "Train Epoch: 14 [8320/60000 (14%)]\tLoss: 0.001993\n",
            "Train Epoch: 14 [8960/60000 (15%)]\tLoss: 0.000224\n",
            "Train Epoch: 14 [9600/60000 (16%)]\tLoss: 0.024870\n",
            "Train Epoch: 14 [10240/60000 (17%)]\tLoss: 0.014707\n",
            "Train Epoch: 14 [10880/60000 (18%)]\tLoss: 0.120611\n",
            "Train Epoch: 14 [11520/60000 (19%)]\tLoss: 0.001162\n",
            "Train Epoch: 14 [12160/60000 (20%)]\tLoss: 0.029096\n",
            "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.011931\n",
            "Train Epoch: 14 [13440/60000 (22%)]\tLoss: 0.042503\n",
            "Train Epoch: 14 [14080/60000 (23%)]\tLoss: 0.074115\n",
            "Train Epoch: 14 [14720/60000 (25%)]\tLoss: 0.033033\n",
            "Train Epoch: 14 [15360/60000 (26%)]\tLoss: 0.004767\n",
            "Train Epoch: 14 [16000/60000 (27%)]\tLoss: 0.109398\n",
            "Train Epoch: 14 [16640/60000 (28%)]\tLoss: 0.000973\n",
            "Train Epoch: 14 [17280/60000 (29%)]\tLoss: 0.006992\n",
            "Train Epoch: 14 [17920/60000 (30%)]\tLoss: 0.001138\n",
            "Train Epoch: 14 [18560/60000 (31%)]\tLoss: 0.054395\n",
            "Train Epoch: 14 [19200/60000 (32%)]\tLoss: 0.180853\n",
            "Train Epoch: 14 [19840/60000 (33%)]\tLoss: 0.063195\n",
            "Train Epoch: 14 [20480/60000 (34%)]\tLoss: 0.017316\n",
            "Train Epoch: 14 [21120/60000 (35%)]\tLoss: 0.154741\n",
            "Train Epoch: 14 [21760/60000 (36%)]\tLoss: 0.014693\n",
            "Train Epoch: 14 [22400/60000 (37%)]\tLoss: 0.020634\n",
            "Train Epoch: 14 [23040/60000 (38%)]\tLoss: 0.152496\n",
            "Train Epoch: 14 [23680/60000 (39%)]\tLoss: 0.006107\n",
            "Train Epoch: 14 [24320/60000 (41%)]\tLoss: 0.060388\n",
            "Train Epoch: 14 [24960/60000 (42%)]\tLoss: 0.066993\n",
            "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.003774\n",
            "Train Epoch: 14 [26240/60000 (44%)]\tLoss: 0.006277\n",
            "Train Epoch: 14 [26880/60000 (45%)]\tLoss: 0.008684\n",
            "Train Epoch: 14 [27520/60000 (46%)]\tLoss: 0.069024\n",
            "Train Epoch: 14 [28160/60000 (47%)]\tLoss: 0.067389\n",
            "Train Epoch: 14 [28800/60000 (48%)]\tLoss: 0.001549\n",
            "Train Epoch: 14 [29440/60000 (49%)]\tLoss: 0.012684\n",
            "Train Epoch: 14 [30080/60000 (50%)]\tLoss: 0.034273\n",
            "Train Epoch: 14 [30720/60000 (51%)]\tLoss: 0.176289\n",
            "Train Epoch: 14 [31360/60000 (52%)]\tLoss: 0.030313\n",
            "Train Epoch: 14 [32000/60000 (53%)]\tLoss: 0.007064\n",
            "Train Epoch: 14 [32640/60000 (54%)]\tLoss: 0.001323\n",
            "Train Epoch: 14 [33280/60000 (55%)]\tLoss: 0.132076\n",
            "Train Epoch: 14 [33920/60000 (57%)]\tLoss: 0.141265\n",
            "Train Epoch: 14 [34560/60000 (58%)]\tLoss: 0.002611\n",
            "Train Epoch: 14 [35200/60000 (59%)]\tLoss: 0.082924\n",
            "Train Epoch: 14 [35840/60000 (60%)]\tLoss: 0.002248\n",
            "Train Epoch: 14 [36480/60000 (61%)]\tLoss: 0.001273\n",
            "Train Epoch: 14 [37120/60000 (62%)]\tLoss: 0.000181\n",
            "Train Epoch: 14 [37760/60000 (63%)]\tLoss: 0.000409\n",
            "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.018380\n",
            "Train Epoch: 14 [39040/60000 (65%)]\tLoss: 0.070517\n",
            "Train Epoch: 14 [39680/60000 (66%)]\tLoss: 0.002097\n",
            "Train Epoch: 14 [40320/60000 (67%)]\tLoss: 0.033230\n",
            "Train Epoch: 14 [40960/60000 (68%)]\tLoss: 0.018399\n",
            "Train Epoch: 14 [41600/60000 (69%)]\tLoss: 0.007102\n",
            "Train Epoch: 14 [42240/60000 (70%)]\tLoss: 0.056886\n",
            "Train Epoch: 14 [42880/60000 (71%)]\tLoss: 0.017710\n",
            "Train Epoch: 14 [43520/60000 (72%)]\tLoss: 0.001042\n",
            "Train Epoch: 14 [44160/60000 (74%)]\tLoss: 0.156172\n",
            "Train Epoch: 14 [44800/60000 (75%)]\tLoss: 0.000802\n",
            "Train Epoch: 14 [45440/60000 (76%)]\tLoss: 0.071848\n",
            "Train Epoch: 14 [46080/60000 (77%)]\tLoss: 0.065588\n",
            "Train Epoch: 14 [46720/60000 (78%)]\tLoss: 0.050847\n",
            "Train Epoch: 14 [47360/60000 (79%)]\tLoss: 0.000535\n",
            "Train Epoch: 14 [48000/60000 (80%)]\tLoss: 0.009056\n",
            "Train Epoch: 14 [48640/60000 (81%)]\tLoss: 0.100640\n",
            "Train Epoch: 14 [49280/60000 (82%)]\tLoss: 0.020217\n",
            "Train Epoch: 14 [49920/60000 (83%)]\tLoss: 0.036622\n",
            "Train Epoch: 14 [50560/60000 (84%)]\tLoss: 0.276518\n",
            "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.061550\n",
            "Train Epoch: 14 [51840/60000 (86%)]\tLoss: 0.075361\n",
            "Train Epoch: 14 [52480/60000 (87%)]\tLoss: 0.002240\n",
            "Train Epoch: 14 [53120/60000 (88%)]\tLoss: 0.128556\n",
            "Train Epoch: 14 [53760/60000 (90%)]\tLoss: 0.001736\n",
            "Train Epoch: 14 [54400/60000 (91%)]\tLoss: 0.041383\n",
            "Train Epoch: 14 [55040/60000 (92%)]\tLoss: 0.001761\n",
            "Train Epoch: 14 [55680/60000 (93%)]\tLoss: 0.006852\n",
            "Train Epoch: 14 [56320/60000 (94%)]\tLoss: 0.004528\n",
            "Train Epoch: 14 [56960/60000 (95%)]\tLoss: 0.052563\n",
            "Train Epoch: 14 [57600/60000 (96%)]\tLoss: 0.001462\n",
            "Train Epoch: 14 [58240/60000 (97%)]\tLoss: 0.005477\n",
            "Train Epoch: 14 [58880/60000 (98%)]\tLoss: 0.014835\n",
            "Train Epoch: 14 [59520/60000 (99%)]\tLoss: 0.005374\n",
            "\n",
            "Test set: Average loss: 0.0149, Accuracy: 9956/10000 (100%)\n",
            "\n",
            "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.027648\n",
            "Train Epoch: 15 [640/60000 (1%)]\tLoss: 0.132594\n",
            "Train Epoch: 15 [1280/60000 (2%)]\tLoss: 0.049240\n",
            "Train Epoch: 15 [1920/60000 (3%)]\tLoss: 0.040207\n",
            "Train Epoch: 15 [2560/60000 (4%)]\tLoss: 0.028427\n",
            "Train Epoch: 15 [3200/60000 (5%)]\tLoss: 0.039067\n",
            "Train Epoch: 15 [3840/60000 (6%)]\tLoss: 0.009969\n",
            "Train Epoch: 15 [4480/60000 (7%)]\tLoss: 0.003217\n",
            "Train Epoch: 15 [5120/60000 (9%)]\tLoss: 0.007644\n",
            "Train Epoch: 15 [5760/60000 (10%)]\tLoss: 0.039389\n",
            "Train Epoch: 15 [6400/60000 (11%)]\tLoss: 0.034955\n",
            "Train Epoch: 15 [7040/60000 (12%)]\tLoss: 0.014280\n",
            "Train Epoch: 15 [7680/60000 (13%)]\tLoss: 0.000763\n",
            "Train Epoch: 15 [8320/60000 (14%)]\tLoss: 0.025219\n",
            "Train Epoch: 15 [8960/60000 (15%)]\tLoss: 0.030809\n",
            "Train Epoch: 15 [9600/60000 (16%)]\tLoss: 0.058344\n",
            "Train Epoch: 15 [10240/60000 (17%)]\tLoss: 0.003941\n",
            "Train Epoch: 15 [10880/60000 (18%)]\tLoss: 0.015097\n",
            "Train Epoch: 15 [11520/60000 (19%)]\tLoss: 0.041372\n",
            "Train Epoch: 15 [12160/60000 (20%)]\tLoss: 0.036957\n",
            "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 0.044838\n",
            "Train Epoch: 15 [13440/60000 (22%)]\tLoss: 0.010979\n",
            "Train Epoch: 15 [14080/60000 (23%)]\tLoss: 0.048579\n",
            "Train Epoch: 15 [14720/60000 (25%)]\tLoss: 0.001356\n",
            "Train Epoch: 15 [15360/60000 (26%)]\tLoss: 0.001883\n",
            "Train Epoch: 15 [16000/60000 (27%)]\tLoss: 0.009438\n",
            "Train Epoch: 15 [16640/60000 (28%)]\tLoss: 0.049190\n",
            "Train Epoch: 15 [17280/60000 (29%)]\tLoss: 0.002754\n",
            "Train Epoch: 15 [17920/60000 (30%)]\tLoss: 0.171173\n",
            "Train Epoch: 15 [18560/60000 (31%)]\tLoss: 0.027368\n",
            "Train Epoch: 15 [19200/60000 (32%)]\tLoss: 0.000938\n",
            "Train Epoch: 15 [19840/60000 (33%)]\tLoss: 0.077294\n",
            "Train Epoch: 15 [20480/60000 (34%)]\tLoss: 0.010180\n",
            "Train Epoch: 15 [21120/60000 (35%)]\tLoss: 0.034125\n",
            "Train Epoch: 15 [21760/60000 (36%)]\tLoss: 0.011720\n",
            "Train Epoch: 15 [22400/60000 (37%)]\tLoss: 0.007327\n",
            "Train Epoch: 15 [23040/60000 (38%)]\tLoss: 0.044193\n",
            "Train Epoch: 15 [23680/60000 (39%)]\tLoss: 0.016178\n",
            "Train Epoch: 15 [24320/60000 (41%)]\tLoss: 0.009209\n",
            "Train Epoch: 15 [24960/60000 (42%)]\tLoss: 0.001183\n",
            "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 0.157877\n",
            "Train Epoch: 15 [26240/60000 (44%)]\tLoss: 0.064288\n",
            "Train Epoch: 15 [26880/60000 (45%)]\tLoss: 0.002154\n",
            "Train Epoch: 15 [27520/60000 (46%)]\tLoss: 0.003712\n",
            "Train Epoch: 15 [28160/60000 (47%)]\tLoss: 0.002171\n",
            "Train Epoch: 15 [28800/60000 (48%)]\tLoss: 0.306458\n",
            "Train Epoch: 15 [29440/60000 (49%)]\tLoss: 0.252202\n",
            "Train Epoch: 15 [30080/60000 (50%)]\tLoss: 0.004302\n",
            "Train Epoch: 15 [30720/60000 (51%)]\tLoss: 0.019128\n",
            "Train Epoch: 15 [31360/60000 (52%)]\tLoss: 0.027591\n",
            "Train Epoch: 15 [32000/60000 (53%)]\tLoss: 0.017428\n",
            "Train Epoch: 15 [32640/60000 (54%)]\tLoss: 0.000834\n",
            "Train Epoch: 15 [33280/60000 (55%)]\tLoss: 0.001642\n",
            "Train Epoch: 15 [33920/60000 (57%)]\tLoss: 0.011856\n",
            "Train Epoch: 15 [34560/60000 (58%)]\tLoss: 0.007659\n",
            "Train Epoch: 15 [35200/60000 (59%)]\tLoss: 0.067804\n",
            "Train Epoch: 15 [35840/60000 (60%)]\tLoss: 0.096368\n",
            "Train Epoch: 15 [36480/60000 (61%)]\tLoss: 0.079497\n",
            "Train Epoch: 15 [37120/60000 (62%)]\tLoss: 0.006291\n",
            "Train Epoch: 15 [37760/60000 (63%)]\tLoss: 0.094786\n",
            "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 0.008791\n",
            "Train Epoch: 15 [39040/60000 (65%)]\tLoss: 0.009768\n",
            "Train Epoch: 15 [39680/60000 (66%)]\tLoss: 0.027840\n",
            "Train Epoch: 15 [40320/60000 (67%)]\tLoss: 0.078298\n",
            "Train Epoch: 15 [40960/60000 (68%)]\tLoss: 0.037665\n",
            "Train Epoch: 15 [41600/60000 (69%)]\tLoss: 0.007945\n",
            "Train Epoch: 15 [42240/60000 (70%)]\tLoss: 0.092037\n",
            "Train Epoch: 15 [42880/60000 (71%)]\tLoss: 0.013653\n",
            "Train Epoch: 15 [43520/60000 (72%)]\tLoss: 0.028668\n",
            "Train Epoch: 15 [44160/60000 (74%)]\tLoss: 0.173665\n",
            "Train Epoch: 15 [44800/60000 (75%)]\tLoss: 0.022895\n",
            "Train Epoch: 15 [45440/60000 (76%)]\tLoss: 0.009821\n",
            "Train Epoch: 15 [46080/60000 (77%)]\tLoss: 0.011593\n",
            "Train Epoch: 15 [46720/60000 (78%)]\tLoss: 0.085891\n",
            "Train Epoch: 15 [47360/60000 (79%)]\tLoss: 0.005742\n",
            "Train Epoch: 15 [48000/60000 (80%)]\tLoss: 0.030675\n",
            "Train Epoch: 15 [48640/60000 (81%)]\tLoss: 0.008499\n",
            "Train Epoch: 15 [49280/60000 (82%)]\tLoss: 0.057236\n",
            "Train Epoch: 15 [49920/60000 (83%)]\tLoss: 0.039613\n",
            "Train Epoch: 15 [50560/60000 (84%)]\tLoss: 0.000796\n",
            "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 0.001683\n",
            "Train Epoch: 15 [51840/60000 (86%)]\tLoss: 0.007468\n",
            "Train Epoch: 15 [52480/60000 (87%)]\tLoss: 0.030360\n",
            "Train Epoch: 15 [53120/60000 (88%)]\tLoss: 0.000482\n",
            "Train Epoch: 15 [53760/60000 (90%)]\tLoss: 0.030611\n",
            "Train Epoch: 15 [54400/60000 (91%)]\tLoss: 0.004796\n",
            "Train Epoch: 15 [55040/60000 (92%)]\tLoss: 0.006118\n",
            "Train Epoch: 15 [55680/60000 (93%)]\tLoss: 0.002414\n",
            "Train Epoch: 15 [56320/60000 (94%)]\tLoss: 0.005209\n",
            "Train Epoch: 15 [56960/60000 (95%)]\tLoss: 0.024412\n",
            "Train Epoch: 15 [57600/60000 (96%)]\tLoss: 0.006413\n",
            "Train Epoch: 15 [58240/60000 (97%)]\tLoss: 0.089185\n",
            "Train Epoch: 15 [58880/60000 (98%)]\tLoss: 0.008247\n",
            "Train Epoch: 15 [59520/60000 (99%)]\tLoss: 0.013166\n",
            "\n",
            "Test set: Average loss: 0.0137, Accuracy: 9961/10000 (100%)\n",
            "\n",
            "Model saved with new best test loss: 0.0137 \n",
            "\n",
            "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.000801\n",
            "Train Epoch: 16 [640/60000 (1%)]\tLoss: 0.000945\n",
            "Train Epoch: 16 [1280/60000 (2%)]\tLoss: 0.053820\n",
            "Train Epoch: 16 [1920/60000 (3%)]\tLoss: 0.004847\n",
            "Train Epoch: 16 [2560/60000 (4%)]\tLoss: 0.000728\n",
            "Train Epoch: 16 [3200/60000 (5%)]\tLoss: 0.007111\n",
            "Train Epoch: 16 [3840/60000 (6%)]\tLoss: 0.005362\n",
            "Train Epoch: 16 [4480/60000 (7%)]\tLoss: 0.013741\n",
            "Train Epoch: 16 [5120/60000 (9%)]\tLoss: 0.003097\n",
            "Train Epoch: 16 [5760/60000 (10%)]\tLoss: 0.004674\n",
            "Train Epoch: 16 [6400/60000 (11%)]\tLoss: 0.075974\n",
            "Train Epoch: 16 [7040/60000 (12%)]\tLoss: 0.003198\n",
            "Train Epoch: 16 [7680/60000 (13%)]\tLoss: 0.002315\n",
            "Train Epoch: 16 [8320/60000 (14%)]\tLoss: 0.025101\n",
            "Train Epoch: 16 [8960/60000 (15%)]\tLoss: 0.000724\n",
            "Train Epoch: 16 [9600/60000 (16%)]\tLoss: 0.046641\n",
            "Train Epoch: 16 [10240/60000 (17%)]\tLoss: 0.000895\n",
            "Train Epoch: 16 [10880/60000 (18%)]\tLoss: 0.024410\n",
            "Train Epoch: 16 [11520/60000 (19%)]\tLoss: 0.001616\n",
            "Train Epoch: 16 [12160/60000 (20%)]\tLoss: 0.092146\n",
            "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 0.084055\n",
            "Train Epoch: 16 [13440/60000 (22%)]\tLoss: 0.012087\n",
            "Train Epoch: 16 [14080/60000 (23%)]\tLoss: 0.001962\n",
            "Train Epoch: 16 [14720/60000 (25%)]\tLoss: 0.074989\n",
            "Train Epoch: 16 [15360/60000 (26%)]\tLoss: 0.007655\n",
            "Train Epoch: 16 [16000/60000 (27%)]\tLoss: 0.009868\n",
            "Train Epoch: 16 [16640/60000 (28%)]\tLoss: 0.074417\n",
            "Train Epoch: 16 [17280/60000 (29%)]\tLoss: 0.091064\n",
            "Train Epoch: 16 [17920/60000 (30%)]\tLoss: 0.051364\n",
            "Train Epoch: 16 [18560/60000 (31%)]\tLoss: 0.004266\n",
            "Train Epoch: 16 [19200/60000 (32%)]\tLoss: 0.091490\n",
            "Train Epoch: 16 [19840/60000 (33%)]\tLoss: 0.016236\n",
            "Train Epoch: 16 [20480/60000 (34%)]\tLoss: 0.021492\n",
            "Train Epoch: 16 [21120/60000 (35%)]\tLoss: 0.040072\n",
            "Train Epoch: 16 [21760/60000 (36%)]\tLoss: 0.000882\n",
            "Train Epoch: 16 [22400/60000 (37%)]\tLoss: 0.109341\n",
            "Train Epoch: 16 [23040/60000 (38%)]\tLoss: 0.127377\n",
            "Train Epoch: 16 [23680/60000 (39%)]\tLoss: 0.114807\n",
            "Train Epoch: 16 [24320/60000 (41%)]\tLoss: 0.001866\n",
            "Train Epoch: 16 [24960/60000 (42%)]\tLoss: 0.002162\n",
            "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 0.087261\n",
            "Train Epoch: 16 [26240/60000 (44%)]\tLoss: 0.005170\n",
            "Train Epoch: 16 [26880/60000 (45%)]\tLoss: 0.010386\n",
            "Train Epoch: 16 [27520/60000 (46%)]\tLoss: 0.014944\n",
            "Train Epoch: 16 [28160/60000 (47%)]\tLoss: 0.005269\n",
            "Train Epoch: 16 [28800/60000 (48%)]\tLoss: 0.001079\n",
            "Train Epoch: 16 [29440/60000 (49%)]\tLoss: 0.002800\n",
            "Train Epoch: 16 [30080/60000 (50%)]\tLoss: 0.084792\n",
            "Train Epoch: 16 [30720/60000 (51%)]\tLoss: 0.091281\n",
            "Train Epoch: 16 [31360/60000 (52%)]\tLoss: 0.004820\n",
            "Train Epoch: 16 [32000/60000 (53%)]\tLoss: 0.011370\n",
            "Train Epoch: 16 [32640/60000 (54%)]\tLoss: 0.017364\n",
            "Train Epoch: 16 [33280/60000 (55%)]\tLoss: 0.006565\n",
            "Train Epoch: 16 [33920/60000 (57%)]\tLoss: 0.005507\n",
            "Train Epoch: 16 [34560/60000 (58%)]\tLoss: 0.001527\n",
            "Train Epoch: 16 [35200/60000 (59%)]\tLoss: 0.042715\n",
            "Train Epoch: 16 [35840/60000 (60%)]\tLoss: 0.004224\n",
            "Train Epoch: 16 [36480/60000 (61%)]\tLoss: 0.001414\n",
            "Train Epoch: 16 [37120/60000 (62%)]\tLoss: 0.002522\n",
            "Train Epoch: 16 [37760/60000 (63%)]\tLoss: 0.050646\n",
            "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 0.020774\n",
            "Train Epoch: 16 [39040/60000 (65%)]\tLoss: 0.023164\n",
            "Train Epoch: 16 [39680/60000 (66%)]\tLoss: 0.181392\n",
            "Train Epoch: 16 [40320/60000 (67%)]\tLoss: 0.109199\n",
            "Train Epoch: 16 [40960/60000 (68%)]\tLoss: 0.052397\n",
            "Train Epoch: 16 [41600/60000 (69%)]\tLoss: 0.065271\n",
            "Train Epoch: 16 [42240/60000 (70%)]\tLoss: 0.024917\n",
            "Train Epoch: 16 [42880/60000 (71%)]\tLoss: 0.019816\n",
            "Train Epoch: 16 [43520/60000 (72%)]\tLoss: 0.004427\n",
            "Train Epoch: 16 [44160/60000 (74%)]\tLoss: 0.055752\n",
            "Train Epoch: 16 [44800/60000 (75%)]\tLoss: 0.014681\n",
            "Train Epoch: 16 [45440/60000 (76%)]\tLoss: 0.005268\n",
            "Train Epoch: 16 [46080/60000 (77%)]\tLoss: 0.032284\n",
            "Train Epoch: 16 [46720/60000 (78%)]\tLoss: 0.028051\n",
            "Train Epoch: 16 [47360/60000 (79%)]\tLoss: 0.001050\n",
            "Train Epoch: 16 [48000/60000 (80%)]\tLoss: 0.019838\n",
            "Train Epoch: 16 [48640/60000 (81%)]\tLoss: 0.020441\n",
            "Train Epoch: 16 [49280/60000 (82%)]\tLoss: 0.060515\n",
            "Train Epoch: 16 [49920/60000 (83%)]\tLoss: 0.005802\n",
            "Train Epoch: 16 [50560/60000 (84%)]\tLoss: 0.038624\n",
            "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 0.018436\n",
            "Train Epoch: 16 [51840/60000 (86%)]\tLoss: 0.003639\n",
            "Train Epoch: 16 [52480/60000 (87%)]\tLoss: 0.041635\n",
            "Train Epoch: 16 [53120/60000 (88%)]\tLoss: 0.005577\n",
            "Train Epoch: 16 [53760/60000 (90%)]\tLoss: 0.044801\n",
            "Train Epoch: 16 [54400/60000 (91%)]\tLoss: 0.089214\n",
            "Train Epoch: 16 [55040/60000 (92%)]\tLoss: 0.021261\n",
            "Train Epoch: 16 [55680/60000 (93%)]\tLoss: 0.021031\n",
            "Train Epoch: 16 [56320/60000 (94%)]\tLoss: 0.009322\n",
            "Train Epoch: 16 [56960/60000 (95%)]\tLoss: 0.009305\n",
            "Train Epoch: 16 [57600/60000 (96%)]\tLoss: 0.048650\n",
            "Train Epoch: 16 [58240/60000 (97%)]\tLoss: 0.004018\n",
            "Train Epoch: 16 [58880/60000 (98%)]\tLoss: 0.016889\n",
            "Train Epoch: 16 [59520/60000 (99%)]\tLoss: 0.007428\n",
            "\n",
            "Test set: Average loss: 0.0157, Accuracy: 9959/10000 (100%)\n",
            "\n",
            "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.093633\n",
            "Train Epoch: 17 [640/60000 (1%)]\tLoss: 0.001691\n",
            "Train Epoch: 17 [1280/60000 (2%)]\tLoss: 0.012613\n",
            "Train Epoch: 17 [1920/60000 (3%)]\tLoss: 0.020047\n",
            "Train Epoch: 17 [2560/60000 (4%)]\tLoss: 0.087843\n",
            "Train Epoch: 17 [3200/60000 (5%)]\tLoss: 0.153965\n",
            "Train Epoch: 17 [3840/60000 (6%)]\tLoss: 0.002390\n",
            "Train Epoch: 17 [4480/60000 (7%)]\tLoss: 0.013768\n",
            "Train Epoch: 17 [5120/60000 (9%)]\tLoss: 0.004821\n",
            "Train Epoch: 17 [5760/60000 (10%)]\tLoss: 0.000871\n",
            "Train Epoch: 17 [6400/60000 (11%)]\tLoss: 0.007882\n",
            "Train Epoch: 17 [7040/60000 (12%)]\tLoss: 0.055674\n",
            "Train Epoch: 17 [7680/60000 (13%)]\tLoss: 0.064165\n",
            "Train Epoch: 17 [8320/60000 (14%)]\tLoss: 0.000711\n",
            "Train Epoch: 17 [8960/60000 (15%)]\tLoss: 0.001698\n",
            "Train Epoch: 17 [9600/60000 (16%)]\tLoss: 0.002225\n",
            "Train Epoch: 17 [10240/60000 (17%)]\tLoss: 0.094159\n",
            "Train Epoch: 17 [10880/60000 (18%)]\tLoss: 0.080970\n",
            "Train Epoch: 17 [11520/60000 (19%)]\tLoss: 0.011287\n",
            "Train Epoch: 17 [12160/60000 (20%)]\tLoss: 0.028101\n",
            "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 0.017484\n",
            "Train Epoch: 17 [13440/60000 (22%)]\tLoss: 0.021560\n",
            "Train Epoch: 17 [14080/60000 (23%)]\tLoss: 0.002444\n",
            "Train Epoch: 17 [14720/60000 (25%)]\tLoss: 0.062948\n",
            "Train Epoch: 17 [15360/60000 (26%)]\tLoss: 0.008037\n",
            "Train Epoch: 17 [16000/60000 (27%)]\tLoss: 0.062350\n",
            "Train Epoch: 17 [16640/60000 (28%)]\tLoss: 0.026747\n",
            "Train Epoch: 17 [17280/60000 (29%)]\tLoss: 0.003700\n",
            "Train Epoch: 17 [17920/60000 (30%)]\tLoss: 0.004797\n",
            "Train Epoch: 17 [18560/60000 (31%)]\tLoss: 0.025676\n",
            "Train Epoch: 17 [19200/60000 (32%)]\tLoss: 0.022957\n",
            "Train Epoch: 17 [19840/60000 (33%)]\tLoss: 0.030981\n",
            "Train Epoch: 17 [20480/60000 (34%)]\tLoss: 0.044868\n",
            "Train Epoch: 17 [21120/60000 (35%)]\tLoss: 0.019863\n",
            "Train Epoch: 17 [21760/60000 (36%)]\tLoss: 0.152596\n",
            "Train Epoch: 17 [22400/60000 (37%)]\tLoss: 0.001729\n",
            "Train Epoch: 17 [23040/60000 (38%)]\tLoss: 0.000279\n",
            "Train Epoch: 17 [23680/60000 (39%)]\tLoss: 0.034656\n",
            "Train Epoch: 17 [24320/60000 (41%)]\tLoss: 0.078435\n",
            "Train Epoch: 17 [24960/60000 (42%)]\tLoss: 0.001604\n",
            "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 0.086620\n",
            "Train Epoch: 17 [26240/60000 (44%)]\tLoss: 0.011045\n",
            "Train Epoch: 17 [26880/60000 (45%)]\tLoss: 0.034393\n",
            "Train Epoch: 17 [27520/60000 (46%)]\tLoss: 0.067487\n",
            "Train Epoch: 17 [28160/60000 (47%)]\tLoss: 0.012967\n",
            "Train Epoch: 17 [28800/60000 (48%)]\tLoss: 0.025454\n",
            "Train Epoch: 17 [29440/60000 (49%)]\tLoss: 0.016527\n",
            "Train Epoch: 17 [30080/60000 (50%)]\tLoss: 0.005438\n",
            "Train Epoch: 17 [30720/60000 (51%)]\tLoss: 0.108962\n",
            "Train Epoch: 17 [31360/60000 (52%)]\tLoss: 0.008059\n",
            "Train Epoch: 17 [32000/60000 (53%)]\tLoss: 0.017901\n",
            "Train Epoch: 17 [32640/60000 (54%)]\tLoss: 0.013931\n",
            "Train Epoch: 17 [33280/60000 (55%)]\tLoss: 0.021821\n",
            "Train Epoch: 17 [33920/60000 (57%)]\tLoss: 0.023780\n",
            "Train Epoch: 17 [34560/60000 (58%)]\tLoss: 0.036835\n",
            "Train Epoch: 17 [35200/60000 (59%)]\tLoss: 0.117349\n",
            "Train Epoch: 17 [35840/60000 (60%)]\tLoss: 0.019555\n",
            "Train Epoch: 17 [36480/60000 (61%)]\tLoss: 0.027454\n",
            "Train Epoch: 17 [37120/60000 (62%)]\tLoss: 0.134217\n",
            "Train Epoch: 17 [37760/60000 (63%)]\tLoss: 0.002065\n",
            "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 0.040709\n",
            "Train Epoch: 17 [39040/60000 (65%)]\tLoss: 0.114748\n",
            "Train Epoch: 17 [39680/60000 (66%)]\tLoss: 0.005586\n",
            "Train Epoch: 17 [40320/60000 (67%)]\tLoss: 0.020762\n",
            "Train Epoch: 17 [40960/60000 (68%)]\tLoss: 0.015700\n",
            "Train Epoch: 17 [41600/60000 (69%)]\tLoss: 0.008902\n",
            "Train Epoch: 17 [42240/60000 (70%)]\tLoss: 0.020203\n",
            "Train Epoch: 17 [42880/60000 (71%)]\tLoss: 0.094510\n",
            "Train Epoch: 17 [43520/60000 (72%)]\tLoss: 0.354966\n",
            "Train Epoch: 17 [44160/60000 (74%)]\tLoss: 0.047014\n",
            "Train Epoch: 17 [44800/60000 (75%)]\tLoss: 0.006521\n",
            "Train Epoch: 17 [45440/60000 (76%)]\tLoss: 0.105162\n",
            "Train Epoch: 17 [46080/60000 (77%)]\tLoss: 0.141044\n",
            "Train Epoch: 17 [46720/60000 (78%)]\tLoss: 0.009754\n",
            "Train Epoch: 17 [47360/60000 (79%)]\tLoss: 0.022655\n",
            "Train Epoch: 17 [48000/60000 (80%)]\tLoss: 0.010203\n",
            "Train Epoch: 17 [48640/60000 (81%)]\tLoss: 0.007319\n",
            "Train Epoch: 17 [49280/60000 (82%)]\tLoss: 0.025583\n",
            "Train Epoch: 17 [49920/60000 (83%)]\tLoss: 0.001123\n",
            "Train Epoch: 17 [50560/60000 (84%)]\tLoss: 0.035956\n",
            "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 0.051227\n",
            "Train Epoch: 17 [51840/60000 (86%)]\tLoss: 0.017898\n",
            "Train Epoch: 17 [52480/60000 (87%)]\tLoss: 0.090981\n",
            "Train Epoch: 17 [53120/60000 (88%)]\tLoss: 0.035652\n",
            "Train Epoch: 17 [53760/60000 (90%)]\tLoss: 0.057124\n",
            "Train Epoch: 17 [54400/60000 (91%)]\tLoss: 0.003313\n",
            "Train Epoch: 17 [55040/60000 (92%)]\tLoss: 0.002012\n",
            "Train Epoch: 17 [55680/60000 (93%)]\tLoss: 0.069567\n",
            "Train Epoch: 17 [56320/60000 (94%)]\tLoss: 0.008300\n",
            "Train Epoch: 17 [56960/60000 (95%)]\tLoss: 0.018428\n",
            "Train Epoch: 17 [57600/60000 (96%)]\tLoss: 0.033523\n",
            "Train Epoch: 17 [58240/60000 (97%)]\tLoss: 0.226062\n",
            "Train Epoch: 17 [58880/60000 (98%)]\tLoss: 0.005081\n",
            "Train Epoch: 17 [59520/60000 (99%)]\tLoss: 0.007217\n",
            "\n",
            "Test set: Average loss: 0.0147, Accuracy: 9962/10000 (100%)\n",
            "\n",
            "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.000637\n",
            "Train Epoch: 18 [640/60000 (1%)]\tLoss: 0.017180\n",
            "Train Epoch: 18 [1280/60000 (2%)]\tLoss: 0.083053\n",
            "Train Epoch: 18 [1920/60000 (3%)]\tLoss: 0.271865\n",
            "Train Epoch: 18 [2560/60000 (4%)]\tLoss: 0.009346\n",
            "Train Epoch: 18 [3200/60000 (5%)]\tLoss: 0.151921\n",
            "Train Epoch: 18 [3840/60000 (6%)]\tLoss: 0.001737\n",
            "Train Epoch: 18 [4480/60000 (7%)]\tLoss: 0.001834\n",
            "Train Epoch: 18 [5120/60000 (9%)]\tLoss: 0.016248\n",
            "Train Epoch: 18 [5760/60000 (10%)]\tLoss: 0.093507\n",
            "Train Epoch: 18 [6400/60000 (11%)]\tLoss: 0.000860\n",
            "Train Epoch: 18 [7040/60000 (12%)]\tLoss: 0.058436\n",
            "Train Epoch: 18 [7680/60000 (13%)]\tLoss: 0.048004\n",
            "Train Epoch: 18 [8320/60000 (14%)]\tLoss: 0.014247\n",
            "Train Epoch: 18 [8960/60000 (15%)]\tLoss: 0.001937\n",
            "Train Epoch: 18 [9600/60000 (16%)]\tLoss: 0.064111\n",
            "Train Epoch: 18 [10240/60000 (17%)]\tLoss: 0.016013\n",
            "Train Epoch: 18 [10880/60000 (18%)]\tLoss: 0.009491\n",
            "Train Epoch: 18 [11520/60000 (19%)]\tLoss: 0.001422\n",
            "Train Epoch: 18 [12160/60000 (20%)]\tLoss: 0.000594\n",
            "Train Epoch: 18 [12800/60000 (21%)]\tLoss: 0.044675\n",
            "Train Epoch: 18 [13440/60000 (22%)]\tLoss: 0.000523\n",
            "Train Epoch: 18 [14080/60000 (23%)]\tLoss: 0.042080\n",
            "Train Epoch: 18 [14720/60000 (25%)]\tLoss: 0.041596\n",
            "Train Epoch: 18 [15360/60000 (26%)]\tLoss: 0.002249\n",
            "Train Epoch: 18 [16000/60000 (27%)]\tLoss: 0.046296\n",
            "Train Epoch: 18 [16640/60000 (28%)]\tLoss: 0.009564\n",
            "Train Epoch: 18 [17280/60000 (29%)]\tLoss: 0.009857\n",
            "Train Epoch: 18 [17920/60000 (30%)]\tLoss: 0.028435\n",
            "Train Epoch: 18 [18560/60000 (31%)]\tLoss: 0.016852\n",
            "Train Epoch: 18 [19200/60000 (32%)]\tLoss: 0.072521\n",
            "Train Epoch: 18 [19840/60000 (33%)]\tLoss: 0.053515\n",
            "Train Epoch: 18 [20480/60000 (34%)]\tLoss: 0.025641\n",
            "Train Epoch: 18 [21120/60000 (35%)]\tLoss: 0.013370\n",
            "Train Epoch: 18 [21760/60000 (36%)]\tLoss: 0.185521\n",
            "Train Epoch: 18 [22400/60000 (37%)]\tLoss: 0.097052\n",
            "Train Epoch: 18 [23040/60000 (38%)]\tLoss: 0.049287\n",
            "Train Epoch: 18 [23680/60000 (39%)]\tLoss: 0.019000\n",
            "Train Epoch: 18 [24320/60000 (41%)]\tLoss: 0.007515\n",
            "Train Epoch: 18 [24960/60000 (42%)]\tLoss: 0.000645\n",
            "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 0.084321\n",
            "Train Epoch: 18 [26240/60000 (44%)]\tLoss: 0.010811\n",
            "Train Epoch: 18 [26880/60000 (45%)]\tLoss: 0.012590\n",
            "Train Epoch: 18 [27520/60000 (46%)]\tLoss: 0.083965\n",
            "Train Epoch: 18 [28160/60000 (47%)]\tLoss: 0.016202\n",
            "Train Epoch: 18 [28800/60000 (48%)]\tLoss: 0.039584\n",
            "Train Epoch: 18 [29440/60000 (49%)]\tLoss: 0.109939\n",
            "Train Epoch: 18 [30080/60000 (50%)]\tLoss: 0.000275\n",
            "Train Epoch: 18 [30720/60000 (51%)]\tLoss: 0.163839\n",
            "Train Epoch: 18 [31360/60000 (52%)]\tLoss: 0.006571\n",
            "Train Epoch: 18 [32000/60000 (53%)]\tLoss: 0.042099\n",
            "Train Epoch: 18 [32640/60000 (54%)]\tLoss: 0.021492\n",
            "Train Epoch: 18 [33280/60000 (55%)]\tLoss: 0.062009\n",
            "Train Epoch: 18 [33920/60000 (57%)]\tLoss: 0.003735\n",
            "Train Epoch: 18 [34560/60000 (58%)]\tLoss: 0.050240\n",
            "Train Epoch: 18 [35200/60000 (59%)]\tLoss: 0.011019\n",
            "Train Epoch: 18 [35840/60000 (60%)]\tLoss: 0.008270\n",
            "Train Epoch: 18 [36480/60000 (61%)]\tLoss: 0.025943\n",
            "Train Epoch: 18 [37120/60000 (62%)]\tLoss: 0.000747\n",
            "Train Epoch: 18 [37760/60000 (63%)]\tLoss: 0.001246\n",
            "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 0.062000\n",
            "Train Epoch: 18 [39040/60000 (65%)]\tLoss: 0.097453\n",
            "Train Epoch: 18 [39680/60000 (66%)]\tLoss: 0.003407\n",
            "Train Epoch: 18 [40320/60000 (67%)]\tLoss: 0.072164\n",
            "Train Epoch: 18 [40960/60000 (68%)]\tLoss: 0.004022\n",
            "Train Epoch: 18 [41600/60000 (69%)]\tLoss: 0.031901\n",
            "Train Epoch: 18 [42240/60000 (70%)]\tLoss: 0.127084\n",
            "Train Epoch: 18 [42880/60000 (71%)]\tLoss: 0.109696\n",
            "Train Epoch: 18 [43520/60000 (72%)]\tLoss: 0.007972\n",
            "Train Epoch: 18 [44160/60000 (74%)]\tLoss: 0.001049\n",
            "Train Epoch: 18 [44800/60000 (75%)]\tLoss: 0.070620\n",
            "Train Epoch: 18 [45440/60000 (76%)]\tLoss: 0.008125\n",
            "Train Epoch: 18 [46080/60000 (77%)]\tLoss: 0.004683\n",
            "Train Epoch: 18 [46720/60000 (78%)]\tLoss: 0.096522\n",
            "Train Epoch: 18 [47360/60000 (79%)]\tLoss: 0.092088\n",
            "Train Epoch: 18 [48000/60000 (80%)]\tLoss: 0.015543\n",
            "Train Epoch: 18 [48640/60000 (81%)]\tLoss: 0.089314\n",
            "Train Epoch: 18 [49280/60000 (82%)]\tLoss: 0.051332\n",
            "Train Epoch: 18 [49920/60000 (83%)]\tLoss: 0.014615\n",
            "Train Epoch: 18 [50560/60000 (84%)]\tLoss: 0.042217\n",
            "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 0.006498\n",
            "Train Epoch: 18 [51840/60000 (86%)]\tLoss: 0.029726\n",
            "Train Epoch: 18 [52480/60000 (87%)]\tLoss: 0.007540\n",
            "Train Epoch: 18 [53120/60000 (88%)]\tLoss: 0.119124\n",
            "Train Epoch: 18 [53760/60000 (90%)]\tLoss: 0.029778\n",
            "Train Epoch: 18 [54400/60000 (91%)]\tLoss: 0.001382\n",
            "Train Epoch: 18 [55040/60000 (92%)]\tLoss: 0.097442\n",
            "Train Epoch: 18 [55680/60000 (93%)]\tLoss: 0.056136\n",
            "Train Epoch: 18 [56320/60000 (94%)]\tLoss: 0.013374\n",
            "Train Epoch: 18 [56960/60000 (95%)]\tLoss: 0.027956\n",
            "Train Epoch: 18 [57600/60000 (96%)]\tLoss: 0.013486\n",
            "Train Epoch: 18 [58240/60000 (97%)]\tLoss: 0.055859\n",
            "Train Epoch: 18 [58880/60000 (98%)]\tLoss: 0.032625\n",
            "Train Epoch: 18 [59520/60000 (99%)]\tLoss: 0.200643\n",
            "\n",
            "Test set: Average loss: 0.0154, Accuracy: 9958/10000 (100%)\n",
            "\n",
            "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.001146\n",
            "Train Epoch: 19 [640/60000 (1%)]\tLoss: 0.029590\n",
            "Train Epoch: 19 [1280/60000 (2%)]\tLoss: 0.007137\n",
            "Train Epoch: 19 [1920/60000 (3%)]\tLoss: 0.000170\n",
            "Train Epoch: 19 [2560/60000 (4%)]\tLoss: 0.033002\n",
            "Train Epoch: 19 [3200/60000 (5%)]\tLoss: 0.020696\n",
            "Train Epoch: 19 [3840/60000 (6%)]\tLoss: 0.026219\n",
            "Train Epoch: 19 [4480/60000 (7%)]\tLoss: 0.013593\n",
            "Train Epoch: 19 [5120/60000 (9%)]\tLoss: 0.018646\n",
            "Train Epoch: 19 [5760/60000 (10%)]\tLoss: 0.061695\n",
            "Train Epoch: 19 [6400/60000 (11%)]\tLoss: 0.025651\n",
            "Train Epoch: 19 [7040/60000 (12%)]\tLoss: 0.000616\n",
            "Train Epoch: 19 [7680/60000 (13%)]\tLoss: 0.003224\n",
            "Train Epoch: 19 [8320/60000 (14%)]\tLoss: 0.220042\n",
            "Train Epoch: 19 [8960/60000 (15%)]\tLoss: 0.028676\n",
            "Train Epoch: 19 [9600/60000 (16%)]\tLoss: 0.026916\n",
            "Train Epoch: 19 [10240/60000 (17%)]\tLoss: 0.017285\n",
            "Train Epoch: 19 [10880/60000 (18%)]\tLoss: 0.005162\n",
            "Train Epoch: 19 [11520/60000 (19%)]\tLoss: 0.000703\n",
            "Train Epoch: 19 [12160/60000 (20%)]\tLoss: 0.001190\n",
            "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 0.108526\n",
            "Train Epoch: 19 [13440/60000 (22%)]\tLoss: 0.008926\n",
            "Train Epoch: 19 [14080/60000 (23%)]\tLoss: 0.027000\n",
            "Train Epoch: 19 [14720/60000 (25%)]\tLoss: 0.002435\n",
            "Train Epoch: 19 [15360/60000 (26%)]\tLoss: 0.015919\n",
            "Train Epoch: 19 [16000/60000 (27%)]\tLoss: 0.000878\n",
            "Train Epoch: 19 [16640/60000 (28%)]\tLoss: 0.065582\n",
            "Train Epoch: 19 [17280/60000 (29%)]\tLoss: 0.016405\n",
            "Train Epoch: 19 [17920/60000 (30%)]\tLoss: 0.003743\n",
            "Train Epoch: 19 [18560/60000 (31%)]\tLoss: 0.094540\n",
            "Train Epoch: 19 [19200/60000 (32%)]\tLoss: 0.025331\n",
            "Train Epoch: 19 [19840/60000 (33%)]\tLoss: 0.006836\n",
            "Train Epoch: 19 [20480/60000 (34%)]\tLoss: 0.045421\n",
            "Train Epoch: 19 [21120/60000 (35%)]\tLoss: 0.051312\n",
            "Train Epoch: 19 [21760/60000 (36%)]\tLoss: 0.000990\n",
            "Train Epoch: 19 [22400/60000 (37%)]\tLoss: 0.000921\n",
            "Train Epoch: 19 [23040/60000 (38%)]\tLoss: 0.117693\n",
            "Train Epoch: 19 [23680/60000 (39%)]\tLoss: 0.085584\n",
            "Train Epoch: 19 [24320/60000 (41%)]\tLoss: 0.013797\n",
            "Train Epoch: 19 [24960/60000 (42%)]\tLoss: 0.002384\n",
            "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 0.003492\n",
            "Train Epoch: 19 [26240/60000 (44%)]\tLoss: 0.015461\n",
            "Train Epoch: 19 [26880/60000 (45%)]\tLoss: 0.082207\n",
            "Train Epoch: 19 [27520/60000 (46%)]\tLoss: 0.034954\n",
            "Train Epoch: 19 [28160/60000 (47%)]\tLoss: 0.110852\n",
            "Train Epoch: 19 [28800/60000 (48%)]\tLoss: 0.035404\n",
            "Train Epoch: 19 [29440/60000 (49%)]\tLoss: 0.002397\n",
            "Train Epoch: 19 [30080/60000 (50%)]\tLoss: 0.002514\n",
            "Train Epoch: 19 [30720/60000 (51%)]\tLoss: 0.075868\n",
            "Train Epoch: 19 [31360/60000 (52%)]\tLoss: 0.047664\n",
            "Train Epoch: 19 [32000/60000 (53%)]\tLoss: 0.064398\n",
            "Train Epoch: 19 [32640/60000 (54%)]\tLoss: 0.007264\n",
            "Train Epoch: 19 [33280/60000 (55%)]\tLoss: 0.081922\n",
            "Train Epoch: 19 [33920/60000 (57%)]\tLoss: 0.096103\n",
            "Train Epoch: 19 [34560/60000 (58%)]\tLoss: 0.001335\n",
            "Train Epoch: 19 [35200/60000 (59%)]\tLoss: 0.005572\n",
            "Train Epoch: 19 [35840/60000 (60%)]\tLoss: 0.000639\n",
            "Train Epoch: 19 [36480/60000 (61%)]\tLoss: 0.059616\n",
            "Train Epoch: 19 [37120/60000 (62%)]\tLoss: 0.089630\n",
            "Train Epoch: 19 [37760/60000 (63%)]\tLoss: 0.002234\n",
            "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 0.057229\n",
            "Train Epoch: 19 [39040/60000 (65%)]\tLoss: 0.011423\n",
            "Train Epoch: 19 [39680/60000 (66%)]\tLoss: 0.002925\n",
            "Train Epoch: 19 [40320/60000 (67%)]\tLoss: 0.005952\n",
            "Train Epoch: 19 [40960/60000 (68%)]\tLoss: 0.012053\n",
            "Train Epoch: 19 [41600/60000 (69%)]\tLoss: 0.044983\n",
            "Train Epoch: 19 [42240/60000 (70%)]\tLoss: 0.030694\n",
            "Train Epoch: 19 [42880/60000 (71%)]\tLoss: 0.003883\n",
            "Train Epoch: 19 [43520/60000 (72%)]\tLoss: 0.085778\n",
            "Train Epoch: 19 [44160/60000 (74%)]\tLoss: 0.003893\n",
            "Train Epoch: 19 [44800/60000 (75%)]\tLoss: 0.000782\n",
            "Train Epoch: 19 [45440/60000 (76%)]\tLoss: 0.001564\n",
            "Train Epoch: 19 [46080/60000 (77%)]\tLoss: 0.105920\n",
            "Train Epoch: 19 [46720/60000 (78%)]\tLoss: 0.015245\n",
            "Train Epoch: 19 [47360/60000 (79%)]\tLoss: 0.014882\n",
            "Train Epoch: 19 [48000/60000 (80%)]\tLoss: 0.000397\n",
            "Train Epoch: 19 [48640/60000 (81%)]\tLoss: 0.002357\n",
            "Train Epoch: 19 [49280/60000 (82%)]\tLoss: 0.051750\n",
            "Train Epoch: 19 [49920/60000 (83%)]\tLoss: 0.005093\n",
            "Train Epoch: 19 [50560/60000 (84%)]\tLoss: 0.021187\n",
            "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 0.004428\n",
            "Train Epoch: 19 [51840/60000 (86%)]\tLoss: 0.018804\n",
            "Train Epoch: 19 [52480/60000 (87%)]\tLoss: 0.003474\n",
            "Train Epoch: 19 [53120/60000 (88%)]\tLoss: 0.081846\n",
            "Train Epoch: 19 [53760/60000 (90%)]\tLoss: 0.028258\n",
            "Train Epoch: 19 [54400/60000 (91%)]\tLoss: 0.008410\n",
            "Train Epoch: 19 [55040/60000 (92%)]\tLoss: 0.026876\n",
            "Train Epoch: 19 [55680/60000 (93%)]\tLoss: 0.007838\n",
            "Train Epoch: 19 [56320/60000 (94%)]\tLoss: 0.044384\n",
            "Train Epoch: 19 [56960/60000 (95%)]\tLoss: 0.037393\n",
            "Train Epoch: 19 [57600/60000 (96%)]\tLoss: 0.022871\n",
            "Train Epoch: 19 [58240/60000 (97%)]\tLoss: 0.013309\n",
            "Train Epoch: 19 [58880/60000 (98%)]\tLoss: 0.002490\n",
            "Train Epoch: 19 [59520/60000 (99%)]\tLoss: 0.086197\n",
            "\n",
            "Test set: Average loss: 0.0139, Accuracy: 9965/10000 (100%)\n",
            "\n",
            "Train Epoch: 20 [0/60000 (0%)]\tLoss: 0.013761\n",
            "Train Epoch: 20 [640/60000 (1%)]\tLoss: 0.006933\n",
            "Train Epoch: 20 [1280/60000 (2%)]\tLoss: 0.002281\n",
            "Train Epoch: 20 [1920/60000 (3%)]\tLoss: 0.011470\n",
            "Train Epoch: 20 [2560/60000 (4%)]\tLoss: 0.039373\n",
            "Train Epoch: 20 [3200/60000 (5%)]\tLoss: 0.001185\n",
            "Train Epoch: 20 [3840/60000 (6%)]\tLoss: 0.020035\n",
            "Train Epoch: 20 [4480/60000 (7%)]\tLoss: 0.001049\n",
            "Train Epoch: 20 [5120/60000 (9%)]\tLoss: 0.023642\n",
            "Train Epoch: 20 [5760/60000 (10%)]\tLoss: 0.064946\n",
            "Train Epoch: 20 [6400/60000 (11%)]\tLoss: 0.061680\n",
            "Train Epoch: 20 [7040/60000 (12%)]\tLoss: 0.002086\n",
            "Train Epoch: 20 [7680/60000 (13%)]\tLoss: 0.032480\n",
            "Train Epoch: 20 [8320/60000 (14%)]\tLoss: 0.027118\n",
            "Train Epoch: 20 [8960/60000 (15%)]\tLoss: 0.027641\n",
            "Train Epoch: 20 [9600/60000 (16%)]\tLoss: 0.008907\n",
            "Train Epoch: 20 [10240/60000 (17%)]\tLoss: 0.027760\n",
            "Train Epoch: 20 [10880/60000 (18%)]\tLoss: 0.000865\n",
            "Train Epoch: 20 [11520/60000 (19%)]\tLoss: 0.002165\n",
            "Train Epoch: 20 [12160/60000 (20%)]\tLoss: 0.016487\n",
            "Train Epoch: 20 [12800/60000 (21%)]\tLoss: 0.030880\n",
            "Train Epoch: 20 [13440/60000 (22%)]\tLoss: 0.001423\n",
            "Train Epoch: 20 [14080/60000 (23%)]\tLoss: 0.002649\n",
            "Train Epoch: 20 [14720/60000 (25%)]\tLoss: 0.032322\n",
            "Train Epoch: 20 [15360/60000 (26%)]\tLoss: 0.038691\n",
            "Train Epoch: 20 [16000/60000 (27%)]\tLoss: 0.000473\n",
            "Train Epoch: 20 [16640/60000 (28%)]\tLoss: 0.043732\n",
            "Train Epoch: 20 [17280/60000 (29%)]\tLoss: 0.008255\n",
            "Train Epoch: 20 [17920/60000 (30%)]\tLoss: 0.001241\n",
            "Train Epoch: 20 [18560/60000 (31%)]\tLoss: 0.004652\n",
            "Train Epoch: 20 [19200/60000 (32%)]\tLoss: 0.053509\n",
            "Train Epoch: 20 [19840/60000 (33%)]\tLoss: 0.084639\n",
            "Train Epoch: 20 [20480/60000 (34%)]\tLoss: 0.017188\n",
            "Train Epoch: 20 [21120/60000 (35%)]\tLoss: 0.032591\n",
            "Train Epoch: 20 [21760/60000 (36%)]\tLoss: 0.039356\n",
            "Train Epoch: 20 [22400/60000 (37%)]\tLoss: 0.022398\n",
            "Train Epoch: 20 [23040/60000 (38%)]\tLoss: 0.032015\n",
            "Train Epoch: 20 [23680/60000 (39%)]\tLoss: 0.013855\n",
            "Train Epoch: 20 [24320/60000 (41%)]\tLoss: 0.008484\n",
            "Train Epoch: 20 [24960/60000 (42%)]\tLoss: 0.006023\n",
            "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 0.006026\n",
            "Train Epoch: 20 [26240/60000 (44%)]\tLoss: 0.028880\n",
            "Train Epoch: 20 [26880/60000 (45%)]\tLoss: 0.005755\n",
            "Train Epoch: 20 [27520/60000 (46%)]\tLoss: 0.003999\n",
            "Train Epoch: 20 [28160/60000 (47%)]\tLoss: 0.043018\n",
            "Train Epoch: 20 [28800/60000 (48%)]\tLoss: 0.017997\n",
            "Train Epoch: 20 [29440/60000 (49%)]\tLoss: 0.076617\n",
            "Train Epoch: 20 [30080/60000 (50%)]\tLoss: 0.373661\n",
            "Train Epoch: 20 [30720/60000 (51%)]\tLoss: 0.003414\n",
            "Train Epoch: 20 [31360/60000 (52%)]\tLoss: 0.001301\n",
            "Train Epoch: 20 [32000/60000 (53%)]\tLoss: 0.026690\n",
            "Train Epoch: 20 [32640/60000 (54%)]\tLoss: 0.022232\n",
            "Train Epoch: 20 [33280/60000 (55%)]\tLoss: 0.016617\n",
            "Train Epoch: 20 [33920/60000 (57%)]\tLoss: 0.005199\n",
            "Train Epoch: 20 [34560/60000 (58%)]\tLoss: 0.020284\n",
            "Train Epoch: 20 [35200/60000 (59%)]\tLoss: 0.042220\n",
            "Train Epoch: 20 [35840/60000 (60%)]\tLoss: 0.105149\n",
            "Train Epoch: 20 [36480/60000 (61%)]\tLoss: 0.005195\n",
            "Train Epoch: 20 [37120/60000 (62%)]\tLoss: 0.120153\n",
            "Train Epoch: 20 [37760/60000 (63%)]\tLoss: 0.016399\n",
            "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 0.002168\n",
            "Train Epoch: 20 [39040/60000 (65%)]\tLoss: 0.019503\n",
            "Train Epoch: 20 [39680/60000 (66%)]\tLoss: 0.014652\n",
            "Train Epoch: 20 [40320/60000 (67%)]\tLoss: 0.004024\n",
            "Train Epoch: 20 [40960/60000 (68%)]\tLoss: 0.108091\n",
            "Train Epoch: 20 [41600/60000 (69%)]\tLoss: 0.035384\n",
            "Train Epoch: 20 [42240/60000 (70%)]\tLoss: 0.058652\n",
            "Train Epoch: 20 [42880/60000 (71%)]\tLoss: 0.003394\n",
            "Train Epoch: 20 [43520/60000 (72%)]\tLoss: 0.099213\n",
            "Train Epoch: 20 [44160/60000 (74%)]\tLoss: 0.113185\n",
            "Train Epoch: 20 [44800/60000 (75%)]\tLoss: 0.181895\n",
            "Train Epoch: 20 [45440/60000 (76%)]\tLoss: 0.036196\n",
            "Train Epoch: 20 [46080/60000 (77%)]\tLoss: 0.085331\n",
            "Train Epoch: 20 [46720/60000 (78%)]\tLoss: 0.010284\n",
            "Train Epoch: 20 [47360/60000 (79%)]\tLoss: 0.056906\n",
            "Train Epoch: 20 [48000/60000 (80%)]\tLoss: 0.002971\n",
            "Train Epoch: 20 [48640/60000 (81%)]\tLoss: 0.006266\n",
            "Train Epoch: 20 [49280/60000 (82%)]\tLoss: 0.089880\n",
            "Train Epoch: 20 [49920/60000 (83%)]\tLoss: 0.067162\n",
            "Train Epoch: 20 [50560/60000 (84%)]\tLoss: 0.121485\n",
            "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 0.001688\n",
            "Train Epoch: 20 [51840/60000 (86%)]\tLoss: 0.039253\n",
            "Train Epoch: 20 [52480/60000 (87%)]\tLoss: 0.001655\n",
            "Train Epoch: 20 [53120/60000 (88%)]\tLoss: 0.011836\n",
            "Train Epoch: 20 [53760/60000 (90%)]\tLoss: 0.017921\n",
            "Train Epoch: 20 [54400/60000 (91%)]\tLoss: 0.000592\n",
            "Train Epoch: 20 [55040/60000 (92%)]\tLoss: 0.109718\n",
            "Train Epoch: 20 [55680/60000 (93%)]\tLoss: 0.023785\n",
            "Train Epoch: 20 [56320/60000 (94%)]\tLoss: 0.003371\n",
            "Train Epoch: 20 [56960/60000 (95%)]\tLoss: 0.013102\n",
            "Train Epoch: 20 [57600/60000 (96%)]\tLoss: 0.003726\n",
            "Train Epoch: 20 [58240/60000 (97%)]\tLoss: 0.001593\n",
            "Train Epoch: 20 [58880/60000 (98%)]\tLoss: 0.116750\n",
            "Train Epoch: 20 [59520/60000 (99%)]\tLoss: 0.001238\n",
            "\n",
            "Test set: Average loss: 0.0163, Accuracy: 9954/10000 (100%)\n",
            "\n",
            "Train Epoch: 21 [0/60000 (0%)]\tLoss: 0.111608\n",
            "Train Epoch: 21 [640/60000 (1%)]\tLoss: 0.002100\n",
            "Train Epoch: 21 [1280/60000 (2%)]\tLoss: 0.060140\n",
            "Train Epoch: 21 [1920/60000 (3%)]\tLoss: 0.011209\n",
            "Train Epoch: 21 [2560/60000 (4%)]\tLoss: 0.004988\n",
            "Train Epoch: 21 [3200/60000 (5%)]\tLoss: 0.026788\n",
            "Train Epoch: 21 [3840/60000 (6%)]\tLoss: 0.001882\n",
            "Train Epoch: 21 [4480/60000 (7%)]\tLoss: 0.000542\n",
            "Train Epoch: 21 [5120/60000 (9%)]\tLoss: 0.004340\n",
            "Train Epoch: 21 [5760/60000 (10%)]\tLoss: 0.000881\n",
            "Train Epoch: 21 [6400/60000 (11%)]\tLoss: 0.010135\n",
            "Train Epoch: 21 [7040/60000 (12%)]\tLoss: 0.037148\n",
            "Train Epoch: 21 [7680/60000 (13%)]\tLoss: 0.002199\n",
            "Train Epoch: 21 [8320/60000 (14%)]\tLoss: 0.068814\n",
            "Train Epoch: 21 [8960/60000 (15%)]\tLoss: 0.001756\n",
            "Train Epoch: 21 [9600/60000 (16%)]\tLoss: 0.050085\n",
            "Train Epoch: 21 [10240/60000 (17%)]\tLoss: 0.002888\n",
            "Train Epoch: 21 [10880/60000 (18%)]\tLoss: 0.010792\n",
            "Train Epoch: 21 [11520/60000 (19%)]\tLoss: 0.024965\n",
            "Train Epoch: 21 [12160/60000 (20%)]\tLoss: 0.002772\n",
            "Train Epoch: 21 [12800/60000 (21%)]\tLoss: 0.074448\n",
            "Train Epoch: 21 [13440/60000 (22%)]\tLoss: 0.006898\n",
            "Train Epoch: 21 [14080/60000 (23%)]\tLoss: 0.004322\n",
            "Train Epoch: 21 [14720/60000 (25%)]\tLoss: 0.010220\n",
            "Train Epoch: 21 [15360/60000 (26%)]\tLoss: 0.034110\n",
            "Train Epoch: 21 [16000/60000 (27%)]\tLoss: 0.004565\n",
            "Train Epoch: 21 [16640/60000 (28%)]\tLoss: 0.001486\n",
            "Train Epoch: 21 [17280/60000 (29%)]\tLoss: 0.055810\n",
            "Train Epoch: 21 [17920/60000 (30%)]\tLoss: 0.058359\n",
            "Train Epoch: 21 [18560/60000 (31%)]\tLoss: 0.029287\n",
            "Train Epoch: 21 [19200/60000 (32%)]\tLoss: 0.121539\n",
            "Train Epoch: 21 [19840/60000 (33%)]\tLoss: 0.000678\n",
            "Train Epoch: 21 [20480/60000 (34%)]\tLoss: 0.010847\n",
            "Train Epoch: 21 [21120/60000 (35%)]\tLoss: 0.048397\n",
            "Train Epoch: 21 [21760/60000 (36%)]\tLoss: 0.034640\n",
            "Train Epoch: 21 [22400/60000 (37%)]\tLoss: 0.000938\n",
            "Train Epoch: 21 [23040/60000 (38%)]\tLoss: 0.002134\n",
            "Train Epoch: 21 [23680/60000 (39%)]\tLoss: 0.082234\n",
            "Train Epoch: 21 [24320/60000 (41%)]\tLoss: 0.032242\n",
            "Train Epoch: 21 [24960/60000 (42%)]\tLoss: 0.003111\n",
            "Train Epoch: 21 [25600/60000 (43%)]\tLoss: 0.053721\n",
            "Train Epoch: 21 [26240/60000 (44%)]\tLoss: 0.002324\n",
            "Train Epoch: 21 [26880/60000 (45%)]\tLoss: 0.020493\n",
            "Train Epoch: 21 [27520/60000 (46%)]\tLoss: 0.000607\n",
            "Train Epoch: 21 [28160/60000 (47%)]\tLoss: 0.015493\n",
            "Train Epoch: 21 [28800/60000 (48%)]\tLoss: 0.120182\n",
            "Train Epoch: 21 [29440/60000 (49%)]\tLoss: 0.001694\n",
            "Train Epoch: 21 [30080/60000 (50%)]\tLoss: 0.033771\n",
            "Train Epoch: 21 [30720/60000 (51%)]\tLoss: 0.029400\n",
            "Train Epoch: 21 [31360/60000 (52%)]\tLoss: 0.008909\n",
            "Train Epoch: 21 [32000/60000 (53%)]\tLoss: 0.004524\n",
            "Train Epoch: 21 [32640/60000 (54%)]\tLoss: 0.001835\n",
            "Train Epoch: 21 [33280/60000 (55%)]\tLoss: 0.007837\n",
            "Train Epoch: 21 [33920/60000 (57%)]\tLoss: 0.004307\n",
            "Train Epoch: 21 [34560/60000 (58%)]\tLoss: 0.036902\n",
            "Train Epoch: 21 [35200/60000 (59%)]\tLoss: 0.007273\n",
            "Train Epoch: 21 [35840/60000 (60%)]\tLoss: 0.017975\n",
            "Train Epoch: 21 [36480/60000 (61%)]\tLoss: 0.000419\n",
            "Train Epoch: 21 [37120/60000 (62%)]\tLoss: 0.055130\n",
            "Train Epoch: 21 [37760/60000 (63%)]\tLoss: 0.024925\n",
            "Train Epoch: 21 [38400/60000 (64%)]\tLoss: 0.010132\n",
            "Train Epoch: 21 [39040/60000 (65%)]\tLoss: 0.040257\n",
            "Train Epoch: 21 [39680/60000 (66%)]\tLoss: 0.010812\n",
            "Train Epoch: 21 [40320/60000 (67%)]\tLoss: 0.061984\n",
            "Train Epoch: 21 [40960/60000 (68%)]\tLoss: 0.075265\n",
            "Train Epoch: 21 [41600/60000 (69%)]\tLoss: 0.052266\n",
            "Train Epoch: 21 [42240/60000 (70%)]\tLoss: 0.006570\n",
            "Train Epoch: 21 [42880/60000 (71%)]\tLoss: 0.001524\n",
            "Train Epoch: 21 [43520/60000 (72%)]\tLoss: 0.037005\n",
            "Train Epoch: 21 [44160/60000 (74%)]\tLoss: 0.031263\n",
            "Train Epoch: 21 [44800/60000 (75%)]\tLoss: 0.001740\n",
            "Train Epoch: 21 [45440/60000 (76%)]\tLoss: 0.007823\n",
            "Train Epoch: 21 [46080/60000 (77%)]\tLoss: 0.066398\n",
            "Train Epoch: 21 [46720/60000 (78%)]\tLoss: 0.000891\n",
            "Train Epoch: 21 [47360/60000 (79%)]\tLoss: 0.079428\n",
            "Train Epoch: 21 [48000/60000 (80%)]\tLoss: 0.000944\n",
            "Train Epoch: 21 [48640/60000 (81%)]\tLoss: 0.003766\n",
            "Train Epoch: 21 [49280/60000 (82%)]\tLoss: 0.040869\n",
            "Train Epoch: 21 [49920/60000 (83%)]\tLoss: 0.006803\n",
            "Train Epoch: 21 [50560/60000 (84%)]\tLoss: 0.032614\n",
            "Train Epoch: 21 [51200/60000 (85%)]\tLoss: 0.184753\n",
            "Train Epoch: 21 [51840/60000 (86%)]\tLoss: 0.004933\n",
            "Train Epoch: 21 [52480/60000 (87%)]\tLoss: 0.004678\n",
            "Train Epoch: 21 [53120/60000 (88%)]\tLoss: 0.013958\n",
            "Train Epoch: 21 [53760/60000 (90%)]\tLoss: 0.000500\n",
            "Train Epoch: 21 [54400/60000 (91%)]\tLoss: 0.050399\n",
            "Train Epoch: 21 [55040/60000 (92%)]\tLoss: 0.024226\n",
            "Train Epoch: 21 [55680/60000 (93%)]\tLoss: 0.004729\n",
            "Train Epoch: 21 [56320/60000 (94%)]\tLoss: 0.066687\n",
            "Train Epoch: 21 [56960/60000 (95%)]\tLoss: 0.018866\n",
            "Train Epoch: 21 [57600/60000 (96%)]\tLoss: 0.073428\n",
            "Train Epoch: 21 [58240/60000 (97%)]\tLoss: 0.003921\n",
            "Train Epoch: 21 [58880/60000 (98%)]\tLoss: 0.002404\n",
            "Train Epoch: 21 [59520/60000 (99%)]\tLoss: 0.022602\n",
            "\n",
            "Test set: Average loss: 0.0154, Accuracy: 9959/10000 (100%)\n",
            "\n",
            "Train Epoch: 22 [0/60000 (0%)]\tLoss: 0.024202\n",
            "Train Epoch: 22 [640/60000 (1%)]\tLoss: 0.011941\n",
            "Train Epoch: 22 [1280/60000 (2%)]\tLoss: 0.088080\n",
            "Train Epoch: 22 [1920/60000 (3%)]\tLoss: 0.000225\n",
            "Train Epoch: 22 [2560/60000 (4%)]\tLoss: 0.010828\n",
            "Train Epoch: 22 [3200/60000 (5%)]\tLoss: 0.019483\n",
            "Train Epoch: 22 [3840/60000 (6%)]\tLoss: 0.001560\n",
            "Train Epoch: 22 [4480/60000 (7%)]\tLoss: 0.000943\n",
            "Train Epoch: 22 [5120/60000 (9%)]\tLoss: 0.014657\n",
            "Train Epoch: 22 [5760/60000 (10%)]\tLoss: 0.004349\n",
            "Train Epoch: 22 [6400/60000 (11%)]\tLoss: 0.002215\n",
            "Train Epoch: 22 [7040/60000 (12%)]\tLoss: 0.034976\n",
            "Train Epoch: 22 [7680/60000 (13%)]\tLoss: 0.009945\n",
            "Train Epoch: 22 [8320/60000 (14%)]\tLoss: 0.025872\n",
            "Train Epoch: 22 [8960/60000 (15%)]\tLoss: 0.002305\n",
            "Train Epoch: 22 [9600/60000 (16%)]\tLoss: 0.123103\n",
            "Train Epoch: 22 [10240/60000 (17%)]\tLoss: 0.004291\n",
            "Train Epoch: 22 [10880/60000 (18%)]\tLoss: 0.048581\n",
            "Train Epoch: 22 [11520/60000 (19%)]\tLoss: 0.026255\n",
            "Train Epoch: 22 [12160/60000 (20%)]\tLoss: 0.006134\n",
            "Train Epoch: 22 [12800/60000 (21%)]\tLoss: 0.007286\n",
            "Train Epoch: 22 [13440/60000 (22%)]\tLoss: 0.031945\n",
            "Train Epoch: 22 [14080/60000 (23%)]\tLoss: 0.020572\n",
            "Train Epoch: 22 [14720/60000 (25%)]\tLoss: 0.000473\n",
            "Train Epoch: 22 [15360/60000 (26%)]\tLoss: 0.015403\n",
            "Train Epoch: 22 [16000/60000 (27%)]\tLoss: 0.013867\n",
            "Train Epoch: 22 [16640/60000 (28%)]\tLoss: 0.000413\n",
            "Train Epoch: 22 [17280/60000 (29%)]\tLoss: 0.099315\n",
            "Train Epoch: 22 [17920/60000 (30%)]\tLoss: 0.001396\n",
            "Train Epoch: 22 [18560/60000 (31%)]\tLoss: 0.053215\n",
            "Train Epoch: 22 [19200/60000 (32%)]\tLoss: 0.001175\n",
            "Train Epoch: 22 [19840/60000 (33%)]\tLoss: 0.014380\n",
            "Train Epoch: 22 [20480/60000 (34%)]\tLoss: 0.002390\n",
            "Train Epoch: 22 [21120/60000 (35%)]\tLoss: 0.009868\n",
            "Train Epoch: 22 [21760/60000 (36%)]\tLoss: 0.003123\n",
            "Train Epoch: 22 [22400/60000 (37%)]\tLoss: 0.012745\n",
            "Train Epoch: 22 [23040/60000 (38%)]\tLoss: 0.002641\n",
            "Train Epoch: 22 [23680/60000 (39%)]\tLoss: 0.000972\n",
            "Train Epoch: 22 [24320/60000 (41%)]\tLoss: 0.007076\n",
            "Train Epoch: 22 [24960/60000 (42%)]\tLoss: 0.110864\n",
            "Train Epoch: 22 [25600/60000 (43%)]\tLoss: 0.004985\n",
            "Train Epoch: 22 [26240/60000 (44%)]\tLoss: 0.013574\n",
            "Train Epoch: 22 [26880/60000 (45%)]\tLoss: 0.006395\n",
            "Train Epoch: 22 [27520/60000 (46%)]\tLoss: 0.052454\n",
            "Train Epoch: 22 [28160/60000 (47%)]\tLoss: 0.035234\n",
            "Train Epoch: 22 [28800/60000 (48%)]\tLoss: 0.024201\n",
            "Train Epoch: 22 [29440/60000 (49%)]\tLoss: 0.023194\n",
            "Train Epoch: 22 [30080/60000 (50%)]\tLoss: 0.039611\n",
            "Train Epoch: 22 [30720/60000 (51%)]\tLoss: 0.040433\n",
            "Train Epoch: 22 [31360/60000 (52%)]\tLoss: 0.063755\n",
            "Train Epoch: 22 [32000/60000 (53%)]\tLoss: 0.213977\n",
            "Train Epoch: 22 [32640/60000 (54%)]\tLoss: 0.123456\n",
            "Train Epoch: 22 [33280/60000 (55%)]\tLoss: 0.019944\n",
            "Train Epoch: 22 [33920/60000 (57%)]\tLoss: 0.026135\n",
            "Train Epoch: 22 [34560/60000 (58%)]\tLoss: 0.064141\n",
            "Train Epoch: 22 [35200/60000 (59%)]\tLoss: 0.006840\n",
            "Train Epoch: 22 [35840/60000 (60%)]\tLoss: 0.070479\n",
            "Train Epoch: 22 [36480/60000 (61%)]\tLoss: 0.000421\n",
            "Train Epoch: 22 [37120/60000 (62%)]\tLoss: 0.138574\n",
            "Train Epoch: 22 [37760/60000 (63%)]\tLoss: 0.007306\n",
            "Train Epoch: 22 [38400/60000 (64%)]\tLoss: 0.016319\n",
            "Train Epoch: 22 [39040/60000 (65%)]\tLoss: 0.024985\n",
            "Train Epoch: 22 [39680/60000 (66%)]\tLoss: 0.004193\n",
            "Train Epoch: 22 [40320/60000 (67%)]\tLoss: 0.024454\n",
            "Train Epoch: 22 [40960/60000 (68%)]\tLoss: 0.051490\n",
            "Train Epoch: 22 [41600/60000 (69%)]\tLoss: 0.053845\n",
            "Train Epoch: 22 [42240/60000 (70%)]\tLoss: 0.123294\n",
            "Train Epoch: 22 [42880/60000 (71%)]\tLoss: 0.001955\n",
            "Train Epoch: 22 [43520/60000 (72%)]\tLoss: 0.002692\n",
            "Train Epoch: 22 [44160/60000 (74%)]\tLoss: 0.028052\n",
            "Train Epoch: 22 [44800/60000 (75%)]\tLoss: 0.030359\n",
            "Train Epoch: 22 [45440/60000 (76%)]\tLoss: 0.094176\n",
            "Train Epoch: 22 [46080/60000 (77%)]\tLoss: 0.000254\n",
            "Train Epoch: 22 [46720/60000 (78%)]\tLoss: 0.013047\n",
            "Train Epoch: 22 [47360/60000 (79%)]\tLoss: 0.000602\n",
            "Train Epoch: 22 [48000/60000 (80%)]\tLoss: 0.006213\n",
            "Train Epoch: 22 [48640/60000 (81%)]\tLoss: 0.033918\n",
            "Train Epoch: 22 [49280/60000 (82%)]\tLoss: 0.002000\n",
            "Train Epoch: 22 [49920/60000 (83%)]\tLoss: 0.012810\n",
            "Train Epoch: 22 [50560/60000 (84%)]\tLoss: 0.003261\n",
            "Train Epoch: 22 [51200/60000 (85%)]\tLoss: 0.001388\n",
            "Train Epoch: 22 [51840/60000 (86%)]\tLoss: 0.020092\n",
            "Train Epoch: 22 [52480/60000 (87%)]\tLoss: 0.005258\n",
            "Train Epoch: 22 [53120/60000 (88%)]\tLoss: 0.077072\n",
            "Train Epoch: 22 [53760/60000 (90%)]\tLoss: 0.001873\n",
            "Train Epoch: 22 [54400/60000 (91%)]\tLoss: 0.017108\n",
            "Train Epoch: 22 [55040/60000 (92%)]\tLoss: 0.003192\n",
            "Train Epoch: 22 [55680/60000 (93%)]\tLoss: 0.107591\n",
            "Train Epoch: 22 [56320/60000 (94%)]\tLoss: 0.017728\n",
            "Train Epoch: 22 [56960/60000 (95%)]\tLoss: 0.014871\n",
            "Train Epoch: 22 [57600/60000 (96%)]\tLoss: 0.061200\n",
            "Train Epoch: 22 [58240/60000 (97%)]\tLoss: 0.017478\n",
            "Train Epoch: 22 [58880/60000 (98%)]\tLoss: 0.015354\n",
            "Train Epoch: 22 [59520/60000 (99%)]\tLoss: 0.014206\n",
            "\n",
            "Test set: Average loss: 0.0146, Accuracy: 9962/10000 (100%)\n",
            "\n",
            "Train Epoch: 23 [0/60000 (0%)]\tLoss: 0.016321\n",
            "Train Epoch: 23 [640/60000 (1%)]\tLoss: 0.038328\n",
            "Train Epoch: 23 [1280/60000 (2%)]\tLoss: 0.000324\n",
            "Train Epoch: 23 [1920/60000 (3%)]\tLoss: 0.030211\n",
            "Train Epoch: 23 [2560/60000 (4%)]\tLoss: 0.007589\n",
            "Train Epoch: 23 [3200/60000 (5%)]\tLoss: 0.077747\n",
            "Train Epoch: 23 [3840/60000 (6%)]\tLoss: 0.008375\n",
            "Train Epoch: 23 [4480/60000 (7%)]\tLoss: 0.085173\n",
            "Train Epoch: 23 [5120/60000 (9%)]\tLoss: 0.006759\n",
            "Train Epoch: 23 [5760/60000 (10%)]\tLoss: 0.014746\n",
            "Train Epoch: 23 [6400/60000 (11%)]\tLoss: 0.042819\n",
            "Train Epoch: 23 [7040/60000 (12%)]\tLoss: 0.026939\n",
            "Train Epoch: 23 [7680/60000 (13%)]\tLoss: 0.015812\n",
            "Train Epoch: 23 [8320/60000 (14%)]\tLoss: 0.000702\n",
            "Train Epoch: 23 [8960/60000 (15%)]\tLoss: 0.019191\n",
            "Train Epoch: 23 [9600/60000 (16%)]\tLoss: 0.022298\n",
            "Train Epoch: 23 [10240/60000 (17%)]\tLoss: 0.019909\n",
            "Train Epoch: 23 [10880/60000 (18%)]\tLoss: 0.006041\n",
            "Train Epoch: 23 [11520/60000 (19%)]\tLoss: 0.012043\n",
            "Train Epoch: 23 [12160/60000 (20%)]\tLoss: 0.135420\n",
            "Train Epoch: 23 [12800/60000 (21%)]\tLoss: 0.022218\n",
            "Train Epoch: 23 [13440/60000 (22%)]\tLoss: 0.002410\n",
            "Train Epoch: 23 [14080/60000 (23%)]\tLoss: 0.004031\n",
            "Train Epoch: 23 [14720/60000 (25%)]\tLoss: 0.001763\n",
            "Train Epoch: 23 [15360/60000 (26%)]\tLoss: 0.112687\n",
            "Train Epoch: 23 [16000/60000 (27%)]\tLoss: 0.007791\n",
            "Train Epoch: 23 [16640/60000 (28%)]\tLoss: 0.018479\n",
            "Train Epoch: 23 [17280/60000 (29%)]\tLoss: 0.026681\n",
            "Train Epoch: 23 [17920/60000 (30%)]\tLoss: 0.000456\n",
            "Train Epoch: 23 [18560/60000 (31%)]\tLoss: 0.000735\n",
            "Train Epoch: 23 [19200/60000 (32%)]\tLoss: 0.003325\n",
            "Train Epoch: 23 [19840/60000 (33%)]\tLoss: 0.075277\n",
            "Train Epoch: 23 [20480/60000 (34%)]\tLoss: 0.054522\n",
            "Train Epoch: 23 [21120/60000 (35%)]\tLoss: 0.000619\n",
            "Train Epoch: 23 [21760/60000 (36%)]\tLoss: 0.015074\n",
            "Train Epoch: 23 [22400/60000 (37%)]\tLoss: 0.006328\n",
            "Train Epoch: 23 [23040/60000 (38%)]\tLoss: 0.009195\n",
            "Train Epoch: 23 [23680/60000 (39%)]\tLoss: 0.008564\n",
            "Train Epoch: 23 [24320/60000 (41%)]\tLoss: 0.011731\n",
            "Train Epoch: 23 [24960/60000 (42%)]\tLoss: 0.036770\n",
            "Train Epoch: 23 [25600/60000 (43%)]\tLoss: 0.012751\n",
            "Train Epoch: 23 [26240/60000 (44%)]\tLoss: 0.001074\n",
            "Train Epoch: 23 [26880/60000 (45%)]\tLoss: 0.076021\n",
            "Train Epoch: 23 [27520/60000 (46%)]\tLoss: 0.009549\n",
            "Train Epoch: 23 [28160/60000 (47%)]\tLoss: 0.022986\n",
            "Train Epoch: 23 [28800/60000 (48%)]\tLoss: 0.002046\n",
            "Train Epoch: 23 [29440/60000 (49%)]\tLoss: 0.092947\n",
            "Train Epoch: 23 [30080/60000 (50%)]\tLoss: 0.002206\n",
            "Train Epoch: 23 [30720/60000 (51%)]\tLoss: 0.027319\n",
            "Train Epoch: 23 [31360/60000 (52%)]\tLoss: 0.067119\n",
            "Train Epoch: 23 [32000/60000 (53%)]\tLoss: 0.000944\n",
            "Train Epoch: 23 [32640/60000 (54%)]\tLoss: 0.041652\n",
            "Train Epoch: 23 [33280/60000 (55%)]\tLoss: 0.164528\n",
            "Train Epoch: 23 [33920/60000 (57%)]\tLoss: 0.032989\n",
            "Train Epoch: 23 [34560/60000 (58%)]\tLoss: 0.001115\n",
            "Train Epoch: 23 [35200/60000 (59%)]\tLoss: 0.003187\n",
            "Train Epoch: 23 [35840/60000 (60%)]\tLoss: 0.020518\n",
            "Train Epoch: 23 [36480/60000 (61%)]\tLoss: 0.009816\n",
            "Train Epoch: 23 [37120/60000 (62%)]\tLoss: 0.068231\n",
            "Train Epoch: 23 [37760/60000 (63%)]\tLoss: 0.048239\n",
            "Train Epoch: 23 [38400/60000 (64%)]\tLoss: 0.002181\n",
            "Train Epoch: 23 [39040/60000 (65%)]\tLoss: 0.031650\n",
            "Train Epoch: 23 [39680/60000 (66%)]\tLoss: 0.032431\n",
            "Train Epoch: 23 [40320/60000 (67%)]\tLoss: 0.036309\n",
            "Train Epoch: 23 [40960/60000 (68%)]\tLoss: 0.003322\n",
            "Train Epoch: 23 [41600/60000 (69%)]\tLoss: 0.002571\n",
            "Train Epoch: 23 [42240/60000 (70%)]\tLoss: 0.002163\n",
            "Train Epoch: 23 [42880/60000 (71%)]\tLoss: 0.054279\n",
            "Train Epoch: 23 [43520/60000 (72%)]\tLoss: 0.002193\n",
            "Train Epoch: 23 [44160/60000 (74%)]\tLoss: 0.017137\n",
            "Train Epoch: 23 [44800/60000 (75%)]\tLoss: 0.093525\n",
            "Train Epoch: 23 [45440/60000 (76%)]\tLoss: 0.003022\n",
            "Train Epoch: 23 [46080/60000 (77%)]\tLoss: 0.002855\n",
            "Train Epoch: 23 [46720/60000 (78%)]\tLoss: 0.007480\n",
            "Train Epoch: 23 [47360/60000 (79%)]\tLoss: 0.018020\n",
            "Train Epoch: 23 [48000/60000 (80%)]\tLoss: 0.022567\n",
            "Train Epoch: 23 [48640/60000 (81%)]\tLoss: 0.006920\n",
            "Train Epoch: 23 [49280/60000 (82%)]\tLoss: 0.043307\n",
            "Train Epoch: 23 [49920/60000 (83%)]\tLoss: 0.122937\n",
            "Train Epoch: 23 [50560/60000 (84%)]\tLoss: 0.007701\n",
            "Train Epoch: 23 [51200/60000 (85%)]\tLoss: 0.002350\n",
            "Train Epoch: 23 [51840/60000 (86%)]\tLoss: 0.010211\n",
            "Train Epoch: 23 [52480/60000 (87%)]\tLoss: 0.007313\n",
            "Train Epoch: 23 [53120/60000 (88%)]\tLoss: 0.013064\n",
            "Train Epoch: 23 [53760/60000 (90%)]\tLoss: 0.000716\n",
            "Train Epoch: 23 [54400/60000 (91%)]\tLoss: 0.017752\n",
            "Train Epoch: 23 [55040/60000 (92%)]\tLoss: 0.002842\n",
            "Train Epoch: 23 [55680/60000 (93%)]\tLoss: 0.068208\n",
            "Train Epoch: 23 [56320/60000 (94%)]\tLoss: 0.001339\n",
            "Train Epoch: 23 [56960/60000 (95%)]\tLoss: 0.023326\n",
            "Train Epoch: 23 [57600/60000 (96%)]\tLoss: 0.035893\n",
            "Train Epoch: 23 [58240/60000 (97%)]\tLoss: 0.062106\n",
            "Train Epoch: 23 [58880/60000 (98%)]\tLoss: 0.017397\n",
            "Train Epoch: 23 [59520/60000 (99%)]\tLoss: 0.000938\n",
            "\n",
            "Test set: Average loss: 0.0140, Accuracy: 9957/10000 (100%)\n",
            "\n",
            "Train Epoch: 24 [0/60000 (0%)]\tLoss: 0.005596\n",
            "Train Epoch: 24 [640/60000 (1%)]\tLoss: 0.040260\n",
            "Train Epoch: 24 [1280/60000 (2%)]\tLoss: 0.039077\n",
            "Train Epoch: 24 [1920/60000 (3%)]\tLoss: 0.006810\n",
            "Train Epoch: 24 [2560/60000 (4%)]\tLoss: 0.102119\n",
            "Train Epoch: 24 [3200/60000 (5%)]\tLoss: 0.001215\n",
            "Train Epoch: 24 [3840/60000 (6%)]\tLoss: 0.005191\n",
            "Train Epoch: 24 [4480/60000 (7%)]\tLoss: 0.124386\n",
            "Train Epoch: 24 [5120/60000 (9%)]\tLoss: 0.005379\n",
            "Train Epoch: 24 [5760/60000 (10%)]\tLoss: 0.005536\n",
            "Train Epoch: 24 [6400/60000 (11%)]\tLoss: 0.000692\n",
            "Train Epoch: 24 [7040/60000 (12%)]\tLoss: 0.000931\n",
            "Train Epoch: 24 [7680/60000 (13%)]\tLoss: 0.001888\n",
            "Train Epoch: 24 [8320/60000 (14%)]\tLoss: 0.000974\n",
            "Train Epoch: 24 [8960/60000 (15%)]\tLoss: 0.000593\n",
            "Train Epoch: 24 [9600/60000 (16%)]\tLoss: 0.014614\n",
            "Train Epoch: 24 [10240/60000 (17%)]\tLoss: 0.003241\n",
            "Train Epoch: 24 [10880/60000 (18%)]\tLoss: 0.005124\n",
            "Train Epoch: 24 [11520/60000 (19%)]\tLoss: 0.180456\n",
            "Train Epoch: 24 [12160/60000 (20%)]\tLoss: 0.003921\n",
            "Train Epoch: 24 [12800/60000 (21%)]\tLoss: 0.007278\n",
            "Train Epoch: 24 [13440/60000 (22%)]\tLoss: 0.001913\n",
            "Train Epoch: 24 [14080/60000 (23%)]\tLoss: 0.006789\n",
            "Train Epoch: 24 [14720/60000 (25%)]\tLoss: 0.000915\n",
            "Train Epoch: 24 [15360/60000 (26%)]\tLoss: 0.057530\n",
            "Train Epoch: 24 [16000/60000 (27%)]\tLoss: 0.049715\n",
            "Train Epoch: 24 [16640/60000 (28%)]\tLoss: 0.004241\n",
            "Train Epoch: 24 [17280/60000 (29%)]\tLoss: 0.025244\n",
            "Train Epoch: 24 [17920/60000 (30%)]\tLoss: 0.002008\n",
            "Train Epoch: 24 [18560/60000 (31%)]\tLoss: 0.000381\n",
            "Train Epoch: 24 [19200/60000 (32%)]\tLoss: 0.012899\n",
            "Train Epoch: 24 [19840/60000 (33%)]\tLoss: 0.001280\n",
            "Train Epoch: 24 [20480/60000 (34%)]\tLoss: 0.013905\n",
            "Train Epoch: 24 [21120/60000 (35%)]\tLoss: 0.148354\n",
            "Train Epoch: 24 [21760/60000 (36%)]\tLoss: 0.001590\n",
            "Train Epoch: 24 [22400/60000 (37%)]\tLoss: 0.002931\n",
            "Train Epoch: 24 [23040/60000 (38%)]\tLoss: 0.012816\n",
            "Train Epoch: 24 [23680/60000 (39%)]\tLoss: 0.019579\n",
            "Train Epoch: 24 [24320/60000 (41%)]\tLoss: 0.029641\n",
            "Train Epoch: 24 [24960/60000 (42%)]\tLoss: 0.033404\n",
            "Train Epoch: 24 [25600/60000 (43%)]\tLoss: 0.147057\n",
            "Train Epoch: 24 [26240/60000 (44%)]\tLoss: 0.013229\n",
            "Train Epoch: 24 [26880/60000 (45%)]\tLoss: 0.003814\n",
            "Train Epoch: 24 [27520/60000 (46%)]\tLoss: 0.041697\n",
            "Train Epoch: 24 [28160/60000 (47%)]\tLoss: 0.002551\n",
            "Train Epoch: 24 [28800/60000 (48%)]\tLoss: 0.002508\n",
            "Train Epoch: 24 [29440/60000 (49%)]\tLoss: 0.022781\n",
            "Train Epoch: 24 [30080/60000 (50%)]\tLoss: 0.000342\n",
            "Train Epoch: 24 [30720/60000 (51%)]\tLoss: 0.058109\n",
            "Train Epoch: 24 [31360/60000 (52%)]\tLoss: 0.045955\n",
            "Train Epoch: 24 [32000/60000 (53%)]\tLoss: 0.009845\n",
            "Train Epoch: 24 [32640/60000 (54%)]\tLoss: 0.012674\n",
            "Train Epoch: 24 [33280/60000 (55%)]\tLoss: 0.027284\n",
            "Train Epoch: 24 [33920/60000 (57%)]\tLoss: 0.002675\n",
            "Train Epoch: 24 [34560/60000 (58%)]\tLoss: 0.043973\n",
            "Train Epoch: 24 [35200/60000 (59%)]\tLoss: 0.001865\n",
            "Train Epoch: 24 [35840/60000 (60%)]\tLoss: 0.016751\n",
            "Train Epoch: 24 [36480/60000 (61%)]\tLoss: 0.039035\n",
            "Train Epoch: 24 [37120/60000 (62%)]\tLoss: 0.063318\n",
            "Train Epoch: 24 [37760/60000 (63%)]\tLoss: 0.018572\n",
            "Train Epoch: 24 [38400/60000 (64%)]\tLoss: 0.005448\n",
            "Train Epoch: 24 [39040/60000 (65%)]\tLoss: 0.001543\n",
            "Train Epoch: 24 [39680/60000 (66%)]\tLoss: 0.001926\n",
            "Train Epoch: 24 [40320/60000 (67%)]\tLoss: 0.025134\n",
            "Train Epoch: 24 [40960/60000 (68%)]\tLoss: 0.001904\n",
            "Train Epoch: 24 [41600/60000 (69%)]\tLoss: 0.003036\n",
            "Train Epoch: 24 [42240/60000 (70%)]\tLoss: 0.036291\n",
            "Train Epoch: 24 [42880/60000 (71%)]\tLoss: 0.004652\n",
            "Train Epoch: 24 [43520/60000 (72%)]\tLoss: 0.004082\n",
            "Train Epoch: 24 [44160/60000 (74%)]\tLoss: 0.017164\n",
            "Train Epoch: 24 [44800/60000 (75%)]\tLoss: 0.021510\n",
            "Train Epoch: 24 [45440/60000 (76%)]\tLoss: 0.084249\n",
            "Train Epoch: 24 [46080/60000 (77%)]\tLoss: 0.087018\n",
            "Train Epoch: 24 [46720/60000 (78%)]\tLoss: 0.003763\n",
            "Train Epoch: 24 [47360/60000 (79%)]\tLoss: 0.040144\n",
            "Train Epoch: 24 [48000/60000 (80%)]\tLoss: 0.006988\n",
            "Train Epoch: 24 [48640/60000 (81%)]\tLoss: 0.085228\n",
            "Train Epoch: 24 [49280/60000 (82%)]\tLoss: 0.000621\n",
            "Train Epoch: 24 [49920/60000 (83%)]\tLoss: 0.000727\n",
            "Train Epoch: 24 [50560/60000 (84%)]\tLoss: 0.005948\n",
            "Train Epoch: 24 [51200/60000 (85%)]\tLoss: 0.001145\n",
            "Train Epoch: 24 [51840/60000 (86%)]\tLoss: 0.002562\n",
            "Train Epoch: 24 [52480/60000 (87%)]\tLoss: 0.116828\n",
            "Train Epoch: 24 [53120/60000 (88%)]\tLoss: 0.000940\n",
            "Train Epoch: 24 [53760/60000 (90%)]\tLoss: 0.143028\n",
            "Train Epoch: 24 [54400/60000 (91%)]\tLoss: 0.001728\n",
            "Train Epoch: 24 [55040/60000 (92%)]\tLoss: 0.013695\n",
            "Train Epoch: 24 [55680/60000 (93%)]\tLoss: 0.002038\n",
            "Train Epoch: 24 [56320/60000 (94%)]\tLoss: 0.001523\n",
            "Train Epoch: 24 [56960/60000 (95%)]\tLoss: 0.003133\n",
            "Train Epoch: 24 [57600/60000 (96%)]\tLoss: 0.100633\n",
            "Train Epoch: 24 [58240/60000 (97%)]\tLoss: 0.019991\n",
            "Train Epoch: 24 [58880/60000 (98%)]\tLoss: 0.016885\n",
            "Train Epoch: 24 [59520/60000 (99%)]\tLoss: 0.083548\n",
            "\n",
            "Test set: Average loss: 0.0138, Accuracy: 9960/10000 (100%)\n",
            "\n",
            "Train Epoch: 25 [0/60000 (0%)]\tLoss: 0.002795\n",
            "Train Epoch: 25 [640/60000 (1%)]\tLoss: 0.001049\n",
            "Train Epoch: 25 [1280/60000 (2%)]\tLoss: 0.001801\n",
            "Train Epoch: 25 [1920/60000 (3%)]\tLoss: 0.007869\n",
            "Train Epoch: 25 [2560/60000 (4%)]\tLoss: 0.009491\n",
            "Train Epoch: 25 [3200/60000 (5%)]\tLoss: 0.001302\n",
            "Train Epoch: 25 [3840/60000 (6%)]\tLoss: 0.036572\n",
            "Train Epoch: 25 [4480/60000 (7%)]\tLoss: 0.010715\n",
            "Train Epoch: 25 [5120/60000 (9%)]\tLoss: 0.081712\n",
            "Train Epoch: 25 [5760/60000 (10%)]\tLoss: 0.004778\n",
            "Train Epoch: 25 [6400/60000 (11%)]\tLoss: 0.005664\n",
            "Train Epoch: 25 [7040/60000 (12%)]\tLoss: 0.031337\n",
            "Train Epoch: 25 [7680/60000 (13%)]\tLoss: 0.020089\n",
            "Train Epoch: 25 [8320/60000 (14%)]\tLoss: 0.003178\n",
            "Train Epoch: 25 [8960/60000 (15%)]\tLoss: 0.005478\n",
            "Train Epoch: 25 [9600/60000 (16%)]\tLoss: 0.017293\n",
            "Train Epoch: 25 [10240/60000 (17%)]\tLoss: 0.006774\n",
            "Train Epoch: 25 [10880/60000 (18%)]\tLoss: 0.038956\n",
            "Train Epoch: 25 [11520/60000 (19%)]\tLoss: 0.011549\n",
            "Train Epoch: 25 [12160/60000 (20%)]\tLoss: 0.001762\n",
            "Train Epoch: 25 [12800/60000 (21%)]\tLoss: 0.002586\n",
            "Train Epoch: 25 [13440/60000 (22%)]\tLoss: 0.005573\n",
            "Train Epoch: 25 [14080/60000 (23%)]\tLoss: 0.043203\n",
            "Train Epoch: 25 [14720/60000 (25%)]\tLoss: 0.028786\n",
            "Train Epoch: 25 [15360/60000 (26%)]\tLoss: 0.000639\n",
            "Train Epoch: 25 [16000/60000 (27%)]\tLoss: 0.017337\n",
            "Train Epoch: 25 [16640/60000 (28%)]\tLoss: 0.101213\n",
            "Train Epoch: 25 [17280/60000 (29%)]\tLoss: 0.001537\n",
            "Train Epoch: 25 [17920/60000 (30%)]\tLoss: 0.005121\n",
            "Train Epoch: 25 [18560/60000 (31%)]\tLoss: 0.028685\n",
            "Train Epoch: 25 [19200/60000 (32%)]\tLoss: 0.000900\n",
            "Train Epoch: 25 [19840/60000 (33%)]\tLoss: 0.039915\n",
            "Train Epoch: 25 [20480/60000 (34%)]\tLoss: 0.012966\n",
            "Train Epoch: 25 [21120/60000 (35%)]\tLoss: 0.113900\n",
            "Train Epoch: 25 [21760/60000 (36%)]\tLoss: 0.001077\n",
            "Train Epoch: 25 [22400/60000 (37%)]\tLoss: 0.008542\n",
            "Train Epoch: 25 [23040/60000 (38%)]\tLoss: 0.015540\n",
            "Train Epoch: 25 [23680/60000 (39%)]\tLoss: 0.007214\n",
            "Train Epoch: 25 [24320/60000 (41%)]\tLoss: 0.014604\n",
            "Train Epoch: 25 [24960/60000 (42%)]\tLoss: 0.048286\n",
            "Train Epoch: 25 [25600/60000 (43%)]\tLoss: 0.047722\n",
            "Train Epoch: 25 [26240/60000 (44%)]\tLoss: 0.130297\n",
            "Train Epoch: 25 [26880/60000 (45%)]\tLoss: 0.011164\n",
            "Train Epoch: 25 [27520/60000 (46%)]\tLoss: 0.135121\n",
            "Train Epoch: 25 [28160/60000 (47%)]\tLoss: 0.008700\n",
            "Train Epoch: 25 [28800/60000 (48%)]\tLoss: 0.000893\n",
            "Train Epoch: 25 [29440/60000 (49%)]\tLoss: 0.067709\n",
            "Train Epoch: 25 [30080/60000 (50%)]\tLoss: 0.051646\n",
            "Train Epoch: 25 [30720/60000 (51%)]\tLoss: 0.024072\n",
            "Train Epoch: 25 [31360/60000 (52%)]\tLoss: 0.022191\n",
            "Train Epoch: 25 [32000/60000 (53%)]\tLoss: 0.000226\n",
            "Train Epoch: 25 [32640/60000 (54%)]\tLoss: 0.024991\n",
            "Train Epoch: 25 [33280/60000 (55%)]\tLoss: 0.034147\n",
            "Train Epoch: 25 [33920/60000 (57%)]\tLoss: 0.001009\n",
            "Train Epoch: 25 [34560/60000 (58%)]\tLoss: 0.052435\n",
            "Train Epoch: 25 [35200/60000 (59%)]\tLoss: 0.012030\n",
            "Train Epoch: 25 [35840/60000 (60%)]\tLoss: 0.000552\n",
            "Train Epoch: 25 [36480/60000 (61%)]\tLoss: 0.132844\n",
            "Train Epoch: 25 [37120/60000 (62%)]\tLoss: 0.024657\n",
            "Train Epoch: 25 [37760/60000 (63%)]\tLoss: 0.006961\n",
            "Train Epoch: 25 [38400/60000 (64%)]\tLoss: 0.047203\n",
            "Train Epoch: 25 [39040/60000 (65%)]\tLoss: 0.011765\n",
            "Train Epoch: 25 [39680/60000 (66%)]\tLoss: 0.001077\n",
            "Train Epoch: 25 [40320/60000 (67%)]\tLoss: 0.020070\n",
            "Train Epoch: 25 [40960/60000 (68%)]\tLoss: 0.009059\n",
            "Train Epoch: 25 [41600/60000 (69%)]\tLoss: 0.015666\n",
            "Train Epoch: 25 [42240/60000 (70%)]\tLoss: 0.004423\n",
            "Train Epoch: 25 [42880/60000 (71%)]\tLoss: 0.001736\n",
            "Train Epoch: 25 [43520/60000 (72%)]\tLoss: 0.011111\n",
            "Train Epoch: 25 [44160/60000 (74%)]\tLoss: 0.003981\n",
            "Train Epoch: 25 [44800/60000 (75%)]\tLoss: 0.080734\n",
            "Train Epoch: 25 [45440/60000 (76%)]\tLoss: 0.043079\n",
            "Train Epoch: 25 [46080/60000 (77%)]\tLoss: 0.057130\n",
            "Train Epoch: 25 [46720/60000 (78%)]\tLoss: 0.081868\n",
            "Train Epoch: 25 [47360/60000 (79%)]\tLoss: 0.004995\n",
            "Train Epoch: 25 [48000/60000 (80%)]\tLoss: 0.060688\n",
            "Train Epoch: 25 [48640/60000 (81%)]\tLoss: 0.002244\n",
            "Train Epoch: 25 [49280/60000 (82%)]\tLoss: 0.029203\n",
            "Train Epoch: 25 [49920/60000 (83%)]\tLoss: 0.002867\n",
            "Train Epoch: 25 [50560/60000 (84%)]\tLoss: 0.003885\n",
            "Train Epoch: 25 [51200/60000 (85%)]\tLoss: 0.000212\n",
            "Train Epoch: 25 [51840/60000 (86%)]\tLoss: 0.003000\n",
            "Train Epoch: 25 [52480/60000 (87%)]\tLoss: 0.011028\n",
            "Train Epoch: 25 [53120/60000 (88%)]\tLoss: 0.043026\n",
            "Train Epoch: 25 [53760/60000 (90%)]\tLoss: 0.000974\n",
            "Train Epoch: 25 [54400/60000 (91%)]\tLoss: 0.048440\n",
            "Train Epoch: 25 [55040/60000 (92%)]\tLoss: 0.018342\n",
            "Train Epoch: 25 [55680/60000 (93%)]\tLoss: 0.042794\n",
            "Train Epoch: 25 [56320/60000 (94%)]\tLoss: 0.007531\n",
            "Train Epoch: 25 [56960/60000 (95%)]\tLoss: 0.003207\n",
            "Train Epoch: 25 [57600/60000 (96%)]\tLoss: 0.009236\n",
            "Train Epoch: 25 [58240/60000 (97%)]\tLoss: 0.015043\n",
            "Train Epoch: 25 [58880/60000 (98%)]\tLoss: 0.046246\n",
            "Train Epoch: 25 [59520/60000 (99%)]\tLoss: 0.015587\n",
            "\n",
            "Test set: Average loss: 0.0141, Accuracy: 9959/10000 (100%)\n",
            "\n",
            "\n",
            "Early stopping triggered after 25 epochs. No improvement in test loss for 10 consecutive epochs.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAHqCAYAAADVi/1VAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAwexJREFUeJzs3Xd4VHX2x/HPzKSHNFoKJQkBgUivoogtFAsiiiDr/lAsrAVdxUVlXSmii6KyrA0sKyqgoqIsWCiiqKxIla4oSE9CEVJIz8z9/TGZgZiEDGGSKbxfzzNPkjt37pyZQXNz7jnnazIMwxAAAAAAAABQh8yeDgAAAAAAAADnHpJSAAAAAAAAqHMkpQAAAAAAAFDnSEoBAAAAAACgzpGUAgAAAAAAQJ0jKQUAAAAAAIA6R1IKAAAAAAAAdY6kFAAAAAAAAOocSSkAAAAAAADUOZJSAOBn3nrrLZlMJq1bt87ToQAAAJzz9uzZI5PJpOeee87ToQBeh6QUgEqR2Kia472p6vbDDz94OkQAAHCWXnnlFZlMJvXs2dPToaAajqRPVbenn37a0yECqEKApwMAAF/1xBNPKDk5ucL2li1beiAaAADgTnPnzlVSUpLWrFmjnTt38vvdBwwfPlxXXXVVhe2dO3f2QDQAXEFSCgBq6Morr1S3bt08HQYAAHCz3bt36/vvv9fHH3+sv/zlL5o7d64mTJjg6bAqlZeXp/DwcE+H4RW6dOmiP//5z54OA8AZoH0PwFn58ccfdeWVVyoyMlL16tXTFVdcUaF9raSkRJMmTVKrVq0UEhKiBg0aqHfv3lq2bJlzn8zMTI0cOVJNmzZVcHCw4uPjNWjQIO3Zs6fK537uuedkMpm0d+/eCveNGzdOQUFBOn78uCTp119/1Q033KC4uDiFhISoadOmuummm5Sdne2eN6ISp84P+Ne//qXExESFhobqkksu0datWyvs/9VXX+niiy9WeHi4oqOjNWjQIP30008V9jt48KBuv/12JSQkKDg4WMnJybr77rtVXFxcbr+ioiKNGTNGjRo1Unh4uAYPHqwjR47U2usFAMBfzJ07VzExMbr66qs1ZMgQzZ07t9L9srKy9OCDDyopKUnBwcFq2rSpRowYoaNHjzr3KSws1MSJE3XeeecpJCRE8fHxuv7667Vr1y5J0ooVK2QymbRixYpyx3acR7z11lvObbfeeqvq1aunXbt26aqrrlJERIRuvvlmSdJ3332nG2+8Uc2bN1dwcLCaNWumBx98UAUFBRXi/vnnnzV06FA1atRIoaGhat26tR577DFJ0tdffy2TyaRPPvmkwuPeffddmUwmrVq1qtL3Y926dTKZTHr77bcr3LdkyRKZTCZ9+umnkqTc3Fw98MADzveucePG6tu3rzZs2FDpsd0lKSlJ11xzjZYuXapOnTopJCREqamp+vjjjyvs+9tvv+nGG29U/fr1FRYWpgsuuECfffZZhf2q+4xP9dprryklJUXBwcHq3r271q5dWyuvE/AVVEoBqLFt27bp4osvVmRkpB5++GEFBgbq1Vdf1aWXXqpvvvnGOYNh4sSJmjJliu644w716NFDOTk5WrdunTZs2KC+fftKkm644QZt27ZN9913n5KSknT48GEtW7ZM+/btU1JSUqXPP3ToUD388MP64IMPNHbs2HL3ffDBB+rXr59iYmJUXFys/v37q6ioSPfdd5/i4uJ08OBBffrpp8rKylJUVFSNXn92dna5k05JMplMatCgQblt77zzjnJzc3XvvfeqsLBQ//73v3X55Zdry5Ytio2NlSR9+eWXuvLKK9WiRQtNnDhRBQUFevHFF3XRRRdpw4YNzvcgPT1dPXr0UFZWlkaNGqU2bdro4MGD+uijj5Sfn6+goCDn8953332KiYnRhAkTtGfPHk2fPl2jR4/WvHnzavR6AQA4V8ydO1fXX3+9goKCNHz4cM2YMUNr165V9+7dnfucOHFCF198sX766Sfddttt6tKli44ePaqFCxfqwIEDatiwoaxWq6655hotX75cN910k/76178qNzdXy5Yt09atW5WSknLGsZWWlqp///7q3bu3nnvuOYWFhUmSPvzwQ+Xn5+vuu+9WgwYNtGbNGr344os6cOCAPvzwQ+fjN2/erIsvvliBgYEaNWqUkpKStGvXLi1atEhPPfWULr30UjVr1kxz587V4MGDK7wvKSkp6tWrV6WxdevWTS1atNAHH3ygW265pdx98+bNU0xMjPr37y9Juuuuu/TRRx9p9OjRSk1N1e+//66VK1fqp59+UpcuXc74fZGk/Pz8CudmkhQdHa2AgJN/+v76668aNmyY7rrrLt1yyy2aNWuWbrzxRi1evNh5bnro0CFdeOGFys/P1/33368GDRro7bff1rXXXquPPvrI+d6cyWf87rvvKjc3V3/5y19kMpk0depUXX/99frtt98UGBhYo9cM+DwDACoxa9YsQ5Kxdu3aKve57rrrjKCgIGPXrl3Obenp6UZERITRp08f57aOHTsaV199dZXHOX78uCHJePbZZ884zl69ehldu3Ytt23NmjWGJOOdd94xDMMwfvzxR0OS8eGHH57x8SvjeG8quwUHBzv32717tyHJCA0NNQ4cOODcvnr1akOS8eCDDzq3derUyWjcuLHx+++/O7dt2rTJMJvNxogRI5zbRowYYZjN5ko/F5vNVi6+tLQ05zbDMIwHH3zQsFgsRlZWllveBwAA/NG6desMScayZcsMw7D/fm3atKnx17/+tdx+48ePNyQZH3/8cYVjOH7/vvnmm4YkY9q0aVXu8/XXXxuSjK+//rrc/Y7ziFmzZjm33XLLLYYk49FHH61wvPz8/ArbpkyZYphMJmPv3r3ObX369DEiIiLKbTs1HsMwjHHjxhnBwcHlzhkOHz5sBAQEGBMmTKjwPKcaN26cERgYaBw7dsy5raioyIiOjjZuu+0257aoqCjj3nvvPe2xXOV4r6q6rVq1yrlvYmKiIcmYP3++c1t2drYRHx9vdO7c2bntgQceMCQZ3333nXNbbm6ukZycbCQlJRlWq9UwDNc+Y0d8DRo0KPe+/Pe//zUkGYsWLXLL+wD4Itr3ANSI1WrV0qVLdd1116lFixbO7fHx8frTn/6klStXKicnR5L96tS2bdv066+/Vnqs0NBQBQUFacWKFc52O1cNGzZM69evL1cePW/ePAUHB2vQoEGS5KyEWrJkifLz88/o+Kfz8ssva9myZeVuX3zxRYX9rrvuOjVp0sT5c48ePdSzZ099/vnnkqSMjAxt3LhRt956q+rXr+/cr0OHDurbt69zP5vNpgULFmjgwIGVzrIymUzlfh41alS5bRdffLGsVmul7Y4AAMBu7ty5io2N1WWXXSbJ/vt12LBhev/992W1Wp37zZ8/Xx07dqxQTeR4jGOfhg0b6r777qtyn5q4++67K2wLDQ11fp+Xl6ejR4/qwgsvlGEY+vHHHyVJR44c0bfffqvbbrtNzZs3rzKeESNGqKioSB999JFz27x581RaWlrtzKZhw4appKSkXDvc0qVLlZWVpWHDhjm3RUdHa/Xq1UpPT3fxVVdv1KhRFc7Nli1bptTU1HL7JSQklPvcIiMjNWLECP3444/KzMyUJH3++efq0aOHevfu7dyvXr16GjVqlPbs2aPt27dLOrPPeNiwYYqJiXH+fPHFF0uytwkC5yqSUgBq5MiRI8rPz1fr1q0r3Ne2bVvZbDbt379fkn2VuqysLJ133nlq3769xo4dq82bNzv3Dw4O1jPPPKMvvvhCsbGx6tOnj6ZOneo8KTidG2+8UWaz2dmSZhiGPvzwQ+ecK0lKTk7WmDFj9MYbb6hhw4bq37+/Xn755bOeJ9WjRw+lpaWVuzlOYE/VqlWrCtvOO+8857wsR5Koqvfy6NGjysvL05EjR5STk6N27dq5FN8fTzYdJ0FnmvgDAOBcYbVa9f777+uyyy7T7t27tXPnTu3cuVM9e/bUoUOHtHz5cue+u3btqvZ38q5du9S6detyrWNnKyAgQE2bNq2wfd++fc4LXPXq1VOjRo10ySWXSJLznMeR/Kgu7jZt2qh79+7lZmnNnTtXF1xwQbWrEHbs2FFt2rQpNy5g3rx5atiwoS6//HLntqlTp2rr1q1q1qyZevTooYkTJ551cqZVq1YVzs3S0tKc54QOLVu2rJAwOu+88ySp3PlZVedmjvulM/uMOTcDKiIpBaDW9enTR7t27dKbb76pdu3a6Y033lCXLl30xhtvOPd54IEH9Msvv2jKlCkKCQnR448/rrZt2zqv7FUlISFBF198sT744ANJ0g8//KB9+/aVuxInSc8//7w2b96sv//97yooKND999+v888/XwcOHHD/C/YSFoul0u2GYdRxJAAA+IavvvpKGRkZev/999WqVSvnbejQoZJU5cDzs1FVxdSpVVmnCg4OltlsrrBv37599dlnn+mRRx7RggULtGzZMueQdJvNdsZxjRgxQt98840OHDigXbt26YcffnB5Zbthw4bp66+/1tGjR1VUVKSFCxfqhhtuKJe4GTp0qH777Te9+OKLSkhI0LPPPqvzzz+/0qpzf8G5GVARSSkANdKoUSOFhYVpx44dFe77+eefZTab1axZM+e2+vXra+TIkXrvvfe0f/9+dejQQRMnTiz3uJSUFD300ENaunSptm7dquLiYj3//PPVxjJs2DBt2rRJO3bs0Lx58xQWFqaBAwdW2K99+/b6xz/+oW+//VbfffedDh48qJkzZ575iz9DlbUt/vLLL87h5YmJiZJU5XvZsGFDhYeHq1GjRoqMjKx05T4AAHD25s6dq8aNG+vDDz+scBs+fLg++eQT52p2KSkp1f5OTklJ0Y4dO1RSUlLlPo5qmaysrHLbz6TdfsuWLfrll1/0/PPP65FHHtGgQYOUlpamhISEcvs5Ri64ci5x0003yWKx6L333tPcuXMVGBhY4aJfVYYNG6bS0lLNnz9fX3zxhXJycnTTTTdV2C8+Pl733HOPFixYoN27d6tBgwZ66qmnXHqOs7Fz584KiaBffvlFksqdn1V1bua4X3LtMwZQNZJSAGrEYrGoX79++u9//+ssc5bsK5W8++676t27t7NU+vfffy/32Hr16qlly5YqKiqSZF8ppbCwsNw+KSkpioiIcO5zOjfccIPzpOnDDz/UNddco/DwcOf9OTk5Ki0tLfeY9u3by2w2lzv+vn37nCca7rRgwQIdPHjQ+fOaNWu0evVqXXnllZLsJ2SdOnXS22+/Xe6EdOvWrVq6dKmuuuoqSZLZbNZ1112nRYsWad26dRWeh6tsAADUXEFBgT7++GNdc801GjJkSIXb6NGjlZubq4ULF0qyn39s2rRJn3zySYVjOX4n33DDDTp69KheeumlKvdJTEyUxWLRt99+W+7+V155xeXYHRU4p54LGIahf//73+X2a9Sokfr06aM333xT+/btqzQeh4YNG+rKK6/UnDlzNHfuXA0YMEANGzZ0KZ62bduqffv2mjdvnubNm6f4+Hj16dPHeb/Vaq0wRqFx48ZKSEgod2529OhR/fzzz26dCSrZVzM+9XPLycnRO++8o06dOikuLk6SdNVVV2nNmjVatWqVc7+8vDy99tprSkpKcs6pcuUzBlA19zU3A/BLb775phYvXlxh+1//+lc9+eSTWrZsmXr37q177rlHAQEBevXVV1VUVKSpU6c6901NTdWll16qrl27qn79+lq3bp1zCWDJfmXqiiuu0NChQ5WamqqAgAB98sknOnToUKVX1f6ocePGuuyyyzRt2jTl5uZWuIr31VdfafTo0brxxht13nnnqbS0VLNnz5bFYtENN9zg3M9Rpu7qCcQXX3xRaRLrwgsvLDf8vWXLlurdu7fuvvtuFRUVafr06WrQoIEefvhh5z7PPvusrrzySvXq1Uu33367CgoK9OKLLyoqKqpcRdk///lPLV26VJdccolGjRqltm3bKiMjQx9++KFWrlyp6Ohol2IHAADlLVy4ULm5ubr22msrvf+CCy5Qo0aNNHfuXA0bNkxjx47VRx99pBtvvFG33XabunbtqmPHjmnhwoWaOXOmOnbsqBEjRuidd97RmDFjtGbNGl188cXKy8vTl19+qXvuuUeDBg1SVFSUbrzxRr344osymUxKSUnRp59+qsOHD7sce5s2bZSSkqK//e1vOnjwoCIjIzV//vxKZxW98MIL6t27t7p06aJRo0YpOTlZe/bs0WeffaaNGzeW23fEiBEaMmSIJGny5Mmuv5myV0uNHz9eISEhuv3228u1HObm5qpp06YaMmSIOnbsqHr16unLL7/U2rVry1XJv/TSS5o0aZK+/vprXXrppdU+54YNGzRnzpwK21NSUtSrVy/nz+edd55uv/12rV27VrGxsXrzzTd16NAhzZo1y7nPo48+qvfee09XXnml7r//ftWvX19vv/22du/erfnz5ztfjyufMYDT8MiafwC83qxZs067tO7+/fsNwzCMDRs2GP379zfq1atnhIWFGZdddpnx/ffflzvWk08+afTo0cOIjo42QkNDjTZt2hhPPfWUUVxcbBiGYRw9etS49957jTZt2hjh4eFGVFSU0bNnT+ODDz5wOd7XX3/dkGREREQYBQUF5e777bffjNtuu81ISUkxQkJCjPr16xuXXXaZ8eWXX5bb75JLLjFc+d9ide+NY+lmx/K/zz77rPH8888bzZo1M4KDg42LL77Y2LRpU4Xjfvnll8ZFF11khIaGGpGRkcbAgQON7du3V9hv7969xogRI4xGjRoZwcHBRosWLYx7773XKCoqKhff2rVryz2uqiWnAQCAYQwcONAICQkx8vLyqtzn1ltvNQIDA42jR48ahmEYv//+uzF69GijSZMmRlBQkNG0aVPjlltucd5vGIaRn59vPPbYY0ZycrIRGBhoxMXFGUOGDDF27drl3OfIkSPGDTfcYISFhRkxMTHGX/7yF2Pr1q3lzisMwzBuueUWIzw8vNLYtm/fbqSlpRn16tUzGjZsaNx5553Gpk2bKhzDMAxj69atxuDBg43o6GgjJCTEaN26tfH4449XOGZRUZERExNjREVFVTi/qs6vv/7qPDdauXJlheOOHTvW6NixoxEREWGEh4cbHTt2NF555ZVy+02YMMGlcxfHOVdVt1tuucW5b2JionH11VcbS5YsMTp06GAEBwcbbdq0MT788MMKx921a5cxZMgQ5/vUo0cP49NPP62wX3Wf8annhH8kyZgwYcJpXx/gz0yGQU0hANSGPXv2KDk5Wc8++6z+9re/eTocAACAM1JaWqqEhAQNHDhQ//nPfzwdjlskJSWpXbt2+vTTTz0dCgAxUwoAAAAAUIkFCxboyJEjGjFihKdDAeCnmCkFAAAAAHBavXq1Nm/erMmTJ6tz58665JJLPB0SAD9FpRQAAAAAwGnGjBm6++671bhxY73zzjueDgeAH2OmFAAAAAAAAOoclVIAAAAAAACocySlAAAAAAAAUOfOuUHnNptN6enpioiIkMlk8nQ4AADACxmGodzcXCUkJMhs5hreqTiXAgAA1XH1XOqcS0qlp6erWbNmng4DAAD4gP3796tp06aeDsOrcC4FAABcVd251DmXlIqIiJBkf2MiIyM9HA0AAPBGOTk5atasmfO8ASdxLgUAAKrj6rnUOZeUcpSZR0ZGciIFAABOi/a0ijiXAgAArqruXIohCQAAAAAAAKhzJKUAAAB8wLfffquBAwcqISFBJpNJCxYsKHe/YRgaP3684uPjFRoaqrS0NP3666/l9jl27JhuvvlmRUZGKjo6WrfffrtOnDhRh68CAADgJJJSAAAAPiAvL08dO3bUyy+/XOn9U6dO1QsvvKCZM2dq9erVCg8PV//+/VVYWOjc5+abb9a2bdu0bNkyffrpp/r22281atSounoJAAAA5ZgMwzA8HURdysnJUVRUlLKzs5mDAAA4Y1arVSUlJZ4OA24QFBRU5RLF3n6+YDKZ9Mknn+i6666TZK+SSkhI0EMPPaS//e1vkqTs7GzFxsbqrbfe0k033aSffvpJqampWrt2rbp16yZJWrx4sa666iodOHBACQkJLj23t783AADA81w9XzjnBp0DAFAThmEoMzNTWVlZng4FbmI2m5WcnKygoCBPh3LWdu/erczMTKWlpTm3RUVFqWfPnlq1apVuuukmrVq1StHR0c6ElCSlpaXJbDZr9erVGjx4sCdCBwAA5zCSUgAAuMCRkGrcuLHCwsJYlc3H2Ww2paenKyMjQ82bN/f5zzMzM1OSFBsbW257bGys877MzEw1bty43P0BAQGqX7++c5/KFBUVqaioyPlzTk6Ou8IGAADnOJJSAABUw2q1OhNSDRo08HQ4cJNGjRopPT1dpaWlCgwM9HQ4XmvKlCmaNGmSp8MAAAB+iEHnAABUwzFDKiwszMORwJ0cbXtWq9XDkZy9uLg4SdKhQ4fKbT906JDzvri4OB0+fLjc/aWlpTp27Jhzn8qMGzdO2dnZztv+/fvdHD0AADhXkZQCAMBFvt7ihfL86fNMTk5WXFycli9f7tyWk5Oj1atXq1evXpKkXr16KSsrS+vXr3fu89VXX8lms6lnz55VHjs4OFiRkZHlbgAAAO5A+x4AAIAPOHHihHbu3On8effu3dq4caPq16+v5s2b64EHHtCTTz6pVq1aKTk5WY8//rgSEhKcK/S1bdtWAwYM0J133qmZM2eqpKREo0eP1k033eTyynsAAADuRKUUAAA4I0lJSZo+fbqnwzjnrFu3Tp07d1bnzp0lSWPGjFHnzp01fvx4SdLDDz+s++67T6NGjVL37t114sQJLV68WCEhIc5jzJ07V23atNEVV1yhq666Sr1799Zrr73mkdcDAABgMgzD8HQQdSknJ0dRUVHKzs52e/m51WZoze5jOpxbqMYRIeqRXF8Ws/+0BgDAuaqwsFC7d+9WcnJyuT/wa6Iuf1dU1542YcIETZw48YyPe+TIEYWHh5/VjK1LL71UnTp18mhy63Sfa22eL/g63hsAOEfYrNLe76UTh6R6sVLihZLZ4umo4CNcPV+gfc9NFm/N0KRF25WRXejcFh8VogkDUzWgXbwHIwMAeIu6/l2RkZHh/H7evHkaP368duzY4dxWr1495/eGYchqtSogoPpTg0aNGrk3UAAAaou7EyvuPJ43J322L5QWPyLlpJ/cFpkgDXhGSr3Wc3Gdyps/W3fz49dK+54bLN6aobvnbCj3R4YkZWYX6u45G7R4a0YVjwQAnCs88bsiLi7OeYuKipLJZHL+/PPPPysiIkJffPGFunbtquDgYK1cuVK7du3SoEGDFBsbq3r16ql79+768ssvyx33j+17JpNJb7zxhgYPHqywsDC1atVKCxcuPKvY58+fr/PPP1/BwcFKSkrS888/X+7+V155Ra1atVJISIhiY2M1ZMgQ530fffSR2rdvr9DQUDVo0EBpaWnKy8s7q3gAAHXEZpV2fydt+cj+1XYWK6RuXyhNbye9fY00/3b71+nt7Ns9fTx3xya5773bvlD6YET5hJQk5WTYt59NjO7izZ+tdO78O3YDklJnyWozNGnRdlXWA+nYNmnRdllt51SXJAD4PcMwlF9c6tItt7BEExZuO+3viokLtyu3sMSl47mz8/7RRx/V008/rZ9++kkdOnTQiRMndNVVV2n58uX68ccfNWDAAA0cOFD79u077XEmTZqkoUOHavPmzbrqqqt0880369ixYzWKaf369Ro6dKhuuukmbdmyRRMnTtTjjz+ut956S5J9ttL999+vJ554Qjt27NDixYvVp08fSfbqsOHDh+u2227TTz/9pBUrVuj6669363sGwA+58w9Ib+fNr9XdSR93JlbcebzaSPq4672zWe0VUqc7a1n8aM3+3Xhr0qw2jncu/Dt2E9r3ztKa3ccqXPU+lSEpI7tQa3YfU6+UBnUXGACgVhWUWJU6folbjmVIyswpVPuJS13af/sT/RUW5J5f4U888YT69u3r/Ll+/frq2LGj8+fJkyfrk08+0cKFCzV69Ogqj3Prrbdq+PDhkqR//vOfeuGFF7RmzRoNGDDgjGOaNm2arrjiCj3++OOSpPPOO0/bt2/Xs88+q1tvvVX79u1TeHi4rrnmGkVERCgxMdE5/DsjI0OlpaW6/vrrlZiYKElq3779GccAnPP8uFWkAne3KXnze1cbLVnuis/xx/IfkyGOP5aHvuN6jNUmVkzSFw9LyX2kwDDJEiidbg6jK8db/KjU5mr7azcMqaRAKsm334rzpZI8+9eiE9Ki+09zLEmfPihFxEmhMVJwpBQcIQWGVh2jq++dzSrlHZFyM+2fV26GlHtIOpF58uvxvVL+0arfCxlSzkFpwT1SyzSpYUupQSspuN5pHiP3/duryWdhLZaK88p/FiUFZZ9HrvTpA6c5nqTP/yY17SGFN7D/W6nuddblv+NTX2tdH89NSEqdpcO5VSekarIfAAB1qVu3buV+PnHihCZOnKjPPvvMmeApKCiotlKqQ4cOzu/Dw8MVGRmpw4cP1yimn376SYMGDSq37aKLLtL06dNltVrVt29fJSYmqkWLFhowYIAGDBjgbB3s2LGjrrjiCrVv3179+/dXv379NGTIEMXExNQoFsBneHPiwptn07jzD0jH8bz1vXP3a3VnfK78sfz536TwRlJRjlRw/PS3E4el4hOneULDnpB5JvHkJkuwFBAsWYKkgBApIKhsW5BUUlSxsuSPx8s5KE1Nlqyl9uRHpa/FRflHpf/0Lb/NHGBPTgVHSMFRp3wfIe34vIrnK9v20W32BFf+Ucmw1TyuU21+335ziEiQGrYqu50nNWhp/xrZRPr505r927OWSoVZ5T/bfT+4+FmkSLayz8I4y2rAE4ekaa3t3wdF2N/L0Oiyr6fcQqKklf+q+DodcUn2BJhhSNaiPyTKHAnMsm0lBVL2Qdde67S2UlA9+78Rc4BkNtu/mizltxXluna8vd9LyRfX5J2qEZJSZ6lxhGurMLm6HwDAN4QGWrT9if4u7btm9zHdOmtttfu9NbK7eiTXd+m53SU8PLzcz3/729+0bNkyPffcc2rZsqVCQ0M1ZMgQFRcXn/Y4gYHlrxyaTCbZbG468f2DiIgIbdiwQStWrNDSpUs1fvx4TZw4UWvXrlV0dLSWLVum77//XkuXLtWLL76oxx57TKtXr1ZycnKtxAN4nDcnLmojESK5Jwnn7qoBb37vaqNC4mzis5bYE0eOCp09K6v/Y/nEIWnWmVffusxaZL+djcLsitsCQuzVWIFhUlCYVFokZe2t/lih9e2fW1GOJMOeYHEkZs6UrUTKK7tQZDJL4Y2liFipXpz9a0S8/b+jiDgpJ1P6fEz1x2zVz57kOPqrPdmVm26/7f6m/H6WkLKk0GkSNZ/cJW2d/4cEVFbZa6+hwkreJ3Og/TM49fMoLpCO7XT9uMW59lv26S/WVSn/d+nDETV7bFVOHJJ0yM3Hqzskpc5Sj+T6io8KUWZ2YaX/mZkkxUWFuPRHBgDAd5hMJpdb6C5u1cil3xUXt2oki/k07QN14H//+59uvfVWDR48WJK9cmrPnj11GkPbtm31v//9r0Jc5513niwW+x9LAQEBSktLU1pamiZMmKDo6Gh99dVXuv7662UymXTRRRfpoosu0vjx45WYmKhPPvlEY8a4cJIN1BVfbnlqdoG9esR8ylV4k8V+Jf5Mj1eTVpGzScJZS6SsfdKx36Rfl7lWNfDOIKl+C3tFSsipFSplbVUhkVJguPT5WPe9Vpcqh8ba4yrOsycHinLKbrn2W6Hj+2z7a3bltc66SopJOvm6/liZ49gWGCZ9cbrXK2nRX+3PmXf4lBaxslv+71U8thrhDaWoZmVVKdEVK1Uct2O/Sf+9p/rj/fljqUlXe3tXadEpX4vsXx3b0n+Uvn6q+uNd+5KU1FsKCre32wWGVfy8d39nnzFUnaHv2KtVDKPsMz71s80++f2e76TN86o/3hXjpU5/tr+Hp/s3aLNKK5+z/z+kqrOWyARp+Psnj5N/TPp9p3T0F3uS6uiv0u+/2j8HqwsdQyV50vYFVd8fHHWyMkmSMjZWf8yBL9g/i8Aw+2cRFF55652rn8eIhVJc+9NX6KVvlPb/UP2x6qdI0c3KJ8cCw8u+hp78Pmu/9N1z1R/vquek2Hb25J+ttOxms391brNKh7ZLK5+v/nj1Yqvfx41ISp0li9mkCQNTdfecDTKp/H+2jj8rJgxM9fgfGQAAz/Gl3xWtWrXSxx9/rIEDB8pkMunxxx+vtYqnI0eOaOPGjeW2xcfH66GHHlL37t01efJkDRs2TKtWrdJLL72kV155RZL06aef6rffflOfPn0UExOjzz//XDabTa1bt9bq1au1fPly9evXT40bN9bq1at15MgRtW3btlZeA1AjddbyJHuriLXIPsfG8Ues84/bnFMSF7lS3tHKqwtOPWZuhvR8qyruN5VPVBmG/Y/N0x0v56C09B9S8172P5bDG0lhDex/fFY2P8eVJFyrftLxPfY/iE+9Hd9t/yPvTFt59nxnv52Vstf6fBsp0IUOipLCk5UtVR3vRKY086KzjOsP9v/g2h/Vrig4VvbvswrmAPsfv/Vi7cmC/aurP+aQt1xrK2rWQ/r6yeoTKy0udS1JmHK5tH5W9cfr9Kfqj5d4oX3f6o6VeGHZjyb7vKaqZjbFJLmWlGraw14VVR2zxf7/og9G2GOp7KxlwNPlX2dYfSmsh/19P5W1RFr9qrT0seqft8NwKeWyylviLKekLWxW+9Dw6t6/zn927bN19fNI6m0/Xthpik1cTXAN/Ldr/45tVmnTu9XH1u02117r+VZp83uu/9urIySl3GBAu3jN+HMXTVq0vdzQ87ioEE0YmKoB7eI9GB0AwBv4yu+KadOm6bbbbtOFF16ohg0b6pFHHlFOzlmUz5/Gu+++q3fffbfctsmTJ+sf//iHPvjgA40fP16TJ09WfHy8nnjiCd16662SpOjoaH388ceaOHGiCgsL1apVK7333ns6//zz9dNPP+nbb7/V9OnTlZOTo8TERD3//PO68sora+U1AGesJpVNNqs9YXRqpcmJQ9LBH6upfpG9ImX+HW59CVUzTl6lPxM/vGK/ncocIIU1LEtUNbR/H9bA/gfa6ZJwH95afdIpMEyKSbZX/LiSgOk+SqrX2F5xVKEKqexr/lH7DJjqnDbRVANB9ezvT3Bk+cqtUyu5giPs/2Zcqbi44F57C5fjdRXmlE9iOrYVHLe3hFUnoYvUtNvJ1jBHu1i9OPvn6aiuczXR4OofyzVJrNTV8dwd25kmuVyReq39/0WVJs+fdj15bgmU4ju6tm/nm11L1HjzZ+vuz8KbX6sbmYxzbI3knJwcRUVFKTs7W5GRkW49ttVm6IF5P2rRpgxd2S5OL/2pi1dc9QYAnJ3CwkLt3r1bycnJCgk5uxmBVpuhNbuP6XBuoRpH2Nu7+V3hGaf7XGvzfMHX8d6cBecf3qdJJAVHSKnXlZ+3k3f47IYTN2wtNUipmKgIOSWRERxpb79ZdH/1xxuxSGp+QTWtIqXSvjXSgr9Uf7xmF0gy7KuC5R09uzkyDsGRUv1ke3vbH2/1Yu3VJ64mQh7YUv0faa5WSFw1TUroVP1+6Rtdm+tzy6euV1y467VKrr9eV+OTTknYSpX+sey2QexNziyxUlvHc/ex3P3eSe6b3ebOf3sO3vrZnmv/jk/D1fMFklJuNvObXXr6i591fZcmmja0k9uPDwCoe+5MSsF7kJSqGZ96b9y5Ip07jvXLUundG2v2/CazvbXNWXESa59140rbjqcSFzU9XmmRPTmVf7QsUfW7/eveldKOL6p/3mv+JXUdWXn73x+56w9Ib3nvTsedfyz7SqLBEau7/j/g7uPV+qqZ7k801Ig3J81q43jn2r/jKrh6vkD7nptFh9qHp2Xnu1DOCgAAgNrh7hXpzvRYhmGfa7R/jXRgjX1eTuZW156v7SCp5eXlW53CG5WfqyLZ/6jY853/tYoEBEtRTey3U8V3dC0p1aCVawkpyX1tSt7y3p2Ou15rbcXniLHN1e79Y9lsce/y9u48njuPVRvvnbu489/eqbz1sz3X/h2fJSql3Gzx1kzdNWe9ujSP1sf3uHnwIADAI6iU8k9UStWMT7w3Vc1tqslVeVePVVJgX6Fr/5qTiai8IzWLn5anytVWdY7j2N5YIeHtFRfeXJ0D71MH1Tn+yhfHP9C+V4XaPpH64bffddNrP6hFo3B99dClbj8+AKDukZTyTySlasbr35tq5zaZpIh46b719qW3T1dR48oMqKB69sqcQ1sqDvg2B9rnBzUtW5WqSVfpzX60PJ1t0qc22oDcyVvfu9ri7fEBLnJn4sedx1q8NaPCQjnxZ7lQTl0kuWjf85DoMNr3AAAAPGbv99WsSGdIuenSP8tO5C1BkiVYCgiSAkLsPwcE27+WFlW/ul3xCSnjR/v39WLtyaemPaRmPe3tZoF/SGTT8nR2aqsNyJ289b2rLd4e3znE26tp3B2ftyZ+3H2su+dsqHAZIzO7UHfP2aAZf+7i0fjcgaSUm8WEBUmSsgpKZBiGTK72swMAAODsZGyWvn32zB5jLbbfis/iebvfKV14nxTdvPpZRr4yW8WbefPsHMBDvC3R8Efujs9bEz/uPJbVZmjSou2V1tUasl/KmLRou/qmxrmcjKuNJNfZIinlZlFlg86tNkO5RaWKDAn0cEQAAAB+rDhf2vaJtO5N6eA61x83fJ69nc5aZK+IshZLpYVSaXHZtmL7jKivn6z+WKmDpJhE15+bpMrZO5eScEA1aivR4K5KJHfHV5eJH0n6x4KtahQRIsmQ1SaV2myy2owKt+JSmyYs3HbaYz30wSZ9++sRFZcaKiyxqrDEpqJSq/P7whKrCkvt358oLFFBia3K2A1JGdmFGvjiSiU2CFN0WKCiQoMUHRao6NDA8j+HBSoiOFAT3ZzkcgeSUm4WEmhRaKBFBSVWZeWVkJQCAACoDUd+kdbPkjbOlQqz7dvMgVKba+wr0uX/rtPObWrVt/okUMpl0vo33be63alIqgBwg9qoppHcV4nk7vhcOd6E/25Ts/phOlFYquyCEmUVlCinoMT+fb79q2P7oexCZeYUVnK0k46eKNYNM76v/sW6IK/YqndX73fLsRy2Z+Roe0bOWR/HkeRas/uYeqU0OPvAXERSqhZEhwWqINuqrIJiNVeYp8MBAADwDdUNTC4tln5eJK2bZU88OUQ3l7qOlDr/WarX+JRh2Gc5t6m2lr0HUGe8eY6RO6zZfaxc4uiPHImGt7/frYtbNVJMeJCiQwMVYDFX+ZizqUSy2QxlF5ToWH6xsvKLtWrX7y7FN+zVVYoOC5JkyGZINsP+1TAMGc6fDWXll1R7vEO5Rbr6hZVV7lMTMWGBigwNlMVkksV88hZgNslc9vVYXrF2Hcmr9lj9z49Tx2ZRCgmwKCTQopBA88mvARYFl33/c2auHvpgU7XHG31ZihpHhigr/9SkW7H957JEXFZ+sUptrq1xdzj39Ek6dyMpVQuiQgOVkV2oLIadAwAAuKbSFeQS7Emh+A7S+relH2dLeUfs95nM0nkDpG63SymXS+ZT/sBy59wmXxisDaBS3jzHSKp5gquwxKpt6TnauD9Ln22uZjGGMk98+pOkn5w/R4YEqH54kGLCgxQTZr/VDw9UVFigXv9292lb0MZ+tFnr9x1XTn6pjuUX63hecVkSyp78cDH3Uc66vcfP/EGnUS/YosYRIYp0trHZb9Gh9uRSVGigosOCdOB4viYt2l7t8V65uWu11UOrdv2u4a//UO2xbr0wyaVKpDZxkXpuyQ5lZhdWVauruKgQPdi3dbX/bgzD0IodRzTyrbXVPm/jiLpdaZqkVC1wDDs/nn82EzMBAH6pDpfOrm6xjQkTJmjixIk1PvYnn3yi6667zi374RznrGz6w2l3Trr0wf+V31YvTup6i9RlhBTVtOpjunNuEzOggDpzLswxchzPlQSXYRjafTRPG/dnOW8/ZeSoxHpmmZ/4yBAVlFqdhRM5haXKKSzVnt/zz+g4kpRbWKrXv9192n0iQgIUExakQIvJpeqh23snqWXjCJlN9nMHs8kkk+zXG8wmU9k2aefhE5r+5a/VHu/1Ed1dSvxYbYZe+/a3ahM/PZLrV3usHsn1FR8V4pZjSZLFbNKEgam6e86Gqmp1NWFgqkv/fZhMJvU5r5Fb43MXklK1IDrMPkcqu4BKKQDAKU5XCVIL1RYZGRnO7+fNm6fx48drx44dzm316tVz+3MCZ8xmtf93Uekp8ilaXCZ1v91eHWVxcWanO+c2MQMKfsKb29m8YY6RYRgqsRplw6atKiqxKa+oVI8t2Hra6qEJC7fpkvMaKzSo+mR1dQmuey5LUYDZ7ExCVfZ3ZcN6QerULFodmkbpre/36nhe8WkTDSsfuVwWs0mlVpuyC0p0PL9Ex/OLdSzPXunk+Hnj/iyt2X2s2tdwaetG6pYYo5jwINUPO6XiKjxQ0aFBCgqwV69abYZ6P/NVtYmQv1/lWnLFajM0b+1+r0z8uPNYDgPaxWvGn7tU+O8irgb/XdRGfO5AUqoWOJJSx/NISgEAylRZCZJh3z70HbcnpuLi4pzfR0VFyWQyldv2xhtv6Pnnn9fu3buVlJSk+++/X/fcc48kqbi4WGPGjNH8+fN1/PhxxcbG6q677tK4ceOUlJQkSRo8eLAkKTExUXv27Dnj+Gw2m5588km99tprOnLkiNq2baunn35aAwYMqDYGwzA0adIkvfnmmzp06JAaNGigIUOG6IUXXqjhuwWP2ft9+URtVS5+iKQQzknemPSpjePVpBKp1GpTbmGpThSVKqewRLmFpcotLNWP+467NMfosudWKMBsKlvxrGzlsxJrjdrPDuUUqe34xQq0mBQWFKDwIItCgywKDw5QWJBF4UEBCgsOUGigWZ9uzjhtguvlr3eV2x4UYFa7hEh1ahajTs2j1blZtJrGhDoros+LjXA50RBgMatBvWA1qBdc6etwtQXtL31SXKpEcncixNsTP+481qnH7Jsa55b/D9RGfGeLpFQtiC5r38sqoH0PAPyWYUglLpa826zSFw+r8kqQsmu2ix+RWlzqWjtQYJhUTWtedebOnavx48frpZdeUufOnfXjjz/qzjvvVHh4uG655Ra98MILWrhwoT744AM1b95c+/fv1/799tVi1q5dq8aNG2vWrFkaMGCALJaatTD9+9//1vPPP69XX31VnTt31ptvvqlrr71W27ZtU6tWrU4bw/z58/Wvf/1L77//vs4//3xlZmZq06bqh4HCC5045N79AD/i6aRPXRyvxGrT0dwi/aOaSqS/vr9RbeJ26URRqTP5VFBidTneyuw7Vv3v8ZBAs8wmk/KLXXuuEqvhXN3tbFzcsqH6nh+rTs2i1SYu0ll5VBl3Jhrc3YLm7vhq43iOY7oz8eOuYzlYzCa3rYhXG/GdDZJStSA6tKx9j0HnAOC/SvKlfya46WCGvVLk6Wau7f73dCko/KyeccKECXr++ed1/fXXS5KSk5O1fft2vfrqq7rlllu0b98+tWrVSr1795bJZFJiYqLzsY0aNZIkRUdHl6u8OlPPPfecHnnkEd10002SpGeeeUZff/21pk+frpdffvm0Mezbt09xcXFKS0tTYGCgmjdvrh49etQ4FnhQvVj37gf4ibNdAe1EsT1xk1NQoqy8Yo37eMtpkz6Pzt+iklJDYcEnVwQLrrA6mEUhAWaZTKbTtsdJ0j8WbFVwgEVZBcX6/YS9TexYXrF+zzvl+xNFyiksden9KCq1adOB7ErvCw20KCIkoOwWKKvNpi0Hc6o95rgr26hz8xgFB5jLv84Ai4IDzQoue62uVg+9cUs3nZ8Qqbwiq/KLS09+LbYqv8j+df2eY/p8a2a1xxrSrakGdWpS7X4O7ko01FaLl7sTId6e+HHnsWqDN8XnFUmpl19+Wc8++6wyMzPVsWNHvfjiiy6dWL7//vsaPny4Bg0apAULFtR+oC5i0DkAwJvl5eVp165duv3223XnnXc6t5eWlioqKkqSdOutt6pv375q3bq1BgwYoGuuuUb9+vVzWww5OTlKT0/XRRddVG77RRdd5Kx4Ol0MN954o6ZPn64WLVpowIABuuqqqzRw4EAFBHjFqQ3OROKF9tlqORmqvJrQZL8/8cK6jgzwmOpmIknSmA82acnWTOUWWZVTWKKcAnv7Wk5hiU4Ulco4wxa0rIIS3ff+jy7tazap2ha3oyeKXVrpS1KF5EdV7uidrCvaxioiJECRIYGKCAlQvZAABVrKVxG5OsfojotbuJTEcLV66LLWjas9Xmp8pEtJqZqsgOauRENttXi5OxHiTYkV1JzHz9zmzZunMWPGaObMmerZs6emT5+u/v37a8eOHWrcuHGVj9uzZ4/+9re/6eKLvW+2QFTZTKksBp0DgP8KDLNXLLli7/fS3CHV73fzR6794R0Y5trzVuHEiROSpNdff109e/Ysd5+jFa9Lly7avXu3vvjiC3355ZcaOnSo0tLS9NFHH53Vc5+J08XQrFkz7dixQ19++aWWLVume+65R88++6y++eYbBQa6OAQb3sFssQ/7/2CEKv5pWvbH3YCnWekOPuNsZ0AVFFv17pq9p52JJEn5xVZ9svH0v4eCLGZFhgbIbDLpcG5Rtc+d0ihc9YIDVFhicw76Liyxz1oqKrU593N15lJCdKhaNAxX/fCgcrcGjq/1glQ/PFg/ZeTo5jdWV3u8K9rG+vwco9poj6sN3tbiBf/l8aTUtGnTdOedd2rkyJGSpJkzZ+qzzz7Tm2++qUcffbTSx1itVt18882aNGmSvvvuO2VlZdVhxNWjfQ8AzgEmk+stdCmXu1YJknJ5nfzhHRsbq4SEBP3222+6+eabq9wvMjJSw4YN07BhwzRkyBANGDBAx44dU/369RUYGCirteazPCIjI5WQkKD//e9/uuSSS5zb//e//5Wrlj5dDKGhoRo4cKAGDhyoe++9V23atNGWLVvUpUuXGscFD0m91j7sv9LVKZ+uldUpgVO5a5h4TWZAHcop1Pq9x7Vuz3Gt33tM29JzVOpi1ufajgnqldLAWTkUGRpYroooJND+O8XV9rMnr2tfZdLHZjNUbLUnqP6383fd++6Gao/3/I0dXUoiXdCiwTkzx8hbV0CrDJVIqAseTUoVFxdr/fr1GjdunHOb2WxWWlqaVq1aVeXjnnjiCTVu3Fi33367vvvuu9M+R1FRkYqKTl4VyMmpvrf4bMWE074HADiFF1aCTJo0Sffff7+ioqI0YMAAFRUVad26dTp+/LjGjBmjadOmKT4+Xp07d5bZbNaHH36ouLg4RUdHS5KSkpK0fPlyXXTRRQoODlZMTEyVz7V7925t3Lix3LZWrVpp7NixmjBhglJSUtSpUyfNmjVLGzdu1Ny5cyXptDG89dZbslqt6tmzp8LCwjRnzhyFhoaWmzsFH5N6rdTmantl4YlD9hlSiRdSIYVKeeOKdK7MgOqbGqcdmblav/eYPRG197gOHC+ocKzo0ECXui6G92juUtLAHdU5ZrNJIWb7XKkB7eLcmkQ61+YYeeMKaICneDQpdfToUVmtVsXGlh9cGRsbq59//rnSx6xcuVL/+c9/KpzcVmXKlCmaNGnS2YZ6RpyVUgUlstkMmb0gyw0A8DAvqwS54447FBYWpmeffVZjx45VeHi42rdvrwceeECSFBERoalTp+rXX3+VxWJR9+7d9fnnn8tsts/teP755zVmzBi9/vrratKkifbs2VPlc40ZM6bCtu+++07333+/srOz9dBDD+nw4cNKTU3VwoUL1apVq2pjiI6O1tNPP60xY8bIarWqffv2WrRokRo04IquTzNbpGTvG80A7+KNK9K5MgPqr+9vVIDZpLw/rOJmNkmt4yLVLTFGXctu8VEhunjq116b9KmNJNK5NseI9jjAzmQYZzoCz33S09PVpEkTff/99+rVq5dz+8MPP6xvvvlGq1eX7yvOzc1Vhw4d9Morr+jKK6+UZB+CmpWVVeWg88oqpZo1a6bs7GxFRka6/0VJKiq1qvU/FkuSNo3v55wxBQDwTYWFhdq9e7eSk5MVEnLmg0fLsVmpBPESp/tcc3JyFBUVVavnC76K9waeVFUSyfFnvKtJJOnkMOyqZjc5Ej+LH+ijwhKrThSVKq+oVCcKS+3fF5fqRJFVeUWl+jkjRwuqme/kEB5kUefm9uRTt6QYdWoWrYiQin8vOF6rVHnS50xe66nHdFdCrzaOJ7m3Cg6A57h6vuDRSqmGDRvKYrHo0KFD5bYfOnSo0iWmd+3apT179mjgwIHObTabfeBeQECAduzYoZSUlHKPCQ4OVnBwcC1EX7XgAIvCgizKL7Yqq6CYpBQA4CQqQQCgRlypRnp8wTY1rBesYqtNRSU2FZRYVVBsVWGp/WtRqc3+c4lVe37PO+0wcUNSRnahOk5a6rbXMLZ/a911SYpLSZbaqBzy1na2UzHHCDi3eDQpFRQUpK5du2r58uW67rrrJNmTTMuXL9fo0aMr7O8YYHqqf/zjH8rNzdW///1vNWvWrC7Cdkl0aKA9KZVfokT+nwoAAIBz2NlWv9hshhZsPFjtinRHThRpyMyqZ9PWlNkk1QsOUL3gAIWX3ezfWxQeHKC8wlIt2X6o2uN0aR5zxi1t3p70IYkE4Gx4fPW9MWPG6JZbblG3bt3Uo0cPTZ8+XXl5ec7V+EaMGKEmTZpoypQpCgkJUbt27co93jFw9Y/bPS06LEjp2YUMOwcAAMA57UxbvAzD0IHjBdpyMFubDmRp8/5sbT2YrdyiUpeer354oBqEBys0yKKQAItCgiwKDTQrJNCi0ED7oO6QQIuO5hbpow0Hqj3e2yO7q895jWQyVZ0IcrQCunP1OAeSPgD8mceTUsOGDdORI0c0fvx4ZWZmqlOnTlq8eLFz+Pm+ffucQ1V9SXTYyWHnAAAAwLnIlUHiXRJjtHl/tjYfyNLmg9nafCBbx/IqXtgNNJtUYqt+HO7Lf+rqUhLHajP0v11Hq00k9W51+oSUVHurxwGAv/N4UkqSRo8eXWm7niStWLHitI9966233B+QGziSUscr+YUKAAAA+DtXZkDdM3eDKsszBZhNahMfoQ5No9WhSZQ6NI1WSqNwXfrcCq9dka62Vo8DAH/mFUkpfxQdFiRJyqJSCgD8hmNxDfgHDy5ADHi9s50BZRiGFm/NrHYGlCMhdV5sPXsCqqk9AdUmLkIhgRVXJnV3NZK7E0m1MQMKAPwZSalaEh1qr5TKyicpBQC+LigoSGazWenp6WrUqJGCgoKqbeWAdzMMQ0eOHJHJZFJgIKvkAqc60xlQVpuh3UdPaFt6jran52h7hv3r7y52DEwd0kFDu7m2YJEvrEjHDCgAcB1JqVoS46iUYtA5APg8s9ms5ORkZWRkKD093dPhwE1MJpOaNm0qi6ViNQZwrqpuBtT0mzopsUG4tqVna3t6jral5+jnzBwVllSsJDWbVGlr3h81iwk7oxh9YUU6AIBrSErVkqiymVK07wGAfwgKClLz5s1VWloqq9Xq6XDgBoGBgSSkgFO4MgPqr+9vrPSxoYEWtY2PUGpCpM5PiFJqfKRaNq6ntGnfsCIdAKBKJKVqiaN97zjtewDgNxytXrR7AfA3hmHos83p1c6AkqTIkAB1bBat8xOidH5CpFITIpXUILzSSiVWpAMAnA5JqVoSE25v38umfQ8AAAC17EwHk1tthn7KyNG6Pce0du9xrd9zXJk51SekJGnyoHYa1LmJS/uyIh0A4HRIStUS56Bz2vcAAABQi1wZTJ5fXKqN+7K0bu9xrd1zTD/uy9KJotJyx3F1BlTjyJAzio8V6QAAVSEpVUuiywadZxeUyGoz+KULAAAAt6tqMHlGdqHumrNBV7RprKMnirQ1PUfWP2ScIoID1CUxRt2TYtQtqb7aJUSp77+YAQUAqDskpWpJVFmllGFIuYUlziQVAAAA4A6nG0zusPznw87v46NC1D2pvrolxahbYn21jouocOGUGVAAgLpk9nQA/ioowKzwIPuKPlkMOwcAAHUgNzdXDzzwgBITExUaGqoLL7xQa9eudd5/4sQJjR49Wk2bNlVoaKhSU1M1c+ZMD0aMs7Fm9zGXBpOPvixF/3v0cq0ad4VeGN5ZI3olKTUhstLkkmMGVFxU+Ra9uKgQzfhzF2ZAAQDcikqpWhQdFqS84gIdzy9WksI9HQ4AAPBzd9xxh7Zu3arZs2crISFBc+bMUVpamrZv364mTZpozJgx+uqrrzRnzhwlJSVp6dKluueee5SQkKBrr73W0+HjDLk6mLxVbISaRIe6fFxmQAEA6gqVUrUoOoxh5wAAoG4UFBRo/vz5mjp1qvr06aOWLVtq4sSJatmypWbMmCFJ+v7773XLLbfo0ksvVVJSkkaNGqWOHTtqzZo1Ho4eZ2pberZe+upXl/ZtHHFmg8mlkzOgBnVqol4pDUhIAQBqBUmpWhRTNkcqK7/Yw5EAAAB/V1paKqvVqpCQ8gmI0NBQrVy5UpJ04YUXauHChTp48KAMw9DXX3+tX375Rf369fNEyKiBvKJSPfnpdl370v+060ieTpcqMsk+R6omg8kBAKgLtO/VoihHpRQzpQAAQC2LiIhQr169NHnyZLVt21axsbF67733tGrVKrVs2VKS9OKLL2rUqFFq2rSpAgICZDab9frrr6tPnz5VHreoqEhFRUXOn3Nycmr9taByy7Yf0oT/blV62Rypq9vH6+JWDTXu4y2SGEwOAPA9JKVqUXQoSSkAAFB3Zs+erdtuu01NmjSRxWJRly5dNHz4cK1fv16SPSn1ww8/aOHChUpMTNS3336re++9VwkJCUpLS6v0mFOmTNGkSZPq8mXgD9KzCjRx4TYt3X5IktQ0JlSTB7XTZW0aS7KPjJi0aHu5oedxUSGaMDCVweQAAK9mMgzjdKvI+p2cnBxFRUUpOztbkZGRtfpczy3ZoZe+3qlbeiVq0qB2tfpcAADAferyfKE25OXlKScnR/Hx8Ro2bJhOnDihjz76SFFRUfrkk0909dVXO/e94447dODAAS1evLjSY1VWKdWsWTOffW98SanVprdX7dW0pTuUV2xVgNmkO/u00P2Xt1Jo2SrPDlabwWByAIDXcPVcikqpWsSgcwAA4Anh4eEKDw/X8ePHtWTJEk2dOlUlJSUqKSmR2Vx+pKjFYpHNZqvyWMHBwQoODq7tkPEHm/Zn6e+fbNG2dHu7ZNfEGP1zcHu1jouodH/HYHIAAHwJSalaFFXWvnec9j0AAFAHlixZIsMw1Lp1a+3cuVNjx45VmzZtNHLkSAUGBuqSSy7R2LFjFRoaqsTERH3zzTd65513NG3aNE+Hfs6pqrIpt7BEzy3ZoXd+2CvDkCJDAjTuqrYa1q2ZzFQ+AQD8DEmpWuRYfS+b1fcAAEAdyM7O1rhx43TgwAHVr19fN9xwg5566ikFBtovlL3//vsaN26cbr75Zh07dkyJiYl66qmndNddd3k48nPL4q0Zlc6AGtghXgs3petQjr1dcnDnJnrs6rZqWI9KNQCAfyIpVYto3wMAAHVp6NChGjp0aJX3x8XFadasWXUYEf5o8dYM3T1ng/441DUzu1Cvf7dbkpTcMFyTB7VT71YN6z5AAADqEEmpWhRdVil1PI9KKQAAgHOd1WZo0qLtFRJSp6oXHKBP7+ut8GBO0wEA/s9c/S6oKUelVE5hqay2c2qRQwAAAPzBmt3HyrXsVeZEUak2H8iuo4gAAPAsklK1yDHoXJJyaOEDAAA4JxmGoc0HsvTat7tc2v9w7ukTVwAA+AvqgmtRoMWsiOAA5RaV6nh+sWLCgzwdEgAAAOrIzsO5WrgxXQs3pWvP7/kuP65xREgtRgUAgPcgKVXLosIClVtUyrBzAAAAH2a1GVqz+5gO5xaqcUSIeiTXl8VsqrDfgeP5WrQpQws3peunjBzn9pBAs65o01jf7/pdWfkllc6VMsm+Cl+P5Pq190IAAPAiJKVqWUxYkA4cL1BWPsPOAQAAfNHirRmatGh7uXlQ8VEhmjAwVQPaxevoiSJ9viVDCzema93e4859AswmXXJeI13bKUFpbWMVHhzgXH3PJJVLTDnSWxMGplaa7AIAwB+RlKpljmHnWflUSgEAAPgaRxLpj5VNmdmFumvOBrWNj9Avh044F7UxmaSeyfV1bccmurJdXIXxDQPaxWvGn7tUSHLFnZLkAgDgXEFSqpY5hp2TlAIAAPAtVpuhSYu2V9pq59j2U0auJKlj0ygN7JigazokKC7q9DOhBrSLV9/UOJfaAQEA8GckpWpZTJj96hjtewAAAL5lze5j5aqZqvKvoR01uEvTMzq2xWxSr5QGNQ0NAAC/YPZ0AP7O2b7HoHMAAACfcji3+oSUJJmpcAIAoEZIStUyR/vecdr3AAAAfErjiNO34Z3pfgAAoDySUrWM9j0AAADf1CO5vhrWC6ryfpPsq/D1SK5fd0EBAOBHSErVMkf7XjbtewAAAD7l9xNFKrVVNubcnpCSpAkDUxlQDgBADTHovJZFl1VKHadSCgAAwGcUllh15+z1ysovUWxksCTpUE6R8/64qBBNGJiqAe3iPRUiAAA+j6RULXMOOmemFAAAgE8wDENjP9qsTfuzFB0WqHmjeqlZ/TCt2X1Mh3ML1TjC3rJHhRQAAGeHpFQtiy4bdJ5bWKpSq00BFjomAQAAvNmLX+3Uok3pCjCbNOPmrkpqGC5J6pXSwMORAQDgX8iQ1DLH6nsSc6UAAAC83edbMjRt2S+SpCeva0ciCgCAWkRSqpYFWMyKCLEXpGWRlAIAAPBaWw5ka8wHGyVJt/dO1k09mns2IAAA/BxJqToQUzbsPIth5wAAAF7pUE6h7nhnrQpLbLq0dSP9/aq2ng4JAAC/R1KqDjDsHAAAwHsVFFt15zvrdCinSK0a19MLwzszxBwAgDpAUqoOOOZKkZQCAADwLjabob99uEmbD2QrJixQ/7mluyJDAqt/IAAAOGskpeqAo33vOO17AAAAXuXfy3/VZ1syFGgxaeafu6p5gzBPhwQAwDmDpFQdcLTvsfoeAACA91i0KV3/Xv6rJOmp69qrZwtW2gMAoC6RlKoD0VRKAQAAeJVN+7P0tw83SZJG9Wmhod2beTgiAADOPSSl6kA0M6UAAAC8RkZ2ge58Z52KSm26ok1jPTKgjadDAgDgnERSqg7QvgcAAOAd8otLdec763Q4t0itYyP0b1baAwDAY0hK1QEGnQMAAHiezWbooQ82aevBHDUID9Ibt3RTveAAT4cFAMA5i6RUHYgKo30PAADA0/715S/6Ymumgixmzfy/rmpWn5X2AADwJC4N1QHHTKlsklIAAAB1xmoztGb3MR3OLdSvh3L10te7JEn/vL69uifV93B0AACApFQdcLTv5RaVqsRqU6CFAjUAAIDatHhrhiYt2q6M7MJy2/ulxmpI16YeigoAAJyK7EgdiAwNlKlsfibDzgEAAGrX4q0ZunvOhgoJKUlatv2QFm/N8EBUAADgj0hK1QGL2aTIEMdcKYadAwAA1BarzdCkRdtlnGafSYu2y2o73R4AAKAukJSqI9EMOwcAAKh1a3Yfq7RCysGQlJFdqDW7j9VdUAAAoFIkpeqIY9g5SSkAAIDaczi36oRUTfYDAAC1h6RUHYkuG3Z+nPY9AACAWtM4IsSt+wEAgNpDUqqOONr3GHQOAABQe3ok11d8VIhMVdxvkhQfFaIeyfXrMiwAAFAJklJ1JIZKKQAAgFpnMZs0YWBqpfc5ElUTBqbKYq4qbQUAAOoKSak6EsVMKQAAgDoxoF28Zvy5i4Is5RNPcVEhmvHnLhrQLt5DkQEAgFMFeDqAc4Vz9T3a9wAAAGrdgHbxSmywQ78eztPoy1J0UctG6pFcnwopAAC8CEmpOuJo38uifQ8AAKBOZBeUSpKubB+v8xOiPBwNAAD4I9r36khUGO17AAAAdcUwDGeFumMVZAAA4F1IStWRaGZKAQAA1JnCEpuKS22STp6HAQAA70JSqo7QvgcAAFB3sgrs51yBFpPCgiwejgYAAFSGpFQdcQw6zyu2Oq/aAQAAoHY4qtOjQoNkMjHcHAAAb0RSqo5EhgTKcT7kuHIHAACA2uFISjkuDAIAAO9DUqqOmM0mRZXNM8hmrhQAAKgFubm5euCBB5SYmKjQ0FBdeOGFWrt2bbl9fvrpJ1177bWKiopSeHi4unfvrn379nko4tqTXXYRkHlSAAB4L5JSdcg57LyApBQAAHC/O+64Q8uWLdPs2bO1ZcsW9evXT2lpaTp48KAkadeuXerdu7fatGmjFStWaPPmzXr88ccVEhLi4cjdj0opAAC8X4CnAziXRIcFSb/n63ge7XsAAMC9CgoKNH/+fP33v/9Vnz59JEkTJ07UokWLNGPGDD355JN67LHHdNVVV2nq1KnOx6WkpHgq5FrluAgYFRrk4UgAAEBVqJSqQ44rdVRKAQAAdystLZXVaq1Q9RQaGqqVK1fKZrPps88+03nnnaf+/furcePG6tmzpxYsWHDa4xYVFSknJ6fczRdQKQUAgPcjKVWHYsLsV+qy8qmUAgAA7hUREaFevXpp8uTJSk9Pl9Vq1Zw5c7Rq1SplZGTo8OHDOnHihJ5++mkNGDBAS5cu1eDBg3X99dfrm2++qfK4U6ZMUVRUlPPWrFmzOnxVNcdMKQAAvB9JqTrkGHSexaBzAABQC2bPni3DMNSkSRMFBwfrhRde0PDhw2U2m2Wz2SRJgwYN0oMPPqhOnTrp0Ucf1TXXXKOZM2dWecxx48YpOzvbedu/f39dvZyzkl1ApRQAAN6OpFQdon0PAADUppSUFH3zzTc6ceKE9u/frzVr1qikpEQtWrRQw4YNFRAQoNTU1HKPadu27WlX3wsODlZkZGS5my9wXASMCmOmFAAA3oqkVB2ifQ8AANSF8PBwxcfH6/jx41qyZIkGDRqkoKAgde/eXTt27Ci37y+//KLExEQPRVp7nDOlaN8DAMBrsfpeHXJWStG+BwAAasGSJUtkGIZat26tnTt3auzYsWrTpo1GjhwpSRo7dqyGDRumPn366LLLLtPixYu1aNEirVixwrOB1wLa9wAA8H5UStWh6LJKqeMkpQAAQC3Izs7WvffeqzZt2mjEiBHq3bu3lixZosBAe2Jm8ODBmjlzpqZOnar27dvrjTfe0Pz589W7d28PR+5+jsr06FDa9wAA8FZUStUhR/l4Nu17AACgFgwdOlRDhw497T633XabbrvttjqKyDOKS23KK7ZKkqKolAIAwGtRKVWHGHQOAABQ+xyte2aTFBHMNVgAALyVVySlXn75ZSUlJSkkJEQ9e/bUmjVrqtz3448/Vrdu3RQdHa3w8HB16tRJs2fPrsNoa87RvpdfbFVRqdXD0QAAAPin7AJ7VXpUaKDMZpOHowEAAFXxeFJq3rx5GjNmjCZMmKANGzaoY8eO6t+/vw4fPlzp/vXr19djjz2mVatWafPmzRo5cqRGjhypJUuW1HHkZy4iOECO86Js5koBAADUCufKe2HMkwIAwJt5PCk1bdo03XnnnRo5cqRSU1M1c+ZMhYWF6c0336x0/0svvVSDBw9W27ZtlZKSor/+9a/q0KGDVq5cWceRnzmz2aSoUFr4AAAAapMjKRUZyjwpAAC8mUeTUsXFxVq/fr3S0tKc28xms9LS0rRq1apqH28YhpYvX64dO3aoT58+tRmq28Q4VuDLY9g5AABAbXBc/IsmKQUAgFfz6OTHo0ePymq1KjY2ttz22NhY/fzzz1U+Ljs7W02aNFFRUZEsFoteeeUV9e3bt9J9i4qKVFRU5Pw5JyfHPcHXUBTDzgEAAGpVVtlKx9GsvAcAgFfzyeVIIiIitHHjRp04cULLly/XmDFj1KJFC1166aUV9p0yZYomTZpU90FWwVEp5ThZAgAAgHtlUykFAIBP8GhSqmHDhrJYLDp06FC57YcOHVJcXFyVjzObzWrZsqUkqVOnTvrpp580ZcqUSpNS48aN05gxY5w/5+TkqFmzZu55ATXgODnKYtA5AABArXCcZ0Ux6BwAAK/m0ZlSQUFB6tq1q5YvX+7cZrPZtHz5cvXq1cvl49hstnIteqcKDg5WZGRkuZsn0b4HAABQu5gpBQCAb/B4+96YMWN0yy23qFu3burRo4emT5+uvLw8jRw5UpI0YsQINWnSRFOmTJFkb8fr1q2bUlJSVFRUpM8//1yzZ8/WjBkzPPkyXEb7HgAAQO1iphQAAL7B40mpYcOG6ciRIxo/frwyMzPVqVMnLV682Dn8fN++fTKbTxZ05eXl6Z577tGBAwcUGhqqNm3aaM6cORo2bJinXsIZcZwc0b4HAABQO5wzpUhKAQDg1TyelJKk0aNHa/To0ZXet2LFinI/P/nkk3ryySfrIKraEV1WKXWcSikAAIBa4ZwpFcpMKQAAvJlHZ0qdixh0DgAAULto3wMAwDeQlKpjjpOjbAadAwAAuJ3VZiinsFQSg84BAPB2JKXqWAztewAAALUm55QLf1EkpQAA8GokpepYVFmlVGGJTYUlVg9HAwAA4F+yypJSEcEBCrBwqgsAgDfjN3UdiwgOkMVskkQLHwAAgLs55klFMU8KAACvR1KqjplMJud8A1r4AAAA3MtRKcWQcwAAvB9JKQ9wXLljBT4AAAD3yi47v4oODfJwJAAAoDokpTzAMew8i0opAAAAt6J9DwAA30FSygMc7XtUSgEAALiXs32PlfcAAPB6JKU8wNm+x6BzAAAAt3Jc9GOmFAAA3o+klAc42vcYdA4AAOBe2QXMlAIAwFeQlPIARzl5Nu17AAAAbsVMKQAAfAdJKQ+IDqdSCgAAoDYwUwoAAN9BUsoDGHQOAABQO7KdM6Vo3wMAwNuRlPIAx+DNbAadAwAAuJWzUor2PQAAvB5JKQ9g0DkAAID72WyGc6YU7XsAAHg/klIeEEX7HgAAgNudKC6VzbB/H0lSCgAAr0dSygNiygadF5XaVFBs9XA0AAAA/sExTyo00KKQQIuHowEAANUhKeUB4UEWBZhNkqSsAlr4AAAA3CGbeVIAAPiUAE8HcC4ymUyKDgvU0RPFysovUXxUqKdDAgAAbmaz2fTNN9/ou+++0969e5Wfn69GjRqpc+fOSktLU7NmzTwdot9xjEaIonUPAACfQKWUh0Qz7BwAAL9UUFCgJ598Us2aNdNVV12lL774QllZWbJYLNq5c6cmTJig5ORkXXXVVfrhhx88Ha5fcVSgUykFAIBvoFLKQxwrwmQz7BwAAL9y3nnnqVevXnr99dfVt29fBQZWTJDs3btX7777rm666SY99thjuvPOOz0Qqf9xVEpFhwZ5OBIAAOAKklIe4riCl1VAUgoAAH+ydOlStW3b9rT7JCYmaty4cfrb3/6mffv21VFk/o+ZUgAA+Bba9zyE9j0AAPxTdQmpUwUGBiolJaUWozm3ZJWdVzFTCgAA30CllIfQvgcAwLmjtLRUr776qlasWCGr1aqLLrpI9957r0JCQjwdml9xDjqnUgoAAJ9AUspDYsKplAIA4Fxx//3365dfftH111+vkpISvfPOO1q3bp3ee+89T4fmVxxjEZgpBQCAbyAp5SGOsvIsKqUAAPA7n3zyiQYPHuz8eenSpdqxY4csFoskqX///rrgggs8FZ7fclSgM1MKAADfwEwpD2HQOQAA/uvNN9/Uddddp/T0dElSly5ddNddd2nx4sVatGiRHn74YXXv3t3DUfqfrAJ7BXo0M6UAAPAJJKU8JKZs0HkW7XsAAPidRYsWafjw4br00kv14osv6rXXXlNkZKQee+wxPf7442rWrJneffddT4fpd5gpBQCAb6F9z0No3wMAwL8NGzZM/fv318MPP6z+/ftr5syZev755z0dlt8yDOPkTKkwZkoBAOALqJTyEMeg86z8EhmG4eFoAABAbYiOjtZrr72mZ599ViNGjNDYsWNVWFjo6bD8UmGJTcWlNkm07wEA4CtISnmI42Sp2GpTQYnVw9EAAAB32rdvn4YOHar27dvr5ptvVqtWrbR+/XqFhYWpY8eO+uKLLzwdot9xzJMKtJgUFmTxcDQAAMAVJKU8JCzIokCLSRItfAAA+JsRI0bIbDbr2WefVePGjfWXv/xFQUFBmjRpkhYsWKApU6Zo6NChng7TrzjnSYUGyWQyeTgaAADgCpJSHmIymZzzDo4z7BwAAL+ybt06PfXUUxowYICmTZumzZs3O+9r27atvv32W6Wlpbn9eXNzc/XAAw8oMTFRoaGhuvDCC7V27dpK973rrrtkMpk0ffp0t8fhCY6kVDRDzgEA8BkkpTzI0cKXTaUUAAB+pWvXrho/fryWLl2qRx55RO3bt6+wz6hRo9z+vHfccYeWLVum2bNna8uWLerXr5/S0tJ08ODBcvt98skn+uGHH5SQkOD2GDwlu6x9j3lSAAD4DpJSHuS4kudYKQYAAPiHd955R0VFRXrwwQd18OBBvfrqq7X+nAUFBZo/f76mTp2qPn36qGXLlpo4caJatmypGTNmOPc7ePCg7rvvPs2dO1eBgf6TwKFSCgAA3xPg6QDOZbTvAQDgnxITE/XRRx/V6XOWlpbKarUqJCSk3PbQ0FCtXLlSkmSz2fR///d/Gjt2rM4//3yXjltUVKSioiLnzzk5Oe4L2o0cF/miQoM8HAkAAHAVlVIe5CgvZ9A5AAD+Iy8vr1b3r0pERIR69eqlyZMnKz09XVarVXPmzNGqVauUkZEhSXrmmWcUEBCg+++/3+XjTpkyRVFRUc5bs2bN3BKvu1EpBQCA7yEp5UEx4fYreVlUSgEA4Ddatmypp59+2pkIqoxhGFq2bJmuvPJKvfDCC2577tmzZ8swDDVp0kTBwcF64YUXNHz4cJnNZq1fv17//ve/9dZbb53R6nTjxo1Tdna287Z//363xetOzJQCAMD30L7nQVFUSgEA4HdWrFihv//975o4caI6duyobt26KSEhQSEhITp+/Li2b9+uVatWKSAgQOPGjdNf/vIXtz13SkqKvvnmG+Xl5SknJ0fx8fEaNmyYWrRooe+++06HDx9W8+bNnftbrVY99NBDmj59uvbs2VPpMYODgxUcHOy2GGsLlVIAAPgeklIexKBzAAD8T+vWrTV//nzt27dPH374ob777jt9//33KigoUMOGDdW5c2e9/vrruvLKK2WxWGolhvDwcIWHh+v48eNasmSJpk6dqhtuuEFpaWnl9uvfv7/+7//+TyNHjqyVOOqSIykVFcZMKQAAfAVJKQ+KCaN9DwAAf9W8eXM99NBDeuihh+rsOZcsWSLDMNS6dWvt3LlTY8eOVZs2bTRy5EgFBgaqQYMG5fYPDAxUXFycWrduXWcx1hbHRT7a9wAA8B3MlPIgBp0DAAB3ys7O1r333qs2bdpoxIgR6t27t5YsWaLAQP9P1GSXXeSjfQ8AAN9BpZQHRZdVSh0nKQUAANxg6NChGjp0qMv7VzVHyhedrJSifQ8AAF9BpZQHOa7kZRcUyzAMD0cDAADgm4pKrcovtkqSoqiUAgDAZ5CU8iBHUqrEajhPpAAAAHBmssuqpMwmKSKYRgAAAHwFSSkPCg20KCjA/hEcZ9g5AABAjWQ7Vt4LDZTZbPJwNAAAwFUkpTzIZDIx7BwAAD+WlJSkJ554Qvv27fN0KH7NOU8qjHlSAAD4EpJSHhZTdvLkKDsHAAD+44EHHtDHH3+sFi1aqG/fvnr//fdVVFTk6bD8TtYplVIAAMB3kJTyMMcwTtr3AADwPw888IA2btyoNWvWqG3btrrvvvsUHx+v0aNHa8OGDZ4Oz29klZ1HRTPkHAAAn0JSysNo3wMAwP916dJFL7zwgtLT0zVhwgS98cYb6t69uzp16qQ333yTVXjPkqPiPJpKKQAAfArLk3iYo30vi0opAAD8VklJiT755BPNmjVLy5Yt0wUXXKDbb79dBw4c0N///nd9+eWXevfddz0dps9yXNxjphQAAL6lRkmp/fv3y2QyqWnTppKkNWvW6N1331VqaqpGjRrl1gD9naPMnEopAAD8z4YNGzRr1iy99957MpvNGjFihP71r3+pTZs2zn0GDx6s7t27ezBK35dVYL+4x0wpAAB8S43a9/70pz/p66+/liRlZmaqb9++WrNmjR577DE98cQTbg3Q3zlmSmUx6BwAAL/TvXt3/frrr5oxY4YOHjyo5557rlxCSpKSk5N10003eShC/5BdUCqJmVIAAPiaGlVKbd26VT169JAkffDBB2rXrp3+97//aenSpbrrrrs0fvx4twbpz2jfAwDAf/32229KTEw87T7h4eGaNWtWHUXknxznUVRKAQDgW2pUKVVSUqLg4GBJ0pdffqlrr71WktSmTRtlZGS4L7pzAIPOAQDwX4cPH9bq1asrbF+9erXWrVvngYj8k3PQOZVSAAD4lBolpc4//3zNnDlT3333nZYtW6YBAwZIktLT09WgQQO3BujvHAM5j1MpBQCA37n33nu1f//+CtsPHjyoe++91wMR+SfHxb2oUAadAwDgS2qUlHrmmWf06quv6tJLL9Xw4cPVsWNHSdLChQudbX1wjeOKXjYzpQAA8Dvbt29Xly5dKmzv3Lmztm/f7oGI/JOjfY9KKQAAfEuNZkpdeumlOnr0qHJychQTE+PcPmrUKIWFhbktuHPBqavvGYYhk8nk4YgAAIC7BAcH69ChQ2rRokW57RkZGQoIqNFpGP7AajOUU1g26JyZUgAA+JQaVUoVFBSoqKjImZDau3evpk+frh07dqhx48ZuDdDfOQadl9oMnSgq9XA0AADAnfr166dx48YpOzvbuS0rK0t///vf1bdvXw9G5j9yTqk2Z9A5AAC+pUaX6AYNGqTrr79ed911l7KystSzZ08FBgbq6NGjmjZtmu6++253x+m3QgItCg4wq6jUpqz8EkWEcDIFAIC/eO6559SnTx8lJiaqc+fOkqSNGzcqNjZWs2fP9nB0/iGrLCkVERygAEuNrrcCAAAPqdFv7g0bNujiiy+WJH300UeKjY3V3r179c477+iFF15wa4DnAke1FCvwAQDgX5o0aaLNmzdr6tSpSk1NVdeuXfXvf/9bW7ZsUbNmzTwdnl9wzJOKYp4UAAA+p0aVUvn5+YqIiJAkLV26VNdff73MZrMuuOAC7d27160BnguiwwKVmVOorAJW4AMAwN+Eh4dr1KhRng7DbzkqpRhyDgCA76lRUqply5ZasGCBBg8erCVLlujBBx+UJB0+fFiRkZFuDfBc4Jh/QKUUAAD+afv27dq3b5+Ki8tfgLr22ms9FJH/yC47f4oODfJwJAAA4EzVKCk1fvx4/elPf9KDDz6oyy+/XL169ZJkr5pyzEuA606271EpBQCAP/ntt980ePBgbdmyRSaTSYZhSJJztV2r1erJ8PwC7XsAAPiuGs2UGjJkiPbt26d169ZpyZIlzu1XXHGF/vWvf7ktuHOFo9ycSikAAPzLX//6VyUnJ+vw4cMKCwvTtm3b9O2336pbt25asWKFp8PzC872PVbeAwDA59SoUkqS4uLiFBcXpwMHDkiSmjZtqh49ergtsHOJ48peVgFJKQAA/MmqVav01VdfqWHDhjKbzTKbzerdu7emTJmi+++/Xz/++KOnQ/R5jot6zJQCAMD31KhSymaz6YknnlBUVJQSExOVmJio6OhoTZ48WTabzd0x+j1H+95x2vcAAPArVqvVuThMw4YNlZ6eLklKTEzUjh07PBma38guYKYUAAC+qkaVUo899pj+85//6Omnn9ZFF10kSVq5cqUmTpyowsJCPfXUU24N0t85ys2zad8DAMCvtGvXTps2bVJycrJ69uypqVOnKigoSK+99ppatGjh6fD8AjOlAADwXTVKSr399tt64403yq0Y06FDBzVp0kT33HMPSakzFE2lFAAAfukf//iH8vLyJElPPPGErrnmGl188cVq0KCB5s2b5+Ho/AMzpQAA8F01SkodO3ZMbdq0qbC9TZs2Onbs2FkHda6JZqYUAAB+qX///s7vW7ZsqZ9//lnHjh1TTEyMcwU+nJ1s50wp2vcAAPA1NZop1bFjR7300ksVtr/00kvq0KHDWQd1rnEkpWjfAwDAf5SUlCggIEBbt24tt71+/fokpNzIWSlF+x4AAD6nRpVSU6dO1dVXX60vv/xSvXr1kmRfXWb//v36/PPP3RrgucAx6DyroESGYXCiCgCAHwgMDFTz5s1ltVo9HYrfstkM50wp2vcAAPA9NaqUuuSSS/TLL79o8ODBysrKUlZWlq6//npt27ZNs2fPdneMfi+q7CTKajOUW1Tq4WgAAIC7PPbYY/r73//OeINacqK4VDbD/n0kSSkAAHxOjSqlJCkhIaHCQPNNmzbpP//5j1577bWzDuxcEhJoUWigRQUlVmXllSgyhJMqAAD8wUsvvaSdO3cqISFBiYmJCg8PL3f/hg0bPBSZf3CMPggNtCgk0OLhaAAAwJmqcVIK7hUdFqiCbKuyCorVXGGeDgcAALjBdddd5+kQ/FpWPvOkAADwZSSlvERUaKAysgudJ1cAAMD3TZgwwdMh+LWsAvs8qSha9wAA8Ek1mikF93MMOz9eNqwTAAAAp0elFAAAvu2MKqWuv/76096flZVVoyBefvllPfvss8rMzFTHjh314osvqkePHpXu+/rrr+udd95xLq/ctWtX/fOf/6xyf1/hOJnKLqBSCgAAf2E2m0+7qi4r852drLLzpujQIA9HAgAAauKMklJRUVHV3j9ixIgzCmDevHkaM2aMZs6cqZ49e2r69Onq37+/duzYocaNG1fYf8WKFRo+fLguvPBChYSE6JlnnlG/fv20bds2NWnS5Iye25tEl1VK0b4HAID/+OSTT8r9XFJSoh9//FFvv/22Jk2a5KGo/Ed2WYU5lVIAAPimM0pKzZo1y+0BTJs2TXfeeadGjhwpSZo5c6Y+++wzvfnmm3r00Ucr7D937txyP7/xxhuaP3++li9ffsYJMW/iOJmifQ8AAP8xaNCgCtuGDBmi888/X/PmzdPtt9/ugaj8h+NiXhRJKQAAfJJHZ0oVFxdr/fr1SktLc24zm81KS0vTqlWrXDpGfn6+SkpKVL9+/UrvLyoqUk5OTrmbN4ouG9CZTaUUAAB+74ILLtDy5cs9HYbPo30PAADf5tGk1NGjR2W1WhUbG1tue2xsrDIzM106xiOPPKKEhIRyia1TTZkyRVFRUc5bs2bNzjru2sCgcwAAzg0FBQV64YUXfHrsgLdg0DkAAL7tjNr3vM3TTz+t999/XytWrFBISEil+4wbN05jxoxx/pyTk+OViSlH2XkWg84BAPAbMTEx5QadG4ah3NxchYWFac6cOR6MzD9kF5TNlAolKQUAgC/yaFKqYcOGslgsOnToULnthw4dUlxc3Gkf+9xzz+npp5/Wl19+qQ4dOlS5X3BwsIKDg90Sb22ifQ8AAP/zr3/9q1xSymw2q1GjRurZs6diYmI8GJl/YKYUAAC+zaNJqaCgIHXt2lXLly/XddddJ0my2Wxavny5Ro8eXeXjpk6dqqeeekpLlixRt27d6ija2hUTTvseAAD+5tZbb/V0CH6NmVIAAPg2j86UkqQxY8bo9ddf19tvv62ffvpJd999t/Ly8pyr8Y0YMULjxo1z7v/MM8/o8ccf15tvvqmkpCRlZmYqMzNTJ06c8NRLcAtnpVRBiWw2w8PRAAAAd5g1a5Y+/PDDCts//PBDvf322x6IyH8YhuGsMKdSCgAA3+TxpNSwYcP03HPPafz48erUqZM2btyoxYsXO4ef79u3TxkZGc79Z8yYoeLiYg0ZMkTx8fHO23PPPeepl+AWjpMpmyHlFpZ6OBoAAOAOU6ZMUcOGDStsb9y4sf75z396ICL/UVBiVbHVJomZUgAA+CqPJ6UkafTo0dq7d6+Kioq0evVq9ezZ03nfihUr9NZbbzl/3rNnjwzDqHCbOHFi3QfuRsEBFoUFWSRJWQW08AEA4A/27dun5OTkCtsTExO1b98+tz9fbm6uHnjgASUmJio0NFQXXnih1q5dK0kqKSnRI488ovbt2ys8PFwJCQkaMWKE0tPT3R5HXcgua90LtJic51AAAMC3eEVSCnaOq3xZDDsHAMAvNG7cWJs3b66wfdOmTWrQoIHbn++OO+7QsmXLNHv2bG3ZskX9+vVTWlqaDh48qPz8fG3YsEGPP/64NmzYoI8//lg7duzQtdde6/Y46oJzyHloULlh8gAAwHd4dNA5yosOC1J6diHDzgEA8BPDhw/X/fffr4iICPXp00eS9M033+ivf/2rbrrpJrc+V0FBgebPn6///ve/zueaOHGiFi1apBkzZujJJ5/UsmXLyj3mpZdeUo8ePbRv3z41b97crfHUNkdSKpp5UgAA+CySUl7EcVLlKEcHAAC+bfLkydqzZ4+uuOIKBQTYT7tsNptGjBjh9plSpaWlslqtCgkJKbc9NDRUK1eurPQx2dnZMplMio6OdmssdSG7bNwB86QAAPBdJKW8SEyYfTlj2vcAAPAPQUFBmjdvnp588klt3LhRoaGhat++vRITE93+XBEREerVq5cmT56stm3bKjY2Vu+9955WrVqlli1bVti/sLBQjzzyiIYPH67IyMgqj1tUVKSioiLnzzk5OW6PvSaolAIAwPeRlPIijhX4aN8DAMC/tGrVSq1atar155k9e7Zuu+02NWnSRBaLRV26dNHw4cO1fv36cvuVlJRo6NChMgxDM2bMOO0xp0yZokmTJtVm2DWSVXByphQAAPBNDDr3Igw6BwDAv9xwww165plnKmyfOnWqbrzxRrc/X0pKir755hudOHFC+/fv15o1a1RSUqIWLVo493EkpPbu3atly5adtkpKksaNG6fs7Gznbf/+/W6PuyaolAIAwPeRlPIiJ9v3qJQCAMAffPvtt7rqqqsqbL/yyiv17bff1trzhoeHKz4+XsePH9eSJUs0aNAgSScTUr/++qu+/PJLl1YADA4OVmRkZLmbN2CmFAAAvo/2PS/iaN/LYtA5AAB+4cSJEwoKqtheFhgYWCuzmZYsWSLDMNS6dWvt3LlTY8eOVZs2bTRy5EiVlJRoyJAh2rBhgz799FNZrVZlZmZKkurXr19pnN6MSikAAHwflVJehPY9AAD8S/v27TVv3rwK299//32lpqa6/fmys7N17733qk2bNhoxYoR69+6tJUuWKDAwUAcPHtTChQt14MABderUSfHx8c7b999/7/ZYapvjfCkqzLeSaQAA4CQqpbxITDjtewAA+JPHH39c119/vXbt2qXLL79ckrR8+XK99957+vDDD93+fEOHDtXQoUMrvS8pKUmGYbj9OT3FUVlO+x4AAL6LpJQXcVZK0b4HAIBfGDhwoBYsWKB//vOf+uijjxQaGqoOHTroyy+/1CWXXOLp8HxadtlFPNr3AADwXSSlvEh0Wfl5dkGJrDZDFrPJwxEBAICzdfXVV+vqq6+usH3r1q1q166dByLyDycrpWjfAwDAVzFTyotElVVKGYaUW0i1FAAA/iY3N1evvfaaevTooY4dO3o6HJ9VVGpVfrFV0smFYgAAgO8hKeVFggLMCg+ySGLYOQAA/uTbb7/ViBEjFB8fr+eee06XX365fvjhB0+H5bOyy6qkzCYpIpjCfwAAfBW/xb1MdFiQ8ooLdDy/WEkK93Q4AACghjIzM/XWW2/pP//5j3JycjR06FAVFRVpwYIFtbLy3rkk27HyXmigzIw7AADAZ1Ep5WUcwzoZdg4AgO8aOHCgWrdurc2bN2v69OlKT0/Xiy++6Omw/IZznlQY86QAAPBlVEp5mZiyk6usshVlAACA7/niiy90//336+6771arVq08HY7fyTqlUgoAAPguKqW8jGNYJzOlAADwXStXrlRubq66du2qnj176qWXXtLRo0c9HZbfcFy8i2bIOQAAPo2klJeJDiUpBQCAr7vgggv0+uuvKyMjQ3/5y1/0/vvvKyEhQTabTcuWLVNubq6nQ/RpjkHn0VRKAQDg00hKeRna9wAA8B/h4eG67bbbtHLlSm3ZskUPPfSQnn76aTVu3FjXXnutp8PzWY6Ld8yUAgDAt5GU8jIMOgcAwD+1bt1aU6dO1YEDB/Tee+95OhyfllVgv3jHTCkAAHwbSSkvE+2slCIpBQCAP7JYLLruuuu0cOFCT4fis05WSpGUAgDAl5GU8jInZ0rRvgcAAFAZ50wpklIAAPg0klJehvY9AACA03NWSoUyUwoAAF9GUsrLONr3judRKQUAAFAZ50wpKqUAAPBpJKW8jKNSKqewVFab4eFoAAAAvM/JSimSUgAA+DKSUl7m1FVkcmjhAwAAKKfUalNuYamkkxXmAADAN5GU8jKBFrMiggMkSccZdg4AAFBOTllCSpIiQwI8GAkAADhbJKW8UBTDzgEAACrlWKE4IjhAARZOZQEA8GX8JvdCMWWl6FlUSgEAAJTjuGjHkHMAAHwfSSkv5Bh27hjiCQAAALtsx5BzklIAAPg8klJeyDHsnKQUAABAeVkF9kry6FCGnAMA4OtISnkh2vcAAAAq57hoR/seAAC+j6SUF4pm0DkAAEClHEmp6FCSUgAA+DqSUl4o2lkpRVIKAADgVNkFzJQCAMBfkJTyQo4rf8dp3wMAACjHmZRiphQAAD6PpJQXclz5y6Z9DwAAoBzHzE1mSgEA4PtISnkhR/selVIAAADlZRUwUwoAAH9BUsoLOQedM1MKAACgnGzHoPMw2vcAAPB1JKW8kOPKX25hqUqtNg9HAwAA4D2yGHQOAIDfICnlhaJOKUdnrhQAAICdzWY4Z0rRvgcAgO8jKeWFAixmRYQESDp5NRAAAOBcd6K4VDbD/n0kSSkAAHweSSkvFVM2JyGLYecAAACSTs6TCg20KCTQ4uFoAADA2SIp5aUYdg4AAFBeVj7zpAAA8CckpbyUY64USSkAAAC7rAJ7BXkUrXsAAPgFklJeytG+d5z2PQAAAElUSgEA4G9ISnkpx8kWq+8BAADYORaAiQ4N8nAkAADAHUhKealo56BzklIAAACSlF1WQU6lFAAA/oGklJeKLpuVQPseAACAneNiXRRJKQAA/AJJKS9F+x4AAEB5tO8BAOBfSEp5KQadAwAAlMegcwAA/AtJKS/lKEtnphQAAIBddkHZTKlQklIAAPgDklJeylEplU1SCgAAQBIzpQAA8DckpbyU4wpgblGpSqw2D0cDAADgecyUAgDAv5CU8lKRoYEymezfM+wcAACc6wzDcFaQM1MKAAD/QFLKS1nMJkWGOOZKMewcAABULzc3Vw888IASExMVGhqqCy+8UGvXrnXebxiGxo8fr/j4eIWGhiotLU2//vqrByN2XUGJVcVl1eMkpQAA8A8kpbxYNMPOAQDAGbjjjju0bNkyzZ49W1u2bFG/fv2UlpamgwcPSpKmTp2qF154QTNnztTq1asVHh6u/v37q7Cw0MORV89xPhRkMSs00OLhaAAAgDuQlPJijrlSJKUAAEB1CgoKNH/+fE2dOlV9+vRRy5YtNXHiRLVs2VIzZsyQYRiaPn26/vGPf2jQoEHq0KGD3nnnHaWnp2vBggWeDr9apw45NzlmHAAAAJ9GUsqLRZetwHec9j0AAFCN0tJSWa1WhYSElNseGhqqlStXavfu3crMzFRaWprzvqioKPXs2VOrVq2q8rhFRUXKyckpd/OErAL7+ZDjoh0AAPB9JKW8mKN9j0HnAACgOhEREerVq5cmT56s9PR0Wa1WzZkzR6tWrVJGRoYyMzMlSbGxseUeFxsb67yvMlOmTFFUVJTz1qxZs1p9HVVhyDkAAP6HpJQXiymrlKJ9DwAAuGL27NkyDENNmjRRcHCwXnjhBQ0fPlxmc81P+caNG6fs7Gznbf/+/W6M2HVZZRfpoqiUAgDAb5CU8mKOky7a9wAAgCtSUlL0zTff6MSJE9q/f7/WrFmjkpIStWjRQnFxcZKkQ4cOlXvMoUOHnPdVJjg4WJGRkeVunuCcKRUa5JHnBwAA7kdSyotFhgZIkral52jVrt9ltRkejggAAPiC8PBwxcfH6/jx41qyZIkGDRqk5ORkxcXFafny5c79cnJytHr1avXq1cuD0brGOVOK9j0AAPxGgKcDQOUWb83Qi8t3SpI27s/S8Nd/UHxUiCYMTNWAdvEejg4AAHijJUuWyDAMtW7dWjt37tTYsWPVpk0bjRw5UiaTSQ888ICefPJJtWrVSsnJyXr88ceVkJCg6667ztOhV8s5U4r2PQAA/AZJKS+0eGuG7p6zQX+si8rMLtTdczZoxp+7kJgCAAAVZGdna9y4cTpw4IDq16+vG264QU899ZQCA+2JnIcfflh5eXkaNWqUsrKy1Lt3by1evLjCin3eKItB5wAA+B2SUl7GajM0adH2CgkpSTIkmSRNWrRdfVPjZDGb6jg6AADgzYYOHaqhQ4dWeb/JZNITTzyhJ554og6jcg9H+15UGDOlAADwF8yU8jJrdh9TRnZhlfcbkjKyC7Vm97G6CwoAAMDDsmjfAwDA75CU8jKHc6tOSNVkPwAAAH+QXUD7HgAA/oaklJdpHOHaTAdX9wMAAPAHJyulaN8DAMBfkJTyMj2S6ys+KkSnmxYVHxWiHsn16ywmAAAATyoqtaqgxCpJiqJSCgAAv0FSystYzCZNGJgqSVUmph69sg1DzgEAwDnD0bpnNkkRwazTAwCAvyAp5YUGtIvXjD93UVxU+RY9Rx7q658PyzAqW58PAADA/2SXte5FhQbKzIU5AAD8BpeavNSAdvHqmxqnNbuP6XBuoRpH2Fv6bv7Pai3YmK5uSfX15wsSPR0mAABArctyDjlnnhQAAP6EpJQXs5hN6pXSoNy2Rwa01j8//1lPLNquDk2j1KFptGeCAwAAqCNZp1RKAQAA/0H7no+58+IW6pcaq2KrTXfP2aDjecWeDgkAAKBWZeXbz3eiGXIOAIBfISnlY0wmk569saMSG4TpYFaBxnywUTYb86UAAID/cgw6j6ZSCgAAv0JSygdFhQbqlZu7KDjArK93HNErK3Z6OiQAAIBa42jfY6YUAAD+xeNJqZdffllJSUkKCQlRz549tWbNmir33bZtm2644QYlJSXJZDJp+vTpdReolzk/IUqTB7WTJE1b9ov+t/OohyMCAACoHVkF9vY9ZkoBAOBfPJqUmjdvnsaMGaMJEyZow4YN6tixo/r376/Dhw9Xun9+fr5atGihp59+WnFxcXUcrfcZ2r2ZhnZrKpsh3f/ej8rMLvR0SAAAAG53slKKpBQAAP7Eo0mpadOm6c4779TIkSOVmpqqmTNnKiwsTG+++Wal+3fv3l3PPvusbrrpJgUHB9dxtN7piUHt1DY+Ur/nFWv0uxtUYrV5OiQAAAC3cs6UIikFAIBf8VhSqri4WOvXr1daWtrJYMxmpaWladWqVZ4Ky+eEBFo04+YuiggO0Lq9x/XMFz97OiQAAAC3clZKhTJTCgAAf+KxpNTRo0dltVoVGxtbbntsbKwyMzPd9jxFRUXKyckpd/M3SQ3D9dzQjpKkN1bu1uKtGR6OCAAAwH2cM6WolAIAwK94fNB5bZsyZYqioqKct2bNmnk6pFrR//w4jerTQpI09sPN2n00z8MRAQAAuMfJSimSUgAA+BOPJaUaNmwoi8WiQ4cOldt+6NAhtw4xHzdunLKzs523/fv3u+3Y3mZs/9bqkVRfuUWlunvOehUUWz0dEgAAwFkptdqUW1gqSYoOo30PAAB/4rGkVFBQkLp27arly5c7t9lsNi1fvly9evVy2/MEBwcrMjKy3M1fBVrMevFPndWwXrB+zszV4//dKsMwPB0WAABAjeWUJaQkKTIkwIORAAAAd/No+96YMWP0+uuv6+2339ZPP/2ku+++W3l5eRo5cqQkacSIERo3bpxz/+LiYm3cuFEbN25UcXGxDh48qI0bN2rnzp2eegleJzYyRC8M7ySzSfpo/QF9sM5/K8MAAID/y8q3z5OKCAlQgMXvJ08AAHBO8ejlpmHDhunIkSMaP368MjMz1alTJy1evNg5/Hzfvn0ym0+efKSnp6tz587On5977jk999xzuuSSS7RixYq6Dt9rXZjSUA/1a61nl+zQ4//dpvMTotSuSZSnwwIAADhjWQVl86QYcg4AgN/xeA306NGjNXr06Erv+2OiKSkpiXY0F919SYo27D2u5T8f1j1zN2jRfb0VxXBQAADgY7KdQ86ZJwUAgL+hBtpPmc0mTRvaSU1jQrXvWL7+9uEmlVptWrXrd/1340Gt2vW7rDYSfAAAwLtlFdjb96iUAgDA/3i8Ugq1JyosUDNu7qobZnyvZdsPqfPkZc7VayQpPipEEwamakC7eA9GCQAAULWsskopKr4BAPA/VEr5ufZNozSka1NJKpeQkqTM7ELdPWeDFm/N8ERoAAAA1XIkpaiUAgDA/5CU8nNWm6Gvdhyu9D5H896kRdtp5QMAAF4pu4BKKQAA/BVJKT+3ZvcxZWYXVnm/ISkju1Brdh+ru6AAAABclJVfNlOKQecAAPgdklJ+7nBu1QmpmuwHAABQl7IclVK07wEA4HdISvm5xhEhLu23eGumDmYV1HI0AAAAZ8Y5U4r2PQAA/A5JKT/XI7m+4qNCZKpmvy+2ZuqSqV9rzLyN+jkzp05iAwAAqI5jplR0GO17AAD4G5JSfs5iNmnCwFRJqpCYMpXd7ru8pS5MaaBSm6GPfzyoAdO/08hZa/TDb7/LMBiADgAAPMc5U4r2PQAA/E6ApwNA7RvQLl4z/txFkxZtV8YpQ8/jokI0YWCqBrSLlyRtPpClV7/5TV9szdDXO47o6x1H1KlZtO66pIX6psbJYi6f1rLaDK3ZfUyHcwvVOCJEPZLrV9gHAACgpmw242SlFO17AAD4HZJS54gB7eLVNzXutEmkDk2j9fLNXbTnaJ7eWPmbPlx3QBv3Z+muORvUomG47uzTQoM7N1FIoEWLt2ZUSHLF/yHJBQAAcDZyi0plKyvajiQpBQCA3zEZ51h/Vk5OjqKiopSdna3IyEhPh+PVjp4o0tvf79E7q/Y6r1I2igjWRSkN9N+N6frjPxxHemvGn7uQmAIA+DTOF6pWl+/Nvt/z1efZrxUaaNFPkwfU6nMBAAD3cfV8gZlSqFLDesF6qF9rff/o5Xr8mlQlRIXoSG6RFlSSkJLk3DZp0XZZbedUrhMAANSCrALmSQEA4M9ISqFa4cEBur13sr55+DLdc2nKafc1JGVkF2rN7mN1ExwAAPBbWfn2Su0oWvcAAPBLJKXgskCLWa3jIlza93BuYfU7AQAAnEaWY8g5lVIAAPglklI4I40jQlzar14wM/QBAMDZyc4va98LDfJwJAAAoDaQlMIZ6ZFcX/FRITJVs9+D8zZq5je7VFBsrZO4AACA/3G071EpBQCAfyIphTNiMZs0YWCqJFVITDl+jo8MUU5hqZ7+4mf1efZrvbNqj4pLbXUaJwAA8H2O1X+jSEoBAOCXSErhjA1oF68Zf+6iuKjyrXxxUSGa+ecuWvno5Zo2tKOa1Q/Vkdwijf/vNl3+/Ap9uG6/Sq0kpwAAgGucM6Vo3wMAwC8x+Ac1MqBdvPqmxmnN7mM6nFuoxhEh6pFcXxazvV7q+i5NdU2HBM1bt18vLv9VB44XaOxHmzXzm116qF9rDTg/TmZzdU2AAADgXEb7HgAA/o2kFGrMYjapV0qDKu8PCjDr/y5I1JAuTTX7hz16ZcUu7TqSp3vmblC7JpF6qF9rXXpeI5lMJlltRpUJLgAAcG7KLnAMOicpBQCAPyIphVoXGmTRqD4pGt6jud74brf+s3K3th7M0chZa9U9KUZ9WjXSu2v2KSO70PmY+KgQTRiYqgHt4j0YOQAA8CRHpRQzpQAA8E/MlEKdiQgJ1IN9z9O3D1+mUX1aKDjArLV7juv5Zb+US0hJUmZ2oe6es0GLt2Z4KFoAAOBpzJQCAMC/kZRCnasfHqS/X9VWXz10qcKCLJXuY5R9nbRou6w2o9J9AADASVarVY8//riSk5MVGhqqlJQUTZ48WYZx8vfoiRMnNHr0aDVt2lShoaFKTU3VzJkzPRh11QzDUDYzpQAA8Gu078Fj9h3LV36xtcr7DUkZ2YX6384j6nNe47oLDAAAH/TMM89oxowZevvtt3X++edr3bp1GjlypKKionT//fdLksaMGaOvvvpKc+bMUVJSkpYuXap77rlHCQkJuvbaaz38CsorKLGquGzVXpJSAAD4Jyql4DGHcwur30nSqHfW68F5G7VkW6YKS6pOYgEAcC77/vvvNWjQIF199dVKSkrSkCFD1K9fP61Zs6bcPrfccosuvfRSJSUladSoUerYsWO5fbyFY55UkMWs0MDKK6sBAIBvIykFj2kcEeLSfoWlNn3y40H9ZfZ6dZm8TPe+u0Gfbc5QXlFplY+x2gyt2vW7/rvxoFbt+p0WQACA37vwwgu1fPly/fLLL5KkTZs2aeXKlbryyivL7bNw4UIdPHhQhmHo66+/1i+//KJ+/fpVedyioiLl5OSUu9WFU4ecm0ysyAsAgD+ifQ8e0yO5vuKjQpSZXajKUkYmSXFRIZo+rJOWbj+kxVszdTCrQJ9tztBnmzMUHGDWpa0b6cp28bq8bWNFhthL+xdvzdCkRdtZzQ8AcE559NFHlZOTozZt2shischqteqpp57SzTff7NznxRdf1KhRo9S0aVMFBATIbDbr9ddfV58+fao87pQpUzRp0qS6eAnlZBUUS5KiQ2ndAwDAX5GUgsdYzCZNGJiqu+dskEkql5hyXA+dMDBVPVs0UM8WDfSPq9tq84FsfbE1U19szdDe3/O1ZNshLdl2SEEWs3q3aqimMaGavWpvhSSXYzW/GX/uQmIKAOCXPvjgA82dO1fvvvuuzj//fG3cuFEPPPCAEhISdMstt0iyJ6V++OEHLVy4UImJifr222917733KiEhQWlpaZUed9y4cRozZozz55ycHDVr1qzWXw9DzgEA8H8m49QlWc4BOTk5ioqKUnZ2tiIjIz0dDlSzyibDMPRTRq6+2Jqhz7dkaNeRvGqfx1F5tfKRy2Uxn1kbgNVmaM3uYzqcW6jGESHqkVz/jI8BAPAdvni+0KxZMz366KO69957nduefPJJzZkzRz///LMKCgoUFRWlTz75RFdffbVznzvuuEMHDhzQ4sWLXXqeunpv3luzT+M+3qK0trF645ZutfY8AADA/Vw9X6BSCh43oF28+qbGnVHSx2QyKTUhUqkJkXqoX2v9eihXr337mz5cf6DKxzhW8/vXsh1KS41TcoNwRblw9ZV2QACAL8jPz5fZXH5cqMVikc1mX8GupKREJSUlp93Hm2RRKQUAgN8jKQWvYDGb1CulQY0f3yo2Qr1bNTxtUsrhpa936aWvd0myn+gmNghXUoMw59ekhuFKahCumLBALdmWqbvnbKAdEADg9QYOHKinnnpKzZs31/nnn68ff/xR06ZN02233SZJioyM1CWXXKKxY8cqNDRUiYmJ+uabb/TOO+9o2rRpHo6+ImZKAQDg/0hKwW+4uppfm7gIHc8v1qGcImXllygrP0ub9mdV2K9esEVFJbZKh7AbsrcDTlq0XX1T42jlAwB43IsvvqjHH39c99xzjw4fPqyEhAT95S9/0fjx4537vP/++xo3bpxuvvlmHTt2TImJiXrqqad01113eTDyyjFTCgAA/0dSCn7D1dX8Prv/YlnMJuUXl2rv7/na+3ue9ji+HrV/Tc8u1Iki62mfz9EOuGx75hlXSzGjCgDgbhEREZo+fbqmT59e5T5xcXGaNWtW3QV1Fhzte1FhQR6OBAAA1BaSUvAbrq7m50j+hAUFqG18pNrGVxy6Vlhi1dvf79GUL36u9nnvmrNBiQ3C1LV5jLokxqhrYozOi42oMslUGzOqSHIBAPwN7XsAAPg/klLwKwPaxWvGn7tUSPrEnWHSJyTQog5No11+XnvFVb4+/vGgJCkiOECdmkera1mSqlOzaEWEBGrx1gy3z6hiEDsAwB85K6VISgGAW9hsNhUXF3s6DPiJwMBAWSyWsz4OSSn4nZqs5leZM2kH3HIwW+v3HteGvcf1477jyi0q1Xe/HtV3vx6172uSzmtcT/uPF7h1RlVtJLkkKq8AAJ6XXcBMKQBwl+LiYu3evdsrV1uF74qOjlZcXJxMppr/rUhSCn7pbFfzcxzDlXbA+uFBuuS8RrrkvEaS7AmdHZm5Wr/vuNbvOab1+45r/7EC7Th04rTP55hR9cC8jWrZqJ7CgiwKCbIoLNDyh+8DFBpkVlCAReP/u83tg9ipvAIAeANHpVR0KDOlAOBsGIahjIwMWSwWNWvWTGaz2dMhwccZhqH8/HwdPnxYkhQfX/O/E0lKAadRk3ZAi9mk1IRIpSZE6v8uSJQkHc4p1Kvf7NJ//ren2udctOn/27vz8Caq9Q/g3yRN0z2le8vWhVL2RSibbALagqIg/FhELYIoAiL2sqrQIiLCBeSCilfZXIACKgiy3MsieNnEBaQIFKiVrZSydd/SZH5/TBtIt6Rl2kyb7+d58mQymZw5k5NpTt+c806yJHUvDnJ99lMi+jb3RYC7I1w0FZ/y1TXyioiIqDLydHrk6sQLjmg5UoqI6KEUFhYiJycHAQEBcHJysnZ1qI5wdHQEAKSmpsLHx6fKU/kYlCIyQ4rpgD5uDujXws+ioNSAVn7QOtkjT6dHTkEhcnUG5BYUIqdA7KDnFt1n5hVCbyhrnJSphXsSsHBPAgDAzcEOAe6OqO/uiADjzQH13R3h6+aA2O1nJR95BXA6IBERVU5G0dQ9pULM00hERFWn14tBfnt7jjwlaRUHOXU6HYNSRNVJiumAluaoWvHcIxYFbI4l3sHIz4+b3a6RhxPSc3VIz9UhI68QGSmZOJ+SWen6F4+8OpF0t1LvBacDEhFRZaXl3k9yruSPGEREkniYvD9EZZHiM8WgFFENsTRHlaUjiCwNcv04tTdUSgWy8gtxIy0X19NykZyWh+S0XCQXP07PxfV7ubBg4BVmfx+P8EBPhHg7I9jbGcFeLmhQzxF2qtJz0zkdkIiIqsKYT8qJv+oTEZF0AgMDMWXKFEyZMsXaVaEiDEoR1aCq5KgqT2WDXC4aO4T6uiLU17XM8o5cuo1Rq342u99Lqdm4lJptsk6tUqCxpzOCvZwR7O2CYC9nNPZ0qpZE7FLj1EIiIvlJyxEvWa51ZD4pIiK5qMl+s7kRODExMYiNja10ub/88gucnZ2rWCtTGzduxPPPP4/x48fj448/lqRMW8SgFFENkyJH1YNlSRXk6hLsaXbklaeLPWZGNsPfd3Lw1+0s/HUrG0m3s5FfaMCl1CxcSs0CcNOi/VV1OqCUX4acWkhEJE/F0/fcmeSciEgWarrffOPGDePypk2bMGfOHCQkJBjXubi4GJcFQYBer4ednfnwhre3t2R1XL16NaZPn45///vfWLJkCRwcHCQru7IKCgpqbc4wXguSyAqKc1Q9064+uoZ4PtQvDJGt/HF4Rh9sHNcF/xrRDhvHdcHhGX0q/eVQPPIKuD/Sqljx4/cGtcLQjg0xNSIMn4zqgD1TeuLcu5E4POMxfDmmE2IHtsCLXRujexMv1LPwH4nP//cXvvv9Gs7dyEBBoaHCbfecuYHuCw9g5OfH8UbcKYz8/Di6LzyAPWduVPi68sp67evfTb5YgftTC6tSJiAGzY4l3sH3p67jWOIdi5LR12R5RES1QXrx9D2OlCIisrrq6jdXxM/Pz3jTarVQKBTGx+fPn4erqyt2796NDh06QKPR4PDhw0hMTMQzzzwDX19fuLi4IDw8HPv27TMpNzAwEMuWLTM+VigUWLVqFQYPHgwnJyeEhoZi+/btZuuXlJSEo0ePYubMmWjatCm+++67UtusWbMGLVu2hEajgb+/PyZNmmR8Li0tDa+++ip8fX3h4OCAVq1a4YcffgAAxMbGol27diZlLVu2DIGBgcbHo0ePxqBBgzB//nwEBAQgLCwMAPDVV1+hY8eOcHV1hZ+fH5577jmkpqaalPXnn3/iqaeegpubG1xdXdGjRw8kJibip59+glqtRkpKisn2U6ZMQY8ePcy+J1XFkVJEdYAUidiBqo28UioVaFDPCQ3qOaFn0/u/PFiaiP3A+VQcOC/+obRTKtDExwXN/d3QzM8Vzfzd0NzPFd6uGvznzxRJ8lPpDQLScgowe1v5UwuBqk0tlPoXpNowkovTH4moOqTlitP3mFOKiEh6giAgV6e3aFu9QUDM9opTcsRuP4tHm3hZ1Ad0VKskS7g+c+ZMLF68GMHBwahXrx6uXr2KAQMGYP78+dBoNPjyyy8xcOBAJCQkoFGjRuWWM3fuXCxatAj//Oc/sWLFCowaNQqXL1+Gh4dHua9Zu3YtnnzySWi1Wjz//PNYvXo1nnvuOePzK1euRHR0ND744AP0798f6enpOHLkCADAYDCgf//+yMzMxNdff42QkBCcPXu20lev279/P9zc3LB3717jOp1Oh3nz5iEsLAypqamIjo7G6NGjsWvXLgDA9evX0bNnT/Tu3RsHDhyAm5sbjhw5gsLCQvTs2RPBwcH46quvMG3aNGN569evx6JFiypVt8pgUIqITEg1vdBcInZAzBXydFt/JKRk4VxKBjLzCnG+jKsDejipkZWvrzCI9NZ38cjKK0RGXiHScnVIzylAWq4O93LuL6fl6JCRp4NgwWCjG+l5aP/uXjSo5wgfNw28XTTwcdPAx9UBPq73l71dNXBQqyRP6l5dSeI5/ZGIaoPiROfMKUVEJL1cnR4t5vxHkrIEACkZeWgd+1+Ltj/7bgSc7KUJQ7z77rt4/PHHjY89PDzQtm1b4+N58+Zh69at2L59u8kopZJGjx6NkSNHAgDef/99LF++HCdOnEBkZGSZ2xsMBqxbtw4rVqwAAIwYMQL/+Mc/kJSUhKCgIADAe++9h3/84x944403jK8LDw8HAOzbtw8nTpzAuXPn0LRpUwBAcHBwpY/f2dkZq1atMpm2N2bMGONycHAwli9fjvDwcGRlZcHFxQUff/wxtFot4uLioFaL37HFdQCAsWPHYu3atcag1I4dO5CXl4dhw4ZVun6WYlBKSgY9cPkokHUTcPEFGncDlJWLdhLJgRQjryxJxL5wSGtj8EIQBCSn5+FccgbOp2TgXEomzt/IQNLtbNwt+uekIndzdJj6zemHqnNJGXk6nL2hw1kzI5JdNCrk6gwVBs1mfhcPQQAc7VVwUKugsVNCY6eCRq0staxSKDB3x1nJk8RLGUTilRWJqDoxpxQREZnTsWNHk8dZWVmIjY3Fzp07cePGDRQWFiI3NxdXrlypsJw2bdoYl52dneHm5lZqytuD9u7di+zsbAwYMAAA4OXlhccffxxr1qzBvHnzkJqaiuTkZPTt27fM1586dQoNGjQwCQZVRevWrUvlkfrtt98QGxuLP/74A/fu3YPBIKZHuXLlClq0aIFTp06hR48exoBUSaNHj8Y777yD48ePo0uXLli3bh2GDRsmWXL4sjAoJZWz24E9M4CM5Pvr3AKAyIVAi6etVy8iK6rMdECFQoH67o6o7+6Ifi18jetzC/RYdfgvLPnvBbP7C/NzRaiPC9yd1HB3tIe7kxpaRzXcnexRz0ld9Nge529k4IU1J8yWt+DZVvDTOuJWRj5SM/OQmpmPW5n5SM0sepyRj/xCA7LyzQ9/TsvR4bX1v5vdzhLFSeKX7buAriGe8HHVwNvFAW6OduUOh5YqiKTTG3A3uwCzt53hlRWJqNoYc0oxKEVEJDlHtQpn342waNsTSXcxeu0vZrdb91I4OgWVP93twX1LpWSgZOrUqdi7dy8WL16MJk2awNHREUOHDkVBQUGF5ZQM0CgUCmMwpyyrV6/G3bt34ejoaFxnMBhw+vRpzJ0712R9Wcw9r1QqIZSY2qHTlf6RvuTxZ2dnIyIiAhEREVi/fj28vb1x5coVREREGN8Dc/v28fHBwIEDsXbtWgQFBWH37t04ePBgha95WAxKSeHsdmDzi0DJf9Eybojrh33JwBTZrIedDuhor0LHxua/4AAgdmBLi0Z4eTh7mb3SoJ/WAcM6NqqwnoIgICOvEJt+uYr3d50zu99ATyc4a+yQX2hAfqEe+ToD8nT6oscVJ3kvy4oDl7DiwCXjY3uVEl4u9vB21RhvXi4aeLrYY9m+ixWO5Jr1XTxuZeUjM68Q6Tk6pBdNd0zP1SEtV4eMXB3ScgqQXWA+AFccNNt04gqGdmwIezvLr6khVSCpOqYWMshFVHOMOaUcmVOKiEhqCoXC4il0PUK9Leo39wj1tnq/6MiRIxg9ejQGDx4MQBw59ffff0u6jzt37uD7779HXFwcWrZsaVyv1+vRvXt3/Pe//0VkZCQCAwOxf/9+PPbYY6XKaNOmDa5du4YLFy6UOVrK29sbKSkpEATB+IPzqVOnzNbt/PnzuHPnDj744AM0bNgQAPDrr7+W2vcXX3wBnU5X7mipl19+GSNHjkSDBg0QEhKCRx991Oy+HwaDUg/LoBdHSFU0ZmDPTKDZk5zKRzbrYacDmstPVfxlaMmvM8X1MTe1MGZgC7NfrAqFAlpHNVrX11q03wXPtin3fRAEAQV6MTh19NJtjP/a/Kiq5n6uyNcbcDszHxl5hSjQG5CcnofkEldGscS9HB1mb/uz0q+ryFvbziB2x1k083dFmwZatKnvjtYNtAj1cYGdqnSgSqpAUnVMLawNQS5bK4/qNmNOKY6UIiKyKqn6zTUhNDQU3333HQYOHAiFQoHZs2dXOOKpKr766it4enpi2LBhpWYoDBgwAKtXr0ZkZCRiY2Mxfvx4+Pj4GJOaHzlyBK+//jp69eqFnj17YsiQIVi6dCmaNGmC8+fPQ6FQIDIyEr1798atW7ewaNEiDB06FHv27MHu3bvh5uZWYd0aNWoEe3t7rFixAuPHj8eZM2cwb948k20mTZqEFStWYMSIEZg1axa0Wi2OHz+OTp06Ga/gFxERATc3N7z33nt49913JX3/ysKg1MO6fNR0yl4pApBxXdwuqPouo0hUl1XHl2FVrjRYHimCZgqFQswrZafC4y38LCrvh8k9jMecp9PjdlY+bmcV4FbRNMNbmfm4nZWPP66l4fS1dLPH0SrADc383cQpj45qaIumPxZPgSxe/2dyOp5fbX76o7NGhex8PU5fSy/avzif30GtRMsArRioaqBF6/ruuJCSiYkbpLm6otT5uGpDkMvWymOAq+4zTt9jonMiIquTst9cnZYuXYoxY8agW7du8PLywowZM5CRkSHpPtasWYPBgweXmTJjyJAheOGFF3D79m1ERUUhLy8PH374IaZOnQovLy8MHTrUuO23336LqVOnYuTIkcjOzkaTJk3wwQcfAACaN2+OTz75BO+//z7mzZuHIUOGYOrUqfjss88qrJu3tzfWrVuHt956C8uXL8cjjzyCxYsX4+mn78/a8vT0xIEDBzBt2jT06tULKpUK7dq1MxkNpVQqMXr0aLz//vt48cUXH/YtM0shlJysWMdlZGRAq9UiPT3dbKTRIvHfAN+ONb/dkNVA66HmtyOicsl5tEpx4AIoO2hW1avvSVHescQ7GPn5cbPbbRzXxaIRbXqDgO4LD5gNmv1v+mNITsvD6etpRYGpNJy5noGs/MIyX1PRl5HWUY3pkWEwCIDBIKDQIEBvMIj3egF6QYDeIODynRxs/6OiHwpEL3ZpjDB/V2jsVHBQFyWatxMTzTuoi5POq6BWKfDsJ0eRmplfZjnFx3p4Rp+HDnI97GfFlsqrias+St5fqEOq+70p1BvQ5O3dAIDfZz8OD2dO4SMiehh5eXnGK8M5ODhUuRz+KGQ7xo4di1u3bmH79u0VblfRZ8vS/gJHSj0sF1/z2wDA2W1AQHvAM6Raq0NUlz1sfqqySHGlweK6SfkLktxGcj3I0pFrdiolGnk6oZGnE55qEwBADCj9dTsb8cZAlRis0ukr/n0kPVeHt7eesah+lvjy+GVJyinOn9X7nz9C66SGWqWEvUoJezulcVltp4RapRCvrKhUYOvv1yu+UuO38SgoNECjVomvV4mvV9spTR+rxPJivv9TspFhUo80k7o8XvXRNmTk3Q9cuzmwq0pEJBdS9ZtJvtLT0xEfH48NGzaYDUhJhSOlHpZBDyxrJSY1r/B3fgBQAGH9gc7jgaCeQDlXySKi2kuueXikHslVXKYUI1a2/n4Nb27+w+x2req7oWE9JyiVCtgpFVAZ75VQKQE7pRKpGXnYdSbFbFndQjzh8kDS+TydwSQBffF9ToEe+jrwNVnPSQ0nezvYqcT3zE6pFJdVyqLHYpArM0+HPyyY6tkj1AverhoocP+zWPIrTQEgNTMPhy7cNlteVNfGCPNzE0erlRi5plGLy3ZKBZ5b9TNuSThqrSIcKVW+6n5v/rqVhT5LDsHVwQ7xsZZdHYqIiMon1Ugpqvt69+6NEydO4NVXX8WHH35odnuOlJIDpQqIXFh09b1yxgz0nAYknwQu7QUSdok3n5ZAl/FA6/8D1BVfllEyBr2Y2yrrpjjCq3E3Jl8nkpjUvyDJdSRXcZlSjFzz01r2N/DtAS3Mvhd6g4CTFkwt/GpsZ4vqaenUx3cGNEeIrwt0hQbo9AIK9HroCsXk9QWFBuj04i3+Wjr+c/am2fKa+DhD62gPXdHrC4perysUxHVFj/MLDbAkZnYvR4d7OaUvJVxV/7toPtBUGV8ce/iRa8Wj1k4k3eWvuLVcWm5RPikmOSciIqpRBw8erPF9MiglhRZPA8O+FK/C92DSc7cAIPID8XkAuH0R+PlT4NQGIPVPYPvrwL5YoMNLQPjLgFuJfwqlDCKd3V5O/Rberx8R1Wlynf4o5fRCqZPiW1q3l7oHWRzksiQoNe+Z1ha9r5YGzd4f3AotA7QoNIhBM71BDG6J9wIKDeLyuRuZ+PRQotnynuvUEI09nQGYvsfFATKhaO2VOzmI++Wq2fK6BHvA1UEtjlbT6YtGrT04cs2ArHwd8nTmr6CTmln5q0+SvNxPcs5cUkRERHUdg1JSafE00OzJioNIXqHAk0uAPu8Av38FnPgcSL8C/G8xcGQZ0PJZcfRU/Q7SBpHObi8ayVXiX6qMG+L6YV8yMEVkI+SYC0DqQJKUo8KsFeSyNL+XpeUND29kUR2faiPg+1PXzZY3b1Bri3NKHbpwy2x561/uYrY8SwNwPq6cllDbpeUWAOBIKSIiIlugtHYF6hSlCgjqIV5lL6hH+aOaHOsBj04GJp8UA0KNugKGQiB+M/B5H2BFR2DzC6YBKeB+EOlsJRKOGfRicKuitLp7ZorbERFZSXEgyU9rGlDw0zpUKd9VZCt/HJ7RBxvHdcG/RrTDxnFdcHhGnypPU5SqbsVBLgAoGYKpSpDLlsorDsCVt6UCYk4zSwN6JF9pRSOltI4MShEREdV1HCllTSo7oMUz4i35JHD8UyD+G+DOxXJeUBRE+mGKuCjoAL0OKMwH9AX3b4XFy/nAvb9LB7dKlplxXRzhFdSjcvVnjioikpDU0wulHBUmZd3kfKVGOZcn9ag1kq/ioBRHShEREdV9vPqe3JzdLo6Sqmn1gsQRW16hgHcY4BUG1AsUA2dlsbUcVQzAEZHE5HqlRrmXJ9VVH82RfX/Biqr7vYnd/ifWHf0bkx5rgqkRYZKXT0Rka3j1PaouvPpeXaQvsGw7jxAxCKSyF2929veXH1yXeVOcFmjOvSTx9iClGvAMEQNVXmFFwapQMWH7d69A0hxVcg762FoAjohqhFyv1Cj38qojYT/JS1oOc0oRERHZCgal5MbF17LtBv7Lsul2Bj1w+bAYMCovzayLj3iVwDuXgNsXgFsJ4rIuB7h1XrxhhwWVEsTy9swUk75bGlSSc9CnupLEyzkIB8i/fkRk0+SYsJ+kk5bLnFJERES2gkEpuWncTQzIVBREcgsQt7OEUiUGdza/KL62rCwcAxaXDqwYDEDGtaIg1QXx/vYF4OYZIC+9gh0W5aha1gbwbgpoGwDaRkX3DQD3hoBrgDiKC5B30MdskvgqBOAAeQfhgOqpn5RBLgbMyFr42SOqEfdzStlbuSZERGSiBvtCCkXFI6BjYmIQGxtb5bK3bt2KQYMGWbT9q6++ilWrViEuLg7/93//V6V9UvkYlJIbS4JIkR9U7uRv8bQY3Ckz0PBB2YEGpRJwbyTemvS7vz7+G+Dbseb3mXFNvJVJAbj6AW4NxCCX3II+ggBk3wbO77AsSfxPi4HA7oCTp3hzrFdxLq7qCMJJpTrqJ2WQS+4Bs+ooT2pyP165vn+14bNHVEek5zLRORGR7NTwD+s3btwwLm/atAlz5sxBQkKCcZ2Li4vk+yxLTk4O4uLiMH36dKxZs8bqQamCggLY29etH20YlJKjqgSRLCmz2ZMP/w+QpdMLn5gvBmfSrxbdrgFpRff6fCDzhnirUFHQ59+9AK8mgLN30c3rgeWim8YVUCgsC6oE9wLSr4tlp199YPla0f11sY6WOvh+6XUO2qIAlccDwSp34OTXpetWfKxVDcIB8h0ZJmWQS+4Bs+ooD5A2cCH345W6PKneu9rw2QPkHyDkiEmygN4g4FammMT+8u1sPNKoHvOFERFZmxV+WPfz8zMua7VaKBQKk3WrVq3CkiVLkJSUhMDAQEyePBkTJkwAIAZuoqOj8e233+LevXvw9fXF+PHjMWvWLAQGBgIABg8eDABo3Lgx/v7773LrsWXLFrRo0QIzZ85EQEAArl69ioYNGxqfz8/Px5w5c7BhwwakpqaiYcOGmDVrFsaOFQdy/Pnnn5gxYwZ++uknCIKAdu3aYd26dQgJCUHv3r3Rrl07LFu2zFjeoEGD4O7ujnXr1gEAAgMDMXbsWFy8eBHbtm3Ds88+i3Xr1mHGjBnYunUrrl27Bj8/P4waNQpz5syBWn3/B50dO3bg3XffRXx8PFxcXNCjRw9s3boV7777LjZv3owzZ86YHGu7du0wcOBAzJs3z/KGkgCDUnIlVRDpQUqVZXmoKmLp9MIur5Vd1+JRSOlXgPgtwPGV5vd5M168VUSlAZy8gOzUcupVtK6sP6ZlUgAO7kDePfObejcHDDog5y6Qe08sPy+9aJrjXxbs64E6ZlwHdk0VR6fVCxKvgGjvVPHLqvLPrUEvBuHu/gXcTQTu/AVcO2HZyLClzcWpmCZBt3oPBN+K1jlogd0SBbnkHjCrjvKKy5RylJmcj7c6ypPivasNn73iMuUcIJT7iEmShT1nbiB2+1lk5esBAFO/OY0ley9IfmVFIiKbJwhi/mBLGPTA7umouC80AwjubVlfSO0kDiZ4COvXr8ecOXPw0UcfoX379jh58iTGjRsHZ2dnREVFYfny5di+fTs2b96MRo0a4erVq7h69SoA4JdffoGPjw/Wrl2LyMhIqFQV13n16tV4/vnnodVq0b9/f6xbtw6zZ882Pv/iiy/i2LFjWL58Odq2bYukpCTcvn0bAHD9+nX07NkTvXv3xoEDB+Dm5oYjR46gsLCwUse7ePFizJkzBzExMcZ1rq6uWLduHQICAhAfH49x48bB1dUV06dPBwDs3LkTgwcPxttvv40vv/wSBQUF2LVrFwBgzJgxmDt3Ln755ReEh4cDAE6ePInTp0/ju+++q1TdpKAQBMGS/9DrDF7iWQLGf6iAMqcXWvoPVdL/gC+eMr9dz2likCP7VtHttulyQVZlj0AMOGkbAtr6gFt98V7b8P6ya4D4R3VZK/MBuCnx9/8AG/RAbhqQcwfIvSve59wRA1aXjwIX/1P5urr6Ax7BYpDKo/hW9Djpp3ICbUVt8dRScdu7fwF3Eu/f3/u7cqPBqlPAI2L7KlWAQinejMsqcTn7FpB4wHxZHV4SrxKpUj9wJcoylhUqYPMLYrllUgBu/sDk04CdBdNHDPqiz0p5Qb0yPivmlBe4qOx5BgD52cCK9mKAuzzO3sAL3wMaF8DeGVA7AnaO4lTekqQ6XkEA9DqgIBv4pAuQlfJw5RV7mPeuIEccxZlxXTz3Lx8Bfv/C/D59W4l1VDsCamcxmGyyXHxzAHZNE/8uSHGsD3u8ta08qetWAfYXylcd782eMzfw2te/l9eyWPn8IwxMERFVUV5eHpKSkhAUFAQHBwex7/V+gHUq81ay2NeshHXr1mHKlClIS0sDADRp0gTz5s3DyJEjjdu899572LVrF44ePYrJkyfjzz//xL59+8rMTWVpTqmLFy+iZcuWSE5OhpeXF7Zt24bo6GgkJiZCoVDgwoULCAsLw969e9GvX79Sr3/rrbcQFxeHhIQEkxFMxSwdKdW+fXts3bq1wrouXrwYcXFx+PXXXwEA3bp1Q3BwML7++usytx8wYAACAwPxySefAAAmT56M+Ph4/PjjjxXup6RSn60HWNpf4EgpqjypphdaOuqq96yK/zkryAFybgN/xAE/zje/32c+Bto/b1kdK5vfS6kCnD3FW0n1O1gWlArsCRRkigGkvPT7Ux0vHylj45L1Kla07oc3y9+Pyl4cieURAniGAILespFr/ReJAbxSgbd7JdbdLaduJST/bn4bS/22VqKCBPGz/Z5XUZBMLQa0lHZF90WPi5cL8ywbZbZrGuDfBrB3EaecFt9rXAD7ons7B0AwmB+ds3u62H65d4sCtbdLB25zitbnZ5g/5OxbwKdlXEDBzrFEUMVRDCRZcryf9gDsNIC+QHyPCovv88WgaGGe+Xo9WN4nXcQ8dw7u4vRgR/ei5QfuNW7iaMMKz4sp4vFm3bwffCoORFV4IYcK3DxTlCPvYRUd6/v1xc+G2kFsA7WD+P7bORQFu4qChnb2wOnNMHu8xa+z09wP0tppij7HGrEclT2gsJN2ZJiUI82q6+ITZHV6g4C5O85W1LKYu+MsHm/hx6l8REQ2Ljs7G4mJiRg7dizGjRtnXF9YWAitVgsAGD16NB5//HGEhYUhMjISTz31FJ544olK72vNmjWIiIiAl5cXADGQM3bsWBw4cAB9+/bFqVOnoFKp0KtXrzJff+rUKfTo0aPMgFRldOzYsdS6TZs2Yfny5UhMTERWVhYKCwtNAj+nTp0yeX9KGjduHMaMGYOlS5dCqVRiw4YN+PDDDx+qnlXFoBRVjRTTC6VK6m7vBNg3Ahp1tWy/7o0tr6OU+b0sDcK9uO3+MefcBe4mAfeSiqbaFd3fSyoa9WJB0MctAPBtLQaePILFm2eIGFh68L016IGz35uvX/jLlrXzXz8BXw40v133aMCziRgUEwxiPQSD6fKdS5YFnEL6isEKfYEYONEXlFguus+9W8EoqRIEgxhAkWJk2a+rzW+jUIkBBF12RZUSgyj/fsjpuCWpncV2eDBYVJgr3lDeyJ4KpP4pWdUA3L8K6MPKuQPsjC7/eXsXcYSim78YiLRklF7P6UC9xmKQXJcN6HLFXyF1OabLaVcsOwbj+y6BnDvABqmSchYFzZY0E4NcCqU4BF+hBKAo/ViXY1kAc1krMThWfO6b/C3Qi8t6nfnzIuO6+L30sFPVqUadSLqLG+nlB6kFADfS83Ai6S66hpTxow8REVWO2kkcsWSJy0eB9UPNbzfqG8uuEK82k5rEjKwscZbM559/js6dO5s8VzwV75FHHkFSUhJ2796Nffv2YdiwYejXrx+++eYbi/ej1+vxxRdfICUlBXZ2dibr16xZg759+8LR0bHCMsw9r1QqUXLimk6nK7Wds7PpyLJjx45h1KhRmDt3LiIiIqDVahEXF4clS5ZYvO+BAwdCo9Fg69atsLe3h06nw9ChFrRzNWBQiqpOihxV1gj6WPLHsmQdpcjvVZUgnJOHeGvQoXR5v38NbJ9ofr+PzwNaW/AHRuorPwY+all79HnHshESF/9jvqxRWyyrn6VTR4dvEN97vU7MG6YvFINaxcsGnfhc8klgX4z58oJ6iV/E+ZniaLj8LHH6aX7W/X+2Bb2Zf7wfYO8i5vd68AIATl6lLwZw5wKwcaT58p7bJJ7TBr0YSNHlPhBgySkKsOQA138DDi00X16vmUBAe3EUjp1D0cgczf3l4tu134CvB5sv77F3xHbOvQfkpYlTZUveZ6WI7685fm3FtnUNEMt087+/7PDA8GLjVEVzIzpnSvvZG/wZ4NtSDBDqcgBdnhik0hU9LswT2+X6b8D5H8yX59ZQDODr88XPbGH+/aBtYX45x1aB7NTKbW9OhYGrSqpomirJUmqmZaMmLd2OiIjMUCgsn0IX0seyPn1InxoZqezr64uAgAD89ddfGDVqVLnbubm5Yfjw4Rg+fDiGDh2KyMhI3L17Fx4eHlCr1dDr9RXuZ9euXcjMzMTJkydN8k6dOXMGL730EtLS0tC6dWsYDAYcOnSozOl7bdq0wRdffAGdTlfmaClvb2+Tqwzq9XqcOXMGjz32WIV1O3r0KBo3boy3337buO7y5cul9r1//3689NJLZZZhZ2eHqKgorF27Fvb29hgxYoTZQFZ1YVCKrM+aQZ/KlC3FL+9SBuHqWTjiy9IrJkpdPynbQ+q2tTSAGRZpWZmB3YET/zZf3gtbyy/PYBADVAVZwF+HgG3jze93ZJxln0uPoMoFbJUqcSqhxgWAd+nNm/QDTn5lvrxe0y17/4J7WVa/HtHmy7M06BMx37L3zlqfvdZDLQ9yWRKUGryy/OMVhKKRSPniZy/OggDmgKXiVFQIRaOZiu5LPk6JB/bONlea+B4HtC/KJ6cQRwyWzC+XfBLY+or5sirzN49kwcfVwfxGldiOiIgkVJ3/Y1XR3LlzMXnyZGi1WkRGRiI/Px+//vor7t27h+joaCxduhT+/v5o3749lEoltmzZAj8/P7i7uwMQ8zTt378fjz76KDQaDerVq1dqH6tXr8aTTz6Jtm3bmqxv0aIF3nzzTaxfvx4TJ05EVFQUxowZY0x0fvnyZaSmpmLYsGGYNGkSVqxYgREjRmDWrFnQarU4fvw4OnXqhLCwMPTp0wfR0dHYuXMnQkJCsHTpUmPerIqEhobiypUriIuLQ3h4OHbu3Fkq51RMTAz69u2LkJAQjBgxAoWFhdi1axdmzJhh3Obll19G8+bNAQBHjpSVKqZmlJHBlsgKioM+rYeK91X9o1YcVHErkQzVLaBaLlVaJS2eBqacAaJ+AIasFu+nxFe+bsX/3BrTwJakEBO3V2VkmBT1Ky5LqvaQsqziL1cApd+/Kny5SlGeUimO0HELANoMk7Zt5Xi81VVedZwXcv7sSXG8CgWgshN/MW0aYVl5HUcDDcOBhp2ARl2Axl3F0ZGB3YGgnmKgMeQxoOtEy8rrNA5o1Blo0FHMvxfQTgx6+bYEfJoD3k3F74fq+JtHVtcpyAP+WoeKWhb+Wgd0CvKoyWoREVExmf2P9fLLL2PVqlVYu3YtWrdujV69emHdunUICgoCIF6ZbtGiRejYsSPCw8Px999/Y9euXVAWXcBnyZIl2Lt3Lxo2bIj27duXKv/mzZvYuXMnhgwZUuo5pVKJwYMHY/VqMS3HypUrMXToUEyYMAHNmjXDuHHjkJ0tznrw9PTEgQMHkJWVhV69eqFDhw74/PPPjaOmxowZg6ioKLz44ovo1asXgoODzY6SAoCnn34ab775JiZNmoR27drh6NGjJlcEBMQk6lu2bMH27dvRrl079OnTBydOnDDZJjQ0FN26dUOzZs1KTYWsSbz6HtVNBv3Dj7yqDaS6EmJ1k7I9pCyrzEvL16/8qLDqKK862lbOxytledV1Xsj1syf18cq5vBr8m8f+Qvmq8+p7QJkty6vvERE9hIqukFYptvI/lo0QBAGhoaGYMGECoqMryLdaASmuvsegFFFtJ3VgwNZI/eUq18BFddRPzuXVhvNCzp8VOZdXQ23L/kL5quu92XPmBubuOGuS9Nxf64CYgS0YkCIiegiSBaWozrh16xbi4uIwa9YsXL16tcwpjJZgUKoK2MmkOom/WtRdbNuqs7X3Tq4Bwuoorwbalv2F8lXne6M3CDiRdBepmXnwcRWn7KmU5U3sIyIiSzAoRSUpFAp4eXnhX//6F5577rkqlyNFUIqJzonqAqkSsZP8sG2rztbeO6mPV87l2Vrb2hCVUoGuIZ7WrgYREVGdJqexSUx0TkRERERERERENU4WQamPP/4YgYGBcHBwQOfOnUtlhS9py5YtaNasGRwcHNC6dWvs2rWrhmpKREREJE96vR6zZ89GUFAQHB0dERISgnnz5pX6NfTcuXN4+umnodVq4ezsjPDwcFy5csVKtSYiIiJbZvWg1KZNmxAdHY2YmBj8/vvvaNu2LSIiIpCamlrm9kePHsXIkSMxduxYnDx5EoMGDcKgQYNw5syZGq45ERERkXwsXLgQK1euxEcffYRz585h4cKFWLRoEVasWGHcJjExEd27d0ezZs1w8OBBnD59GrNnz2aOESIiGyCnKVtUN0jxmbJ6ovPOnTsjPDwcH330EQDAYDCgYcOGeP311zFz5sxS2w8fPhzZ2dn44YcfjOu6dOmCdu3a4dNPPzW7PyYuJSIiInNqY3/hqaeegq+vL1avXm1cN2TIEDg6OuLrr78GAIwYMQJqtRpfffVVlfdTG98bIiJbptPpcOnSJQQEBECr1Vq7OlSH3LlzB6mpqWjatClUKtOLztSKROcFBQX47bffMGvWLOM6pVKJfv364dixY2W+5tixY4iOjjZZFxERgW3btlVnVYmIiIhkrVu3bvjss89w4cIFNG3aFH/88QcOHz6MpUuXAhB/+Nu5cyemT5+OiIgInDx5EkFBQZg1axYGDRpk3coTEVG1sbOzg5OTE27dugW1Wg2l0uoTpqiWEwQBOTk5SE1Nhbu7e6mAVGVYNSh1+/Zt6PV6+Pr6mqz39fXF+fPny3xNSkpKmdunpKSUuX1+fj7y8/ONjzMyMh6y1kRERETyM3PmTGRkZKBZs2ZQqVTQ6/WYP38+Ro0aBQBITU1FVlYWPvjgA7z33ntYuHAh9uzZg2effRY//vgjevXqVWa57EsREdVuCoUC/v7+SEpKwuXLl61dHapD3N3d4efn91BlWDUoVRMWLFiAuXPnWrsaRERERNVq8+bNWL9+PTZs2ICWLVvi1KlTmDJlCgICAhAVFQWDwQAAeOaZZ/Dmm28CANq1a4ejR4/i008/LTcoxb4UEVHtZ29vj9DQUBQUFFi7KlRHqNXqhxohVcyqQSkvLy+oVCrcvHnTZP3NmzfLjbb5+flVavtZs2aZTPfLyMhAw4YNH7LmRERERPIybdo0zJw5EyNGjAAAtG7dGpcvX8aCBQsQFRUFLy8v2NnZoUWLFiava968OQ4fPlxuuexLERHVDUqlkhe2INmx6mRSe3t7dOjQAfv37zeuMxgM2L9/P7p27Vrma7p27WqyPQDs3bu33O01Gg3c3NxMbkRERER1TU5OTqk8ISqVyjhCyt7eHuHh4UhISDDZ5sKFC2jcuHG55bIvRURERNXF6tP3oqOjERUVhY4dO6JTp05YtmwZsrOz8dJLLwEAXnzxRdSvXx8LFiwAALzxxhvo1asXlixZgieffBJxcXH49ddf8dlnn1nzMIiIiIisauDAgZg/fz4aNWqEli1b4uTJk1i6dCnGjBlj3GbatGkYPnw4evbsicceewx79uzBjh07cPDgQetVnIiIiGyW1YNSw4cPx61btzBnzhykpKSgXbt22LNnjzGZ+ZUrV0x+9evWrRs2bNiAd955B2+99RZCQ0Oxbds2tGrVylqHQERERGR1K1aswOzZszFhwgSkpqYiICAAr776KubMmWPcZvDgwfj000+xYMECTJ48GWFhYfj222/RvXt3K9aciIiIbJVCEATB2pWoSenp6XB3d8fVq1c5/JyIiIjKVJw3KS0tDVqt1trVkRX2pYiIiMgcS/tSVh8pVdMyMzMBgAk6iYiIyKzMzEwGpUpgX4qIiIgsZa4vZXMjpQwGA5KTk+Hq6gqFQmGM3vHXPutjW8gL20M+2BbywbaQj+puC0EQkJmZiYCAgFLJw20d+1LyxbaQD7aFvLA95INtIR9y6UvZ3EgppVKJBg0alFrPq8nIB9tCXtge8sG2kA+2hXxUZ1twhFTZ2JeSP7aFfLAt5IXtIR9sC/mwdl+KP/0REREREREREVGNY1CKiIiIiIiIiIhqnM0HpTQaDWJiYqDRaKxdFZvHtpAXtod8sC3kg20hH2wL+WBbyAfbQj7YFvLC9pAPtoV8yKUtbC7RORERERERERERWZ/Nj5QiIiIiIiIiIqKax6AUERERERERERHVOAaliIiIiIiIiIioxtl8UOrjjz9GYGAgHBwc0LlzZ5w4ccLaVbI5sbGxUCgUJrdmzZpZu1o24aeffsLAgQMREBAAhUKBbdu2mTwvCALmzJkDf39/ODo6ol+/frh48aJ1KmsDzLXH6NGjS50rkZGR1qlsHbZgwQKEh4fD1dUVPj4+GDRoEBISEky2ycvLw8SJE+Hp6QkXFxcMGTIEN2/etFKN6zZL2qN3796lzo3x48dbqca2hf0oeWBfynrYl5IP9qPkg30p+agN/SibDkpt2rQJ0dHRiImJwe+//462bdsiIiICqamp1q6azWnZsiVu3LhhvB0+fNjaVbIJ2dnZaNu2LT7++OMyn1+0aBGWL1+OTz/9FD///DOcnZ0RERGBvLy8Gq6pbTDXHgAQGRlpcq5s3LixBmtoGw4dOoSJEyfi+PHj2Lt3L3Q6HZ544glkZ2cbt3nzzTexY8cObNmyBYcOHUJycjKeffZZK9a67rKkPQBg3LhxJufGokWLrFRj28F+lLywL2Ud7EvJB/tR8sG+lHzUin6UYMM6deokTJw40fhYr9cLAQEBwoIFC6xYK9sTExMjtG3b1trVsHkAhK1btxofGwwGwc/PT/jnP/9pXJeWliZoNBph48aNVqihbSnZHoIgCFFRUcIzzzxjlfrYstTUVAGAcOjQIUEQxPNArVYLW7ZsMW5z7tw5AYBw7Ngxa1XTZpRsD0EQhF69eglvvPGG9Splo9iPkg/2peSBfSn5YD9KXtiXkg859qNsdqRUQUEBfvvtN/Tr18+4TqlUol+/fjh27JgVa2abLl68iICAAAQHB2PUqFG4cuWKtatk85KSkpCSkmJyjmi1WnTu3JnniBUdPHgQPj4+CAsLw2uvvYY7d+5Yu0p1Xnp6OgDAw8MDAPDbb79Bp9OZnBvNmjVDo0aNeG7UgJLtUWz9+vXw8vJCq1atMGvWLOTk5FijejaD/Sj5YV9KftiXkh/2o6yDfSn5kGM/yq7G9iQzt2/fhl6vh6+vr8l6X19fnD9/3kq1sk2dO3fGunXrEBYWhhs3bmDu3Lno0aMHzpw5A1dXV2tXz2alpKQAQJnnSPFzVLMiIyPx7LPPIigoCImJiXjrrbfQv39/HDt2DCqVytrVq5MMBgOmTJmCRx99FK1atQIgnhv29vZwd3c32ZbnRvUrqz0A4LnnnkPjxo0REBCA06dPY8aMGUhISMB3331nxdrWbexHyQv7UvLEvpS8sB9lHexLyYdc+1E2G5Qi+ejfv79xuU2bNujcuTMaN26MzZs3Y+zYsVasGZG8jBgxwrjcunVrtGnTBiEhITh48CD69u1rxZrVXRMnTsSZM2eYm0UmymuPV155xbjcunVr+Pv7o2/fvkhMTERISEhNV5OoxrEvRWQe+1HWwb6UfMi1H2Wz0/e8vLygUqlKZfi/efMm/Pz8rFQrAgB3d3c0bdoUly5dsnZVbFrxecBzRL6Cg4Ph5eXFc6WaTJo0CT/88AN+/PFHNGjQwLjez88PBQUFSEtLM9me50b1Kq89ytK5c2cA4LlRjdiPkjf2peSBfSl5Yz+q+rEvJR9y7kfZbFDK3t4eHTp0wP79+43rDAYD9u/fj65du1qxZpSVlYXExET4+/tbuyo2LSgoCH5+fibnSEZGBn7++WeeIzJx7do13Llzh+eKxARBwKRJk7B161YcOHAAQUFBJs936NABarXa5NxISEjAlStXeG5UA3PtUZZTp04BAM+NasR+lLyxLyUP7EvJG/tR1Yd9KfmoDf0om56+Fx0djaioKHTs2BGdOnXCsmXLkJ2djZdeesnaVbMpU6dOxcCBA9G4cWMkJycjJiYGKpUKI0eOtHbV6rysrCyTCHhSUhJOnToFDw8PNGrUCFOmTMF7772H0NBQBAUFYfbs2QgICMCgQYOsV+k6rKL28PDwwNy5czFkyBD4+fkhMTER06dPR5MmTRAREWHFWtc9EydOxIYNG/D999/D1dXVmNtAq9XC0dERWq0WY8eORXR0NDw8PODm5obXX38dXbt2RZcuXaxc+7rHXHskJiZiw4YNGDBgADw9PXH69Gm8+eab6NmzJ9q0aWPl2tdt7EfJB/tS1sO+lHywHyUf7EvJR63oR1ntun8ysWLFCqFRo0aCvb290KlTJ+H48ePWrpLNGT58uODv7y/Y29sL9evXF4YPHy5cunTJ2tWyCT/++KMAoNQtKipKEATxUsazZ88WfH19BY1GI/Tt21dISEiwbqXrsIraIycnR3jiiScEb29vQa1WC40bNxbGjRsnpKSkWLvadU5ZbQBAWLt2rXGb3NxcYcKECUK9evUEJycnYfDgwcKNGzesV+k6zFx7XLlyRejZs6fg4eEhaDQaoUmTJsK0adOE9PR061bcRrAfJQ/sS1kP+1LywX6UfLAvJR+1oR+lKKooERERERERERFRjbHZnFJERERERERERGQ9DEoREREREREREVGNY1CKiIiIiIiIiIhqHINSRERERERERERU4xiUIiIiIiIiIiKiGsegFBERERERERER1TgGpYiIiIiIiIiIqMYxKEVERERERERERDWOQSkioipSKBTYtm2btatBREREVCuxL0VEDEoRUa00evRoKBSKUrfIyEhrV42IiIhI9tiXIiI5sLN2BYiIqioyMhJr1641WafRaKxUGyIiIqLahX0pIrI2jpQiolpLo9HAz8/P5FavXj0A4nDwlStXon///nB0dERwcDC++eYbk9fHx8ejT58+cHR0hKenJ1555RVkZWWZbLNmzRq0bNkSGo0G/v7+mDRpksnzt2/fxuDBg+Hk5ITQ0FBs3769eg+aiIiISCLsSxGRtTEoRUR11uzZszFkyBD88ccfGDVqFEaMGIFz584BALKzsxEREYF69erhl19+wZYtW7Bv3z6TjtLKlSsxceJEvPLKK4iPj8f27dvRpEkTk33MnTsXw4YNw+nTpzFgwACMGjUKd+/erdHjJCIiIqoO7EsRUbUTiIhqoaioKEGlUgnOzs4mt/nz5wuCIAgAhPHjx5u8pnPnzsJrr70mCIIgfPbZZ0K9evWErKws4/M7d+4UlEqlkJKSIgiCIAQEBAhvv/12uXUAILzzzjvGx1lZWQIAYffu3ZIdJxEREVF1YF+KiOSAOaWIqNZ67LHHsHLlSpN1Hh4exuWuXbuaPNe1a1ecOnUKAHDu3Dm0bdsWzs7OxucfffRRGAwGJCQkQKFQIDk5GX379q2wDm3atDEuOzs7w83NDampqVU9JCIiIqIaw74UEVkbg1JEVGs5OzuXGgIuFUdHR4u2U6vVJo8VCgUMBkN1VImIiIhIUuxLEZG1MacUEdVZx48fL/W4efPmAIDmzZvjjz/+QHZ2tvH5I0eOQKlUIiwsDK6urggMDMT+/ftrtM5EREREcsG+FBFVN46UIqJaKz8/HykpKSbr7Ozs4OXlBQDYsmULOnbsiO7du2P9+vU4ceIEVq9eDQAYNWoUYmJiEBUVhdjYWNy6dQuvv/46XnjhBfj6+gIAYmNjMX78ePj4+KB///7IzMzEkSNH8Prrr9fsgRIRERFVA/aliMjaGJQiolprz5498Pf3N1kXFhaG8+fPAxCv5hIXF4cJEybA398fGzduRIsWLQAATk5O+M9//oM33ngD4eHhcHJywpAhQ7B06VJjWVFRUcjLy8OHH36IqVOnwsvLC0OHDq25AyQiIiKqRuxLEZG1KQRBEKxdCSIiqSkUCmzduhWDBg2ydlWIiIiIah32pYioJjCnFBERERERERER1TgGpYiIiIiIiIiIqMZx+h4REREREREREdU4jpQiIiIiIiIiIqIax6AUERERERERERHVOAaliIiIiIiIiIioxjEoRURERERERERENY5BKSIiIiIiIiIiqnEMShERERERERERUY1jUIqIiIiIiIiIiGocg1JERERERERERFTjGJQiIiIiIiIiIqIa9//p6GV1IgmQ6AAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model_dir' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-685ba93c60ee>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-1-685ba93c60ee>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;31m# Compress the folder into a zip file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m     \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'zip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Use the same folder name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;31m# Download the zip file in Google Colab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model_dir' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = '/content/MNIST_Model_seed_83082'\n",
        "\n",
        "# Compress the folder into a zip file\n",
        "shutil.make_archive(model_path, 'zip', model_path)  # Use the same folder name\n",
        "\n",
        "# Download the zip file in Google Colab\n",
        "files.download('MNIST_Model_seed_83082.zip')  # Download the zip file with the correct name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "wWNX1-fHWZAB",
        "outputId": "ffefd9f9-2254-4a89-de22-773ff66a066a"
      },
      "id": "wWNX1-fHWZAB",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2b094ec2-74d1-4e74-a72a-4eeb86623e43\", \"MNIST_Model_seed_83082.zip\", 56238615)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}