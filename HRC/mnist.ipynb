{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Augmentation"
      ],
      "metadata": {
        "id": "QYAo84CmbY9R"
      },
      "id": "QYAo84CmbY9R"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import random\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,)),\n",
        "])\n",
        "\n",
        "# Load the MNIST dataset with the transformation\n",
        "dataset = datasets.MNIST('../data', train=True, download=True, transform=transform)\n",
        "\n",
        "# Retrieve an image from the dataset\n",
        "image, label = dataset[0]  # Get the first image and its label\n",
        "\n",
        "# Convert the tensor to a numpy array and remove the batch dimension\n",
        "image = image.squeeze().numpy()\n",
        "\n",
        "# Display the image\n",
        "plt.imshow(image, cmap='gray')\n",
        "plt.title(f'Label: {label}')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "J_3E_Ky6bWax",
        "outputId": "d1bd7307-5f76-4056-db41-6b1afb2b154a"
      },
      "id": "J_3E_Ky6bWax",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGzCAYAAABpdMNsAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAIH5JREFUeJzt3XtwVPX5x/HPEmG5mCwGyI2bBBREbhYhUhFBIkmqjCB2vE6hdbBgcFAqKLYCtrXxig6KyEwtaBVQWwGlDlaBhFoDNFxkqEoJEwpIEhCb3RAkIPn+/mDcnysJcMKGJwnv18x3JnvO99nz5HjMh7Nn96zPOecEAMA51sS6AQDA+YkAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACztKuXbvk8/n0zDPPRO05c3Nz5fP5lJubG7XnBOobAgjnpYULF8rn86mgoMC6lToxa9Ys+Xy+k0bz5s2tWwPCLrBuAEDdmTdvni688MLw45iYGMNugEgEENCI3XLLLWrbtq11G0C1eAkOqMHRo0c1Y8YM9e/fX4FAQK1atdI111yjNWvW1Fjz3HPPqXPnzmrRooWuvfZabdu27aQ5X3zxhW655RbFx8erefPmuvLKK/Xuu++etp/Dhw/riy++0FdffXXGv4NzTqFQSNz0HvURAQTUIBQK6Y9//KOGDh2qJ598UrNmzdKBAweUkZGhLVu2nDT/tdde05w5c5Sdna3p06dr27Ztuu6661RaWhqe8+9//1tXXXWVPv/8cz388MN69tln1apVK40aNUpLly49ZT8bNmzQZZddphdffPGMf4fU1FQFAgHFxsbqrrvuiugFsMZLcEANLrroIu3atUvNmjULLxs/frx69OihF154Qa+88krE/MLCQu3YsUPt27eXJGVmZiotLU1PPvmkZs+eLUmaPHmyOnXqpH/961/y+/2SpHvvvVeDBw/WQw89pNGjR0et90mTJmnQoEHy+/36xz/+oblz52rDhg0qKChQXFxcVLYDnA0CCKhBTExM+KJ9VVWVysrKVFVVpSuvvFKbNm06af6oUaPC4SNJAwcOVFpamt5//33Nnj1bX3/9tVavXq3f/va3Ki8vV3l5eXhuRkaGZs6cqS+//DLiOb5v6NChZ/xS2uTJkyMejxkzRgMHDtSdd96pl156SQ8//PAZPQ9Ql3gJDjiFV199VX369FHz5s3Vpk0btWvXTn/7298UDAZPmnvJJZectOzSSy/Vrl27JJ04Q3LO6dFHH1W7du0ixsyZMyVJ+/fvr7Pf5Y477lBSUpI++uijOtsG4AVnQEANXn/9dY0bN06jRo3S1KlTlZCQoJiYGOXk5Gjnzp2en6+qqkqS9OCDDyojI6PaOd26dTurnk+nY8eO+vrrr+t0G8CZIoCAGvzlL39Ramqq3nnnHfl8vvDy785WfmjHjh0nLfvPf/6jiy++WNKJNwRIUtOmTZWenh79hk/DOaddu3bpiiuuOOfbBqrDS3BADb67/vP96y7r169Xfn5+tfOXLVumL7/8Mvx4w4YNWr9+vbKysiRJCQkJGjp0qObPn6/i4uKT6g8cOHDKfry8Dbu655o3b54OHDigzMzM09YD5wJnQDiv/elPf9LKlStPWj558mTdeOONeueddzR69GjdcMMNKioq0ssvv6yePXvq0KFDJ9V069ZNgwcP1sSJE1VZWannn39ebdq00bRp08Jz5s6dq8GDB6t3794aP368UlNTVVpaqvz8fO3du1effvppjb1u2LBBw4YN08yZMzVr1qxT/l6dO3fWrbfeqt69e6t58+b6+OOPtWTJEvXr10+//OUvz3wHAXWIAMJ5bd68edUuHzdunMaNG6eSkhLNnz9fH3zwgXr27KnXX39db7/9drU3Cf3Zz36mJk2a6Pnnn9f+/fs1cOBAvfjii0pOTg7P6dmzpwoKCvTYY49p4cKFOnjwoBISEnTFFVdoxowZUfu97rzzTn3yySf661//qiNHjqhz586aNm2afv3rX6tly5ZR2w5wNnyOj0gDAAxwDQgAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmKh3nwOqqqrSvn37FBsbG3H7EwBAw+CcU3l5uVJSUtSkSc3nOfUugPbt26eOHTtatwEAOEt79uxRhw4dalxf716Ci42NtW4BABAFp/t7XmcBNHfuXF188cVq3ry50tLStGHDhjOq42U3AGgcTvf3vE4C6M0339SUKVM0c+ZMbdq0SX379lVGRkadftkWAKCBcXVg4MCBLjs7O/z4+PHjLiUlxeXk5Jy2NhgMOkkMBoPBaOAjGAye8u991M+Ajh49qo0bN0Z84VaTJk2Unp5e7feoVFZWKhQKRQwAQOMX9QD66quvdPz4cSUmJkYsT0xMVElJyUnzc3JyFAgEwoN3wAHA+cH8XXDTp09XMBgMjz179li3BAA4B6L+OaC2bdsqJiZGpaWlEctLS0uVlJR00ny/3y+/3x/tNgAA9VzUz4CaNWum/v37a9WqVeFlVVVVWrVqlQYNGhTtzQEAGqg6uRPClClTNHbsWF155ZUaOHCgnn/+eVVUVOjnP/95XWwOANAA1UkA3XrrrTpw4IBmzJihkpIS9evXTytXrjzpjQkAgPOXzznnrJv4vlAopEAgYN0GAOAsBYNBxcXF1bje/F1wAIDzEwEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATF1g3ANQnMTExnmsCgUAddBIdkyZNqlVdy5YtPdd0797dc012drbnmmeeecZzze233+65RpKOHDniueaJJ57wXPPYY495rmkMOAMCAJgggAAAJqIeQLNmzZLP54sYPXr0iPZmAAANXJ1cA7r88sv10Ucf/f9GLuBSEwAgUp0kwwUXXKCkpKS6eGoAQCNRJ9eAduzYoZSUFKWmpurOO+/U7t27a5xbWVmpUCgUMQAAjV/UAygtLU0LFy7UypUrNW/ePBUVFemaa65ReXl5tfNzcnIUCATCo2PHjtFuCQBQD0U9gLKysvTTn/5Uffr0UUZGht5//32VlZXprbfeqnb+9OnTFQwGw2PPnj3RbgkAUA/V+bsDWrdurUsvvVSFhYXVrvf7/fL7/XXdBgCgnqnzzwEdOnRIO3fuVHJycl1vCgDQgEQ9gB588EHl5eVp165d+uSTTzR69GjFxMTU+lYYAIDGKeovwe3du1e33367Dh48qHbt2mnw4MFat26d2rVrF+1NAQAasKgH0JIlS6L9lKinOnXq5LmmWbNmnmt+/OMfe64ZPHiw5xrpxDVLr8aMGVOrbTU2e/fu9VwzZ84czzWjR4/2XFPTu3BP59NPP/Vck5eXV6ttnY+4FxwAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATPuecs27i+0KhkAKBgHUb55V+/frVqm716tWea/hv2zBUVVV5rvnFL37huebQoUOea2qjuLi4VnX/+9//PNds3769VttqjILBoOLi4mpczxkQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMDEBdYNwN7u3btrVXfw4EHPNdwN+4T169d7rikrK/NcM2zYMM81knT06FHPNX/+859rtS2cvzgDAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIKbkUJff/11reqmTp3quebGG2/0XLN582bPNXPmzPFcU1tbtmzxXHP99dd7rqmoqPBcc/nll3uukaTJkyfXqg7wgjMgAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJnzOOWfdxPeFQiEFAgHrNlBH4uLiPNeUl5d7rpk/f77nGkm6++67PdfcddddnmsWL17suQZoaILB4Cn/n+cMCABgggACAJjwHEBr167VyJEjlZKSIp/Pp2XLlkWsd85pxowZSk5OVosWLZSenq4dO3ZEq18AQCPhOYAqKirUt29fzZ07t9r1Tz31lObMmaOXX35Z69evV6tWrZSRkaEjR46cdbMAgMbD8zeiZmVlKSsrq9p1zjk9//zz+s1vfqObbrpJkvTaa68pMTFRy5Yt02233XZ23QIAGo2oXgMqKipSSUmJ0tPTw8sCgYDS0tKUn59fbU1lZaVCoVDEAAA0flENoJKSEklSYmJixPLExMTwuh/KyclRIBAIj44dO0azJQBAPWX+Lrjp06crGAyGx549e6xbAgCcA1ENoKSkJElSaWlpxPLS0tLwuh/y+/2Ki4uLGACAxi+qAdSlSxclJSVp1apV4WWhUEjr16/XoEGDorkpAEAD5/ldcIcOHVJhYWH4cVFRkbZs2aL4+Hh16tRJ999/v37/+9/rkksuUZcuXfToo48qJSVFo0aNimbfAIAGznMAFRQUaNiwYeHHU6ZMkSSNHTtWCxcu1LRp01RRUaF77rlHZWVlGjx4sFauXKnmzZtHr2sAQIPHzUjRKD399NO1qvvuH1Re5OXlea75/kcVzlRVVZXnGsASNyMFANRLBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAAT3A0bjVKrVq1qVffee+95rrn22ms912RlZXmu+fvf/+65BrDE3bABAPUSAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAE9yMFPierl27eq7ZtGmT55qysjLPNWvWrPFcU1BQ4LlGkubOneu5pp79KUE9wM1IAQD1EgEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABPcjBQ4S6NHj/Zcs2DBAs81sbGxnmtq65FHHvFc89prr3muKS4u9lyDhoObkQIA6iUCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmuBkpYKBXr16ea2bPnu25Zvjw4Z5ramv+/Pmeax5//HHPNV9++aXnGtjgZqQAgHqJAAIAmPAcQGvXrtXIkSOVkpIin8+nZcuWRawfN26cfD5fxMjMzIxWvwCARsJzAFVUVKhv376aO3dujXMyMzNVXFwcHosXLz6rJgEAjc8FXguysrKUlZV1yjl+v19JSUm1bgoA0PjVyTWg3NxcJSQkqHv37po4caIOHjxY49zKykqFQqGIAQBo/KIeQJmZmXrttde0atUqPfnkk8rLy1NWVpaOHz9e7fycnBwFAoHw6NixY7RbAgDUQ55fgjud2267Lfxz79691adPH3Xt2lW5ubnVfiZh+vTpmjJlSvhxKBQihADgPFDnb8NOTU1V27ZtVVhYWO16v9+vuLi4iAEAaPzqPID27t2rgwcPKjk5ua43BQBoQDy/BHfo0KGIs5mioiJt2bJF8fHxio+P12OPPaYxY8YoKSlJO3fu1LRp09StWzdlZGREtXEAQMPmOYAKCgo0bNiw8OPvrt+MHTtW8+bN09atW/Xqq6+qrKxMKSkpGjFihH73u9/J7/dHr2sAQIPHzUiBBqJ169aea0aOHFmrbS1YsMBzjc/n81yzevVqzzXXX3+95xrY4GakAIB6iQACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABggrthAzhJZWWl55oLLvD87S769ttvPdfU5rvFcnNzPdfg7HE3bABAvUQAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMCE97sHAjhrffr08Vxzyy23eK4ZMGCA5xqpdjcWrY3PPvvMc83atWvroBNY4AwIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACW5GCnxP9+7dPddMmjTJc83NN9/suSYpKclzzbl0/PhxzzXFxcWea6qqqjzXoH7iDAgAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJbkaKeq82N+G8/fbba7Wt2txY9OKLL67VtuqzgoICzzWPP/6455p3333Xcw0aD86AAAAmCCAAgAlPAZSTk6MBAwYoNjZWCQkJGjVqlLZv3x4x58iRI8rOzlabNm104YUXasyYMSotLY1q0wCAhs9TAOXl5Sk7O1vr1q3Thx9+qGPHjmnEiBGqqKgIz3nggQf03nvv6e2331ZeXp727dtXqy/fAgA0bp7ehLBy5cqIxwsXLlRCQoI2btyoIUOGKBgM6pVXXtGiRYt03XXXSZIWLFigyy67TOvWrdNVV10Vvc4BAA3aWV0DCgaDkqT4+HhJ0saNG3Xs2DGlp6eH5/To0UOdOnVSfn5+tc9RWVmpUCgUMQAAjV+tA6iqqkr333+/rr76avXq1UuSVFJSombNmql169YRcxMTE1VSUlLt8+Tk5CgQCIRHx44da9sSAKABqXUAZWdna9u2bVqyZMlZNTB9+nQFg8Hw2LNnz1k9HwCgYajVB1EnTZqkFStWaO3aterQoUN4eVJSko4ePaqysrKIs6DS0tIaP0zo9/vl9/tr0wYAoAHzdAbknNOkSZO0dOlSrV69Wl26dIlY379/fzVt2lSrVq0KL9u+fbt2796tQYMGRadjAECj4OkMKDs7W4sWLdLy5csVGxsbvq4TCATUokULBQIB3X333ZoyZYri4+MVFxen++67T4MGDeIdcACACJ4CaN68eZKkoUOHRixfsGCBxo0bJ0l67rnn1KRJE40ZM0aVlZXKyMjQSy+9FJVmAQCNh88556yb+L5QKKRAIGDdBs5AYmKi55qePXt6rnnxxRc91/To0cNzTX23fv16zzVPP/10rba1fPlyzzVVVVW12hYar2AwqLi4uBrXcy84AIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAICJWn0jKuqv+Ph4zzXz58+v1bb69evnuSY1NbVW26rPPvnkE881zz77rOeaDz74wHPNN99847kGOFc4AwIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCm5GeI2lpaZ5rpk6d6rlm4MCBnmvat2/vuaa+O3z4cK3q5syZ47nmD3/4g+eaiooKzzVAY8MZEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABPcjPQcGT169DmpOZc+++wzzzUrVqzwXPPtt996rnn22Wc910hSWVlZreoAeMcZEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABM+55yzbuL7QqGQAoGAdRsAgLMUDAYVFxdX43rOgAAAJgggAIAJTwGUk5OjAQMGKDY2VgkJCRo1apS2b98eMWfo0KHy+XwRY8KECVFtGgDQ8HkKoLy8PGVnZ2vdunX68MMPdezYMY0YMUIVFRUR88aPH6/i4uLweOqpp6LaNACg4fP0jagrV66MeLxw4UIlJCRo48aNGjJkSHh5y5YtlZSUFJ0OAQCN0lldAwoGg5Kk+Pj4iOVvvPGG2rZtq169emn69Ok6fPhwjc9RWVmpUCgUMQAA5wFXS8ePH3c33HCDu/rqqyOWz58/361cudJt3brVvf766659+/Zu9OjRNT7PzJkznSQGg8FgNLIRDAZPmSO1DqAJEya4zp07uz179pxy3qpVq5wkV1hYWO36I0eOuGAwGB579uwx32kMBoPBOPtxugDydA3oO5MmTdKKFSu0du1adejQ4ZRz09LSJEmFhYXq2rXrSev9fr/8fn9t2gAANGCeAsg5p/vuu09Lly5Vbm6uunTpctqaLVu2SJKSk5Nr1SAAoHHyFEDZ2dlatGiRli9frtjYWJWUlEiSAoGAWrRooZ07d2rRokX6yU9+ojZt2mjr1q164IEHNGTIEPXp06dOfgEAQAPl5bqPanidb8GCBc4553bv3u2GDBni4uPjnd/vd926dXNTp0497euA3xcMBs1ft2QwGAzG2Y/T/e3nZqQAgDrBzUgBAPUSAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMBEvQsg55x1CwCAKDjd3/N6F0Dl5eXWLQAAouB0f899rp6dclRVVWnfvn2KjY2Vz+eLWBcKhdSxY0ft2bNHcXFxRh3aYz+cwH44gf1wAvvhhPqwH5xzKi8vV0pKipo0qfk854Jz2NMZadKkiTp06HDKOXFxcef1AfYd9sMJ7IcT2A8nsB9OsN4PgUDgtHPq3UtwAIDzAwEEADDRoALI7/dr5syZ8vv91q2YYj+cwH44gf1wAvvhhIa0H+rdmxAAAOeHBnUGBABoPAggAIAJAggAYIIAAgCYIIAAACYaTADNnTtXF198sZo3b660tDRt2LDBuqVzbtasWfL5fBGjR48e1m3VubVr12rkyJFKSUmRz+fTsmXLItY75zRjxgwlJyerRYsWSk9P144dO2yarUOn2w/jxo076fjIzMy0abaO5OTkaMCAAYqNjVVCQoJGjRql7du3R8w5cuSIsrOz1aZNG1144YUaM2aMSktLjTquG2eyH4YOHXrS8TBhwgSjjqvXIALozTff1JQpUzRz5kxt2rRJffv2VUZGhvbv32/d2jl3+eWXq7i4ODw+/vhj65bqXEVFhfr27au5c+dWu/6pp57SnDlz9PLLL2v9+vVq1aqVMjIydOTIkXPcad063X6QpMzMzIjjY/Hixeeww7qXl5en7OxsrVu3Th9++KGOHTumESNGqKKiIjzngQce0Hvvvae3335beXl52rdvn26++WbDrqPvTPaDJI0fPz7ieHjqqaeMOq6BawAGDhzosrOzw4+PHz/uUlJSXE5OjmFX597MmTNd3759rdswJcktXbo0/LiqqsolJSW5p59+OrysrKzM+f1+t3jxYoMOz40f7gfnnBs7dqy76aabTPqxsn//fifJ5eXlOedO/Ldv2rSpe/vtt8NzPv/8cyfJ5efnW7VZ5364H5xz7tprr3WTJ0+2a+oM1PszoKNHj2rjxo1KT08PL2vSpInS09OVn59v2JmNHTt2KCUlRampqbrzzju1e/du65ZMFRUVqaSkJOL4CAQCSktLOy+Pj9zcXCUkJKh79+6aOHGiDh48aN1SnQoGg5Kk+Ph4SdLGjRt17NixiOOhR48e6tSpU6M+Hn64H77zxhtvqG3bturVq5emT5+uw4cPW7RXo3p3N+wf+uqrr3T8+HElJiZGLE9MTNQXX3xh1JWNtLQ0LVy4UN27d1dxcbEee+wxXXPNNdq2bZtiY2Ot2zNRUlIiSdUeH9+tO19kZmbq5ptvVpcuXbRz50498sgjysrKUn5+vmJiYqzbi7qqqirdf//9uvrqq9WrVy9JJ46HZs2aqXXr1hFzG/PxUN1+kKQ77rhDnTt3VkpKirZu3aqHHnpI27dv1zvvvGPYbaR6H0D4f1lZWeGf+/Tpo7S0NHXu3FlvvfWW7r77bsPOUB/cdttt4Z979+6tPn36qGvXrsrNzdXw4cMNO6sb2dnZ2rZt23lxHfRUatoP99xzT/jn3r17Kzk5WcOHD9fOnTvVtWvXc91mter9S3Bt27ZVTEzMSe9iKS0tVVJSklFX9UPr1q116aWXqrCw0LoVM98dAxwfJ0tNTVXbtm0b5fExadIkrVixQmvWrIn4/rCkpCQdPXpUZWVlEfMb6/FQ036oTlpamiTVq+Oh3gdQs2bN1L9/f61atSq8rKqqSqtWrdKgQYMMO7N36NAh7dy5U8nJydatmOnSpYuSkpIijo9QKKT169ef98fH3r17dfDgwUZ1fDjnNGnSJC1dulSrV69Wly5dItb3799fTZs2jTgetm/frt27dzeq4+F0+6E6W7ZskaT6dTxYvwviTCxZssT5/X63cOFC99lnn7l77rnHtW7d2pWUlFi3dk796le/crm5ua6oqMj985//dOnp6a5t27Zu//791q3VqfLycrd582a3efNmJ8nNnj3bbd682f33v/91zjn3xBNPuNatW7vly5e7rVu3uptuusl16dLFffPNN8adR9ep9kN5ebl78MEHXX5+visqKnIfffSR+9GPfuQuueQSd+TIEevWo2bixIkuEAi43NxcV1xcHB6HDx8Oz5kwYYLr1KmTW716tSsoKHCDBg1ygwYNMuw6+k63HwoLC91vf/tbV1BQ4IqKitzy5ctdamqqGzJkiHHnkRpEADnn3AsvvOA6derkmjVr5gYOHOjWrVtn3dI5d+utt7rk5GTXrFkz1759e3frrbe6wsJC67bq3Jo1a5ykk8bYsWOdcyfeiv3oo4+6xMRE5/f73fDhw9327dttm64Dp9oPhw8fdiNGjHDt2rVzTZs2dZ07d3bjx49vdP9Iq+73l+QWLFgQnvPNN9+4e++911100UWuZcuWbvTo0a64uNiu6Tpwuv2we/duN2TIEBcfH+/8fr/r1q2bmzp1qgsGg7aN/wDfBwQAMFHvrwEBABonAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJj4P4+ugj9xwbmpAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import random\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "# Custom transformation to add Gaussian noise\n",
        "class AddGaussianNoise:\n",
        "    def __init__(self, mean=0., std=0.1):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n",
        "\n",
        "# Define the augmentation pipeline with thinning and Gaussian noise\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Convert to tensor\n",
        "    transforms.Normalize((0.1307,), (0.3081,)),  # Normalize\n",
        "    transforms.RandomAffine(degrees=(-5,5), translate=(0.2, 0.2), scale=(0.7, 1.3), shear=10),  # Random affine\n",
        "    transforms.RandomApply([transforms.GaussianBlur(kernel_size=1)], p=0.3),  # Gaussian blur\n",
        "    transforms.RandomApply([transforms.ColorJitter(brightness=0.1, contrast=0.1)], p=0.3),\n",
        "    transforms.RandomApply([AddGaussianNoise(mean=0., std=0.1)], p=0.2)  # Add Gaussian noise\n",
        "])\n",
        "\n",
        "# Load the MNIST dataset with the transformation\n",
        "dataset = datasets.MNIST('../data', train=True, download=True, transform=transform)\n",
        "\n",
        "# Retrieve an image from the dataset\n",
        "image, label = dataset[4]  # Get the first image and its label\n",
        "\n",
        "# Convert the tensor to a numpy array and remove the batch dimension\n",
        "image = image * 0.3081 + 0.1307  # Reverse the normalization\n",
        "image = image.squeeze().numpy()\n",
        "\n",
        "# Display the image\n",
        "plt.imshow(image, cmap='gray')\n",
        "plt.title(f'Label: {label}')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "382Ifm9_bu-5",
        "outputId": "c548632b-9537-45b7-b54f-85600df0f184"
      },
      "id": "382Ifm9_bu-5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import random\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "# Custom transformation to add Gaussian noise\n",
        "class AddGaussianNoise:\n",
        "    def __init__(self, mean=0., std=0.1):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n",
        "\n",
        "# Custom transformation to drop pixel randomly\n",
        "class RandomPixelDrop:\n",
        "    def __init__(self, max_blobs=3, min_radius=2, max_radius=5, intensity=0.7):\n",
        "        self.max_blobs = max_blobs         # Maximum number of blobs to create\n",
        "        self.min_radius = min_radius       # Minimum radius of blobs\n",
        "        self.max_radius = max_radius       # Maximum radius of blobs\n",
        "        self.intensity = intensity         # Threshold for blob intensity\n",
        "        self.background_value = (0 - 0.1307) / 0.3081  # Normalized background value\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        # Create a copy to modify\n",
        "        modified = tensor.clone()\n",
        "\n",
        "        # Generate random blobs\n",
        "        for _ in range(random.randint(1, self.max_blobs)):\n",
        "            # Create random position within digit bounds\n",
        "            height, width = tensor.shape[1:]\n",
        "            cx = random.randint(0, width-1)\n",
        "            cy = random.randint(0, height-1)\n",
        "\n",
        "            # Create grid\n",
        "            x = torch.arange(width, dtype=torch.float32)\n",
        "            y = torch.arange(height, dtype=torch.float32)\n",
        "            grid_x, grid_y = torch.meshgrid(x, y, indexing='xy')\n",
        "\n",
        "            # Generate random radius\n",
        "            radius = random.randint(self.min_radius, self.max_radius)\n",
        "\n",
        "            # Create circular mask\n",
        "            mask = ((grid_x - cx)**2 + (grid_y - cy)**2) < radius**2\n",
        "            mask = mask.float().unsqueeze(0)\n",
        "\n",
        "            # Apply random intensity variation\n",
        "            mask *= random.uniform(0.8, 1.2)\n",
        "\n",
        "            # Threshold to create binary mask\n",
        "            blob_mask = (mask > self.intensity).float()\n",
        "\n",
        "            # Only apply to digit pixels\n",
        "            digit_area = (modified > -0.5).float()  # Wider threshold for digit region\n",
        "            combined_mask = (blob_mask * digit_area).bool()\n",
        "\n",
        "            # Apply to tensor\n",
        "            modified[combined_mask] = self.background_value\n",
        "\n",
        "        return modified\n",
        "\n",
        "    def __repr__(self):\n",
        "        return (f'{self.__class__.__name__}(max_blobs={self.max_blobs}, '\n",
        "                f'radius=({self.min_radius}-{self.max_radius}), '\n",
        "                f'intensity={self.intensity})')\n",
        "\n",
        "# Updated augmentation pipeline with pixel dropping\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,)),\n",
        "    transforms.RandomAffine(degrees=(-5,5), translate=(0.1, 0.1), scale=(0.6, 1.3), shear=10),\n",
        "    transforms.RandomApply([AddGaussianNoise(mean=0., std=0.1)], p=0.2),  # Add Gaussian noise\n",
        "    transforms.RandomApply([RandomPixelDrop(\n",
        "        max_blobs=2,\n",
        "        min_radius=1,\n",
        "        max_radius=2,\n",
        "        intensity=0.6\n",
        "    )], p=0.4)\n",
        "])\n",
        "\n",
        "# Load the MNIST dataset with the new transformation\n",
        "dataset = datasets.MNIST('../data', train=True, download=True, transform=transform)\n",
        "\n",
        "# Retrieve and display an image\n",
        "image, label = dataset[1]\n",
        "\n",
        "# Reverse normalization for display\n",
        "image = image * 0.3081 + 0.1307  # Revert normalization\n",
        "image = image.squeeze().numpy()\n",
        "\n",
        "plt.imshow(image, cmap='gray')\n",
        "plt.title(f'Label: {label}')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "W5wmN_EzOp5s",
        "outputId": "125cc9d8-5311-4600-d53e-17516695f1c4"
      },
      "id": "W5wmN_EzOp5s",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Model"
      ],
      "metadata": {
        "id": "IhVzQHC4cMhA"
      },
      "id": "IhVzQHC4cMhA"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import sys\n",
        "import time\n",
        "import random\n",
        "import argparse\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # Increased number of filters in convolutional layers\n",
        "        self.conv1 = nn.Conv2d(1, 64, 3, 1)  # Input channels: 1, Output channels: 64\n",
        "        self.conv2 = nn.Conv2d(64, 128, 3, 1)  # Output channels: 128\n",
        "        self.conv3 = nn.Conv2d(128, 256, 3, 1)  # Added a third convolutional layer\n",
        "        self.dropout1 = nn.Dropout(0.25)\n",
        "        self.dropout2 = nn.Dropout(0.4)\n",
        "        self.fc1 = nn.Linear(256 * 5 * 5, 512)  # Adjusted input size for the new conv layer\n",
        "        self.fc2 = nn.Linear(512, 256)  # Added an additional fully connected layer\n",
        "        self.fc3 = nn.Linear(256, 10)  # Output layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = self.conv3(x)  # Added the third convolutional layer\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = self.dropout1(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc2(x)  # Added the additional fully connected layer\n",
        "        x = F.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "        return output\n",
        "\n",
        "# Custom transformation to add Gaussian noise\n",
        "class AddGaussianNoise:\n",
        "    def __init__(self, mean=0., std=0.1):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n",
        "\n",
        "\n",
        "# Custom transformation\n",
        "class RandomPixelDrop:\n",
        "    def __init__(self, max_blobs=3, min_radius=2, max_radius=5, intensity=0.7):\n",
        "        self.max_blobs = max_blobs         # Maximum number of blobs to create\n",
        "        self.min_radius = min_radius       # Minimum radius of blobs\n",
        "        self.max_radius = max_radius       # Maximum radius of blobs\n",
        "        self.intensity = intensity         # Threshold for blob intensity\n",
        "        self.background_value = (0 - 0.1307) / 0.3081  # Normalized background value\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        # Create a copy to modify\n",
        "        modified = tensor.clone()\n",
        "\n",
        "        # Generate random blobs\n",
        "        for _ in range(random.randint(1, self.max_blobs)):\n",
        "            # Create random position within digit bounds\n",
        "            height, width = tensor.shape[1:]\n",
        "            cx = random.randint(0, width-1)\n",
        "            cy = random.randint(0, height-1)\n",
        "\n",
        "            # Create grid\n",
        "            x = torch.arange(width, dtype=torch.float32)\n",
        "            y = torch.arange(height, dtype=torch.float32)\n",
        "            grid_x, grid_y = torch.meshgrid(x, y, indexing='xy')\n",
        "\n",
        "            # Generate random radius\n",
        "            radius = random.randint(self.min_radius, self.max_radius)\n",
        "\n",
        "            # Create circular mask\n",
        "            mask = ((grid_x - cx)**2 + (grid_y - cy)**2) < radius**2\n",
        "            mask = mask.float().unsqueeze(0)\n",
        "\n",
        "            # Apply random intensity variation\n",
        "            mask *= random.uniform(0.8, 1.2)\n",
        "\n",
        "            # Threshold to create binary mask\n",
        "            blob_mask = (mask > self.intensity).float()\n",
        "\n",
        "            # Only apply to digit pixels\n",
        "            digit_area = (modified > -0.5).float()  # Wider threshold for digit region\n",
        "            combined_mask = (blob_mask * digit_area).bool()\n",
        "\n",
        "            # Apply to tensor\n",
        "            modified[combined_mask] = self.background_value\n",
        "\n",
        "        return modified\n",
        "\n",
        "    def __repr__(self):\n",
        "        return (f'{self.__class__.__name__}(max_blobs={self.max_blobs}, '\n",
        "                f'radius=({self.min_radius}-{self.max_radius}), '\n",
        "                f'intensity={self.intensity})')\n",
        "\n",
        "# Training Function\n",
        "def train(args, model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = torch.nn.functional.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        pred = output.argmax(dim=1, keepdim=True)\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "        if batch_idx % args.log_interval == 0:\n",
        "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} ({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
        "\n",
        "    train_loss /= len(train_loader)\n",
        "    accuracy = 100. * correct / len(train_loader.dataset)\n",
        "    return train_loss, accuracy\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += torch.nn.functional.nll_loss(output, target, reduction='sum').item()\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    accuracy = 100. * correct / len(test_loader.dataset)\n",
        "\n",
        "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({accuracy:.0f}%)\\n')\n",
        "\n",
        "    return test_loss, accuracy\n",
        "\n",
        "# Train and Evaluate\n",
        "def train_and_evaluate(args, model, device, train_loader, test_loader, optimizer, scheduler):\n",
        "    test_losses = []\n",
        "    test_accuracies = []\n",
        "    train_losses = []\n",
        "    train_accuracies = []\n",
        "\n",
        "    best_test_loss = float('inf')  # Initialize with a very high value\n",
        "    best_test_accuracy = float('inf')  # Initialize with a very high value\n",
        "\n",
        "    patience = 10  # Number of epochs to wait for improvement\n",
        "    no_improvement_count = 0  # Counter for epochs without improvement\n",
        "\n",
        "    # Create the \"MNIST_Model\" directory if it doesn't exist\n",
        "    model_dir = f\"MNIST_Model_seed_{args.seed}\"\n",
        "    if not os.path.exists(model_dir):\n",
        "        os.makedirs(model_dir)\n",
        "\n",
        "    for epoch in range(1, args.epochs + 1):\n",
        "        train_loss, train_accuracy = train(args, model, device, train_loader, optimizer, epoch)\n",
        "        test_loss, test_accuracy = test(model, device, test_loader)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        train_accuracies.append(train_accuracy)\n",
        "        test_losses.append(test_loss)\n",
        "        test_accuracies.append(test_accuracy)\n",
        "\n",
        "        # Check if the current test loss is the best so far\n",
        "        if test_loss < best_test_loss or test_accuracy > best_test_accuracy:\n",
        "            best_test_loss = test_loss\n",
        "            no_improvement_count = 0  # Reset the counter since we have improvement\n",
        "            if args.save_model and epoch > 4:\n",
        "                model_filename = f\"mnist_cnn_epoch:{epoch}_test-accuracy:{test_accuracy:.4f}_test-loss:{test_loss:.4f}.pt\"\n",
        "                model_path = os.path.join(model_dir, model_filename)  # Save model in the \"MNIST_Model\" directory\n",
        "                try:\n",
        "                    torch.save(model.state_dict(), model_path)\n",
        "                    print(f\"Model saved with new best test loss: {best_test_loss:.4f} \\n\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Error saving model: {e}\")\n",
        "        else:\n",
        "            no_improvement_count += 1  # Increment the counter since there's no improvement\n",
        "\n",
        "        # Early stopping check\n",
        "        if no_improvement_count >= patience:\n",
        "            print(f\"\\nEarly stopping triggered after {epoch} epochs. No improvement in test loss for {patience} consecutive epochs.\")\n",
        "            break\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    return train_losses, train_accuracies, test_losses, test_accuracies\n",
        "\n",
        "# Plot graphs\n",
        "def plot_results(train_losses, train_accuracies, test_losses, test_accuracies):\n",
        "    epochs = range(1, len(train_losses) + 1)\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    # Plot Train Loss\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, train_losses, 'o-', label='Train Loss')\n",
        "    plt.plot(epochs, test_losses, 'o-', label='Test Loss')\n",
        "    plt.title('Loss vs. Epoch')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot Accuracy\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, train_accuracies, 'o-', label='Train Accuracy')\n",
        "    plt.plot(epochs, test_accuracies, 'o-', label='Test Accuracy')\n",
        "    plt.title('Accuracy vs. Epoch')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy (%)')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    # Generate a random seed\n",
        "    random_seed = random.randint(0, 100000)\n",
        "    print(f\"Using random seed: {random_seed}\")\n",
        "\n",
        "    # Set the seed for reproducibility\n",
        "    torch.manual_seed(random_seed)\n",
        "    random.seed(random_seed)\n",
        "\n",
        "    # Running in a Jupyter notebook\n",
        "    args = argparse.Namespace(\n",
        "        batch_size=64,\n",
        "        test_batch_size=128,\n",
        "        epochs=500,\n",
        "        lr=1,\n",
        "        gamma=0.9, # Factor for adjusting the learning rate in the scheduler, reducing it over time.\n",
        "        no_cuda=False, # can use the GPU if available\n",
        "        no_mps=False, #  can use the MPS if available\n",
        "        dry_run=False, # If True, performs a quick single pass to test the setup.\n",
        "        seed=random_seed,\n",
        "        log_interval=10, # Determines how often to log training progress (e.g., every 10 batches).\n",
        "        save_model=True\n",
        "    )\n",
        "\n",
        "    # Device Setup\n",
        "    use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
        "    use_mps = not args.no_mps and torch.backends.mps.is_available()\n",
        "\n",
        "    torch.manual_seed(args.seed)\n",
        "\n",
        "    if use_cuda:\n",
        "        device = torch.device(\"cuda\")\n",
        "    elif use_mps:\n",
        "        device = torch.device(\"mps\")\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "\n",
        "    # Data Loading\n",
        "    train_kwargs = {'batch_size': args.batch_size}\n",
        "    test_kwargs = {'batch_size': args.test_batch_size}\n",
        "\n",
        "    if use_cuda:\n",
        "        cuda_kwargs = {'num_workers': 1,\n",
        "                       'pin_memory': True,\n",
        "                       'shuffle': True}\n",
        "        train_kwargs.update(cuda_kwargs)\n",
        "        test_kwargs.update(cuda_kwargs)\n",
        "\n",
        "    # Data Loading with Augmentation for Training\n",
        "    transform_train = transforms.Compose([\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize((0.1307,), (0.3081,)),\n",
        "      transforms.RandomAffine(degrees=(-5,5), translate=(0.1, 0.1), scale=(0.6, 1.3), shear=10),\n",
        "      transforms.RandomApply([AddGaussianNoise(mean=0., std=0.1)], p=0.2),  # Add Gaussian noise\n",
        "      transforms.RandomApply([RandomPixelDrop(\n",
        "          max_blobs=2,\n",
        "          min_radius=1,\n",
        "          max_radius=2,\n",
        "          intensity=0.6\n",
        "      )], p=0.4)\n",
        "  ])\n",
        "\n",
        "    # Transform for testing (no augmentation)\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])\n",
        "\n",
        "    # Dataset and DataLoader\n",
        "    dataset1 = datasets.MNIST('../data', train=True, download=True,\n",
        "                       transform=transform_train)\n",
        "    dataset2 = datasets.MNIST('../data', train=False,\n",
        "                       transform=transform_test)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs)\n",
        "    test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)\n",
        "\n",
        "    # Model and Optimizer Initialization\n",
        "    model = Net().to(device)\n",
        "    optimizer = optim.Adadelta(model.parameters(), lr=args.lr) # optimizer: Adadelta / SGD / Adam\n",
        "    scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)\n",
        "\n",
        "    # Train and Evaluate\n",
        "    train_losses, train_accuracies, test_losses, test_accuracies = train_and_evaluate(args, model, device, train_loader, test_loader, optimizer, scheduler)\n",
        "\n",
        "    # Plot Results\n",
        "    plot_results(train_losses, train_accuracies, test_losses, test_accuracies)\n",
        "\n",
        "    # Compress the folder into a zip file\n",
        "    shutil.make_archive(model_dir, 'zip', model_dir)  # Use the same folder name\n",
        "\n",
        "    # Download the zip file in Google Colab\n",
        "    files.download(f'{model_dir}.zip')  # Download the zip file with the correct name\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ggENXZXJcOH4",
        "outputId": "f5cf5582-917a-4854-d11c-2c7286319ce8"
      },
      "id": "ggENXZXJcOH4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using random seed: 16059\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:01<00:00, 5.07MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 65.2kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.27MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 5.26MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
            "\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.304725\n",
            "Train Epoch: 1 [640/60000 (1%)]\tLoss: 2.272077\n",
            "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 2.272708\n",
            "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 2.275848\n",
            "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 2.095652\n",
            "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 1.904788\n",
            "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 1.264906\n",
            "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 1.348885\n",
            "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 1.125845\n",
            "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 0.594338\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.898117\n",
            "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 0.680346\n",
            "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.562153\n",
            "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.607661\n",
            "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.400093\n",
            "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.376331\n",
            "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.549874\n",
            "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.331756\n",
            "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.444405\n",
            "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.198142\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.419892\n",
            "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.261304\n",
            "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.458289\n",
            "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.167502\n",
            "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.372271\n",
            "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.414157\n",
            "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.329764\n",
            "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.574875\n",
            "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.357500\n",
            "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.175776\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.270623\n",
            "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.356747\n",
            "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.257049\n",
            "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.181801\n",
            "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.314076\n",
            "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.406684\n",
            "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.267488\n",
            "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.256693\n",
            "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.251686\n",
            "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.364994\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.270677\n",
            "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.486105\n",
            "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.288162\n",
            "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.293105\n",
            "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.160800\n",
            "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.214687\n",
            "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.395597\n",
            "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.229064\n",
            "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.082547\n",
            "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.212165\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.401553\n",
            "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.232138\n",
            "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.190953\n",
            "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.105535\n",
            "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.157581\n",
            "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.226434\n",
            "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.190533\n",
            "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.155594\n",
            "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.099170\n",
            "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.247105\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.110358\n",
            "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.169774\n",
            "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.062670\n",
            "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.349459\n",
            "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.312551\n",
            "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.319365\n",
            "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.129384\n",
            "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.174244\n",
            "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.094631\n",
            "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.090996\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.179401\n",
            "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.142976\n",
            "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.174919\n",
            "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.094671\n",
            "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.061730\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.250504\n",
            "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.194637\n",
            "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.110690\n",
            "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.056855\n",
            "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.165573\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.063062\n",
            "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.064399\n",
            "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.078122\n",
            "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.100187\n",
            "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.231234\n",
            "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.079413\n",
            "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.157961\n",
            "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.154592\n",
            "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.137236\n",
            "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.207109\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.102108\n",
            "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.073574\n",
            "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.105932\n",
            "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.064572\n",
            "\n",
            "Test set: Average loss: 0.0449, Accuracy: 9858/10000 (99%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.094511\n",
            "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.109947\n",
            "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.141712\n",
            "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.028161\n",
            "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.105412\n",
            "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.074875\n",
            "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.102143\n",
            "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.160963\n",
            "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.025780\n",
            "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.550210\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.078946\n",
            "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.138870\n",
            "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.110921\n",
            "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.168815\n",
            "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.128207\n",
            "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.090250\n",
            "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.246962\n",
            "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.076707\n",
            "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.029229\n",
            "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.133126\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.093156\n",
            "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.040178\n",
            "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.195940\n",
            "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.098760\n",
            "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.161570\n",
            "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.182920\n",
            "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.057894\n",
            "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.074110\n",
            "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.100806\n",
            "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.166884\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.133903\n",
            "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.137930\n",
            "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.171848\n",
            "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.041821\n",
            "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.122802\n",
            "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.070279\n",
            "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.191144\n",
            "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.118098\n",
            "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.189696\n",
            "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.176071\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.398815\n",
            "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.020633\n",
            "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.102664\n",
            "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.196432\n",
            "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.094084\n",
            "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.144635\n",
            "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.260095\n",
            "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.180038\n",
            "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.062457\n",
            "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.171607\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.054365\n",
            "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.017791\n",
            "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.051089\n",
            "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.097034\n",
            "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.070798\n",
            "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.057274\n",
            "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.113552\n",
            "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.027110\n",
            "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.288378\n",
            "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.149466\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.087904\n",
            "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.184876\n",
            "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.112593\n",
            "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.018715\n",
            "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.193090\n",
            "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.025312\n",
            "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.184066\n",
            "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.042425\n",
            "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.447642\n",
            "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.349521\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.133755\n",
            "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.096362\n",
            "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.022798\n",
            "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.010378\n",
            "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.136319\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.055691\n",
            "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.052446\n",
            "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.138243\n",
            "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.235636\n",
            "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.100837\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.114473\n",
            "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.161047\n",
            "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.086421\n",
            "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.052665\n",
            "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.062308\n",
            "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.090281\n",
            "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.073692\n",
            "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.182965\n",
            "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.428222\n",
            "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.165008\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.155984\n",
            "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.105406\n",
            "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.008075\n",
            "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.067539\n",
            "\n",
            "Test set: Average loss: 0.0320, Accuracy: 9895/10000 (99%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.185921\n",
            "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.091067\n",
            "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.099848\n",
            "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.030415\n",
            "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.066472\n",
            "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.076339\n",
            "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.276797\n",
            "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.337726\n",
            "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.029328\n",
            "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.090761\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.030412\n",
            "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.102584\n",
            "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.073622\n",
            "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.010780\n",
            "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.060785\n",
            "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.028833\n",
            "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.016414\n",
            "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.057633\n",
            "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.028780\n",
            "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.162737\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.073964\n",
            "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.005037\n",
            "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.250797\n",
            "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.062204\n",
            "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.187134\n",
            "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.041350\n",
            "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.083404\n",
            "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.067754\n",
            "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.012373\n",
            "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.087904\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.025669\n",
            "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.006631\n",
            "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.110419\n",
            "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.022725\n",
            "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.043232\n",
            "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.100971\n",
            "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.213239\n",
            "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.083148\n",
            "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.115855\n",
            "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.061691\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.122080\n",
            "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.104181\n",
            "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.042010\n",
            "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.034318\n",
            "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.084438\n",
            "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.062911\n",
            "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.159089\n",
            "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.054424\n",
            "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.061797\n",
            "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.052051\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.089929\n",
            "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.045158\n",
            "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.147745\n",
            "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.104313\n",
            "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.091353\n",
            "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.231727\n",
            "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.071700\n",
            "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.017475\n",
            "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.015167\n",
            "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.024054\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.215153\n",
            "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.207302\n",
            "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.061146\n",
            "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.138388\n",
            "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.190982\n",
            "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.081237\n",
            "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.114994\n",
            "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.212755\n",
            "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.085809\n",
            "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.132600\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.071127\n",
            "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.107997\n",
            "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.119755\n",
            "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.185194\n",
            "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.101960\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.197825\n",
            "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.074414\n",
            "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.228298\n",
            "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.098382\n",
            "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.071832\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.271601\n",
            "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.129698\n",
            "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.080753\n",
            "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.384131\n",
            "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.087348\n",
            "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.024059\n",
            "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.018874\n",
            "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.206430\n",
            "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.236898\n",
            "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.030934\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.092288\n",
            "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.032255\n",
            "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.104667\n",
            "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.049486\n",
            "\n",
            "Test set: Average loss: 0.0224, Accuracy: 9926/10000 (99%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.051200\n",
            "Train Epoch: 4 [640/60000 (1%)]\tLoss: 0.050742\n",
            "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 0.015440\n",
            "Train Epoch: 4 [1920/60000 (3%)]\tLoss: 0.038656\n",
            "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 0.099717\n",
            "Train Epoch: 4 [3200/60000 (5%)]\tLoss: 0.021046\n",
            "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 0.024395\n",
            "Train Epoch: 4 [4480/60000 (7%)]\tLoss: 0.116004\n",
            "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 0.080246\n",
            "Train Epoch: 4 [5760/60000 (10%)]\tLoss: 0.061791\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.178542\n",
            "Train Epoch: 4 [7040/60000 (12%)]\tLoss: 0.044808\n",
            "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 0.179413\n",
            "Train Epoch: 4 [8320/60000 (14%)]\tLoss: 0.051280\n",
            "Train Epoch: 4 [8960/60000 (15%)]\tLoss: 0.104738\n",
            "Train Epoch: 4 [9600/60000 (16%)]\tLoss: 0.127180\n",
            "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 0.165390\n",
            "Train Epoch: 4 [10880/60000 (18%)]\tLoss: 0.117443\n",
            "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 0.056645\n",
            "Train Epoch: 4 [12160/60000 (20%)]\tLoss: 0.035772\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.056183\n",
            "Train Epoch: 4 [13440/60000 (22%)]\tLoss: 0.073268\n",
            "Train Epoch: 4 [14080/60000 (23%)]\tLoss: 0.169337\n",
            "Train Epoch: 4 [14720/60000 (25%)]\tLoss: 0.094541\n",
            "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 0.050348\n",
            "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.077659\n",
            "Train Epoch: 4 [16640/60000 (28%)]\tLoss: 0.040875\n",
            "Train Epoch: 4 [17280/60000 (29%)]\tLoss: 0.151113\n",
            "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 0.205602\n",
            "Train Epoch: 4 [18560/60000 (31%)]\tLoss: 0.050969\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.092805\n",
            "Train Epoch: 4 [19840/60000 (33%)]\tLoss: 0.226394\n",
            "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.114884\n",
            "Train Epoch: 4 [21120/60000 (35%)]\tLoss: 0.065066\n",
            "Train Epoch: 4 [21760/60000 (36%)]\tLoss: 0.252347\n",
            "Train Epoch: 4 [22400/60000 (37%)]\tLoss: 0.040736\n",
            "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 0.054681\n",
            "Train Epoch: 4 [23680/60000 (39%)]\tLoss: 0.102653\n",
            "Train Epoch: 4 [24320/60000 (41%)]\tLoss: 0.100405\n",
            "Train Epoch: 4 [24960/60000 (42%)]\tLoss: 0.053661\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.124704\n",
            "Train Epoch: 4 [26240/60000 (44%)]\tLoss: 0.028207\n",
            "Train Epoch: 4 [26880/60000 (45%)]\tLoss: 0.039833\n",
            "Train Epoch: 4 [27520/60000 (46%)]\tLoss: 0.057216\n",
            "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 0.017273\n",
            "Train Epoch: 4 [28800/60000 (48%)]\tLoss: 0.003260\n",
            "Train Epoch: 4 [29440/60000 (49%)]\tLoss: 0.007525\n",
            "Train Epoch: 4 [30080/60000 (50%)]\tLoss: 0.070919\n",
            "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 0.123243\n",
            "Train Epoch: 4 [31360/60000 (52%)]\tLoss: 0.125558\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.003546\n",
            "Train Epoch: 4 [32640/60000 (54%)]\tLoss: 0.083320\n",
            "Train Epoch: 4 [33280/60000 (55%)]\tLoss: 0.028077\n",
            "Train Epoch: 4 [33920/60000 (57%)]\tLoss: 0.031826\n",
            "Train Epoch: 4 [34560/60000 (58%)]\tLoss: 0.064954\n",
            "Train Epoch: 4 [35200/60000 (59%)]\tLoss: 0.024602\n",
            "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 0.026577\n",
            "Train Epoch: 4 [36480/60000 (61%)]\tLoss: 0.130311\n",
            "Train Epoch: 4 [37120/60000 (62%)]\tLoss: 0.056751\n",
            "Train Epoch: 4 [37760/60000 (63%)]\tLoss: 0.006259\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.012742\n",
            "Train Epoch: 4 [39040/60000 (65%)]\tLoss: 0.019380\n",
            "Train Epoch: 4 [39680/60000 (66%)]\tLoss: 0.049565\n",
            "Train Epoch: 4 [40320/60000 (67%)]\tLoss: 0.126966\n",
            "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.064081\n",
            "Train Epoch: 4 [41600/60000 (69%)]\tLoss: 0.027798\n",
            "Train Epoch: 4 [42240/60000 (70%)]\tLoss: 0.027099\n",
            "Train Epoch: 4 [42880/60000 (71%)]\tLoss: 0.017497\n",
            "Train Epoch: 4 [43520/60000 (72%)]\tLoss: 0.116962\n",
            "Train Epoch: 4 [44160/60000 (74%)]\tLoss: 0.378563\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.124284\n",
            "Train Epoch: 4 [45440/60000 (76%)]\tLoss: 0.086264\n",
            "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 0.125590\n",
            "Train Epoch: 4 [46720/60000 (78%)]\tLoss: 0.094508\n",
            "Train Epoch: 4 [47360/60000 (79%)]\tLoss: 0.173205\n",
            "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.215022\n",
            "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 0.005509\n",
            "Train Epoch: 4 [49280/60000 (82%)]\tLoss: 0.108242\n",
            "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 0.043973\n",
            "Train Epoch: 4 [50560/60000 (84%)]\tLoss: 0.102055\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.121703\n",
            "Train Epoch: 4 [51840/60000 (86%)]\tLoss: 0.029555\n",
            "Train Epoch: 4 [52480/60000 (87%)]\tLoss: 0.152077\n",
            "Train Epoch: 4 [53120/60000 (88%)]\tLoss: 0.078505\n",
            "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 0.113735\n",
            "Train Epoch: 4 [54400/60000 (91%)]\tLoss: 0.084084\n",
            "Train Epoch: 4 [55040/60000 (92%)]\tLoss: 0.000836\n",
            "Train Epoch: 4 [55680/60000 (93%)]\tLoss: 0.057416\n",
            "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 0.027969\n",
            "Train Epoch: 4 [56960/60000 (95%)]\tLoss: 0.072410\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.023472\n",
            "Train Epoch: 4 [58240/60000 (97%)]\tLoss: 0.086672\n",
            "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 0.118358\n",
            "Train Epoch: 4 [59520/60000 (99%)]\tLoss: 0.030954\n",
            "\n",
            "Test set: Average loss: 0.0206, Accuracy: 9931/10000 (99%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.052587\n",
            "Train Epoch: 5 [640/60000 (1%)]\tLoss: 0.021383\n",
            "Train Epoch: 5 [1280/60000 (2%)]\tLoss: 0.135067\n",
            "Train Epoch: 5 [1920/60000 (3%)]\tLoss: 0.140682\n",
            "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 0.002657\n",
            "Train Epoch: 5 [3200/60000 (5%)]\tLoss: 0.089760\n",
            "Train Epoch: 5 [3840/60000 (6%)]\tLoss: 0.210924\n",
            "Train Epoch: 5 [4480/60000 (7%)]\tLoss: 0.173844\n",
            "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 0.034229\n",
            "Train Epoch: 5 [5760/60000 (10%)]\tLoss: 0.047129\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.135197\n",
            "Train Epoch: 5 [7040/60000 (12%)]\tLoss: 0.154376\n",
            "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 0.021750\n",
            "Train Epoch: 5 [8320/60000 (14%)]\tLoss: 0.094885\n",
            "Train Epoch: 5 [8960/60000 (15%)]\tLoss: 0.157926\n",
            "Train Epoch: 5 [9600/60000 (16%)]\tLoss: 0.035768\n",
            "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 0.169174\n",
            "Train Epoch: 5 [10880/60000 (18%)]\tLoss: 0.138610\n",
            "Train Epoch: 5 [11520/60000 (19%)]\tLoss: 0.216985\n",
            "Train Epoch: 5 [12160/60000 (20%)]\tLoss: 0.096058\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.039302\n",
            "Train Epoch: 5 [13440/60000 (22%)]\tLoss: 0.164864\n",
            "Train Epoch: 5 [14080/60000 (23%)]\tLoss: 0.082447\n",
            "Train Epoch: 5 [14720/60000 (25%)]\tLoss: 0.156496\n",
            "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 0.004936\n",
            "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.011301\n",
            "Train Epoch: 5 [16640/60000 (28%)]\tLoss: 0.118755\n",
            "Train Epoch: 5 [17280/60000 (29%)]\tLoss: 0.050507\n",
            "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 0.062358\n",
            "Train Epoch: 5 [18560/60000 (31%)]\tLoss: 0.093553\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.019018\n",
            "Train Epoch: 5 [19840/60000 (33%)]\tLoss: 0.082072\n",
            "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.041695\n",
            "Train Epoch: 5 [21120/60000 (35%)]\tLoss: 0.055994\n",
            "Train Epoch: 5 [21760/60000 (36%)]\tLoss: 0.040878\n",
            "Train Epoch: 5 [22400/60000 (37%)]\tLoss: 0.109704\n",
            "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 0.068487\n",
            "Train Epoch: 5 [23680/60000 (39%)]\tLoss: 0.025430\n",
            "Train Epoch: 5 [24320/60000 (41%)]\tLoss: 0.045405\n",
            "Train Epoch: 5 [24960/60000 (42%)]\tLoss: 0.028323\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.020956\n",
            "Train Epoch: 5 [26240/60000 (44%)]\tLoss: 0.035596\n",
            "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 0.047647\n",
            "Train Epoch: 5 [27520/60000 (46%)]\tLoss: 0.172106\n",
            "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 0.231228\n",
            "Train Epoch: 5 [28800/60000 (48%)]\tLoss: 0.073374\n",
            "Train Epoch: 5 [29440/60000 (49%)]\tLoss: 0.019325\n",
            "Train Epoch: 5 [30080/60000 (50%)]\tLoss: 0.044760\n",
            "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.027930\n",
            "Train Epoch: 5 [31360/60000 (52%)]\tLoss: 0.212265\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.028246\n",
            "Train Epoch: 5 [32640/60000 (54%)]\tLoss: 0.022915\n",
            "Train Epoch: 5 [33280/60000 (55%)]\tLoss: 0.135126\n",
            "Train Epoch: 5 [33920/60000 (57%)]\tLoss: 0.159498\n",
            "Train Epoch: 5 [34560/60000 (58%)]\tLoss: 0.103269\n",
            "Train Epoch: 5 [35200/60000 (59%)]\tLoss: 0.075081\n",
            "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 0.054982\n",
            "Train Epoch: 5 [36480/60000 (61%)]\tLoss: 0.083692\n",
            "Train Epoch: 5 [37120/60000 (62%)]\tLoss: 0.012956\n",
            "Train Epoch: 5 [37760/60000 (63%)]\tLoss: 0.105445\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.003446\n",
            "Train Epoch: 5 [39040/60000 (65%)]\tLoss: 0.006886\n",
            "Train Epoch: 5 [39680/60000 (66%)]\tLoss: 0.117613\n",
            "Train Epoch: 5 [40320/60000 (67%)]\tLoss: 0.019994\n",
            "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.017105\n",
            "Train Epoch: 5 [41600/60000 (69%)]\tLoss: 0.073740\n",
            "Train Epoch: 5 [42240/60000 (70%)]\tLoss: 0.089510\n",
            "Train Epoch: 5 [42880/60000 (71%)]\tLoss: 0.035941\n",
            "Train Epoch: 5 [43520/60000 (72%)]\tLoss: 0.039954\n",
            "Train Epoch: 5 [44160/60000 (74%)]\tLoss: 0.017520\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.028410\n",
            "Train Epoch: 5 [45440/60000 (76%)]\tLoss: 0.034308\n",
            "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 0.023565\n",
            "Train Epoch: 5 [46720/60000 (78%)]\tLoss: 0.108615\n",
            "Train Epoch: 5 [47360/60000 (79%)]\tLoss: 0.024755\n",
            "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.018421\n",
            "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 0.086103\n",
            "Train Epoch: 5 [49280/60000 (82%)]\tLoss: 0.029121\n",
            "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 0.001716\n",
            "Train Epoch: 5 [50560/60000 (84%)]\tLoss: 0.129542\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.060491\n",
            "Train Epoch: 5 [51840/60000 (86%)]\tLoss: 0.089762\n",
            "Train Epoch: 5 [52480/60000 (87%)]\tLoss: 0.117644\n",
            "Train Epoch: 5 [53120/60000 (88%)]\tLoss: 0.021057\n",
            "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 0.062083\n",
            "Train Epoch: 5 [54400/60000 (91%)]\tLoss: 0.004811\n",
            "Train Epoch: 5 [55040/60000 (92%)]\tLoss: 0.015373\n",
            "Train Epoch: 5 [55680/60000 (93%)]\tLoss: 0.087086\n",
            "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 0.101525\n",
            "Train Epoch: 5 [56960/60000 (95%)]\tLoss: 0.027559\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.016705\n",
            "Train Epoch: 5 [58240/60000 (97%)]\tLoss: 0.105434\n",
            "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 0.042057\n",
            "Train Epoch: 5 [59520/60000 (99%)]\tLoss: 0.016479\n",
            "\n",
            "Test set: Average loss: 0.0178, Accuracy: 9943/10000 (99%)\n",
            "\n",
            "Model saved with new best test loss: 0.0178 \n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.016642\n",
            "Train Epoch: 6 [640/60000 (1%)]\tLoss: 0.022896\n",
            "Train Epoch: 6 [1280/60000 (2%)]\tLoss: 0.008188\n",
            "Train Epoch: 6 [1920/60000 (3%)]\tLoss: 0.005849\n",
            "Train Epoch: 6 [2560/60000 (4%)]\tLoss: 0.015249\n",
            "Train Epoch: 6 [3200/60000 (5%)]\tLoss: 0.047278\n",
            "Train Epoch: 6 [3840/60000 (6%)]\tLoss: 0.148227\n",
            "Train Epoch: 6 [4480/60000 (7%)]\tLoss: 0.246412\n",
            "Train Epoch: 6 [5120/60000 (9%)]\tLoss: 0.085799\n",
            "Train Epoch: 6 [5760/60000 (10%)]\tLoss: 0.022560\n",
            "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.011566\n",
            "Train Epoch: 6 [7040/60000 (12%)]\tLoss: 0.040875\n",
            "Train Epoch: 6 [7680/60000 (13%)]\tLoss: 0.073862\n",
            "Train Epoch: 6 [8320/60000 (14%)]\tLoss: 0.077117\n",
            "Train Epoch: 6 [8960/60000 (15%)]\tLoss: 0.233794\n",
            "Train Epoch: 6 [9600/60000 (16%)]\tLoss: 0.035044\n",
            "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 0.096327\n",
            "Train Epoch: 6 [10880/60000 (18%)]\tLoss: 0.016941\n",
            "Train Epoch: 6 [11520/60000 (19%)]\tLoss: 0.005709\n",
            "Train Epoch: 6 [12160/60000 (20%)]\tLoss: 0.047638\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.003869\n",
            "Train Epoch: 6 [13440/60000 (22%)]\tLoss: 0.125014\n",
            "Train Epoch: 6 [14080/60000 (23%)]\tLoss: 0.016574\n",
            "Train Epoch: 6 [14720/60000 (25%)]\tLoss: 0.123579\n",
            "Train Epoch: 6 [15360/60000 (26%)]\tLoss: 0.067810\n",
            "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.205965\n",
            "Train Epoch: 6 [16640/60000 (28%)]\tLoss: 0.092415\n",
            "Train Epoch: 6 [17280/60000 (29%)]\tLoss: 0.056425\n",
            "Train Epoch: 6 [17920/60000 (30%)]\tLoss: 0.041750\n",
            "Train Epoch: 6 [18560/60000 (31%)]\tLoss: 0.124234\n",
            "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.058681\n",
            "Train Epoch: 6 [19840/60000 (33%)]\tLoss: 0.096166\n",
            "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 0.162814\n",
            "Train Epoch: 6 [21120/60000 (35%)]\tLoss: 0.115853\n",
            "Train Epoch: 6 [21760/60000 (36%)]\tLoss: 0.085497\n",
            "Train Epoch: 6 [22400/60000 (37%)]\tLoss: 0.098323\n",
            "Train Epoch: 6 [23040/60000 (38%)]\tLoss: 0.043403\n",
            "Train Epoch: 6 [23680/60000 (39%)]\tLoss: 0.047989\n",
            "Train Epoch: 6 [24320/60000 (41%)]\tLoss: 0.141837\n",
            "Train Epoch: 6 [24960/60000 (42%)]\tLoss: 0.021497\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.117481\n",
            "Train Epoch: 6 [26240/60000 (44%)]\tLoss: 0.004311\n",
            "Train Epoch: 6 [26880/60000 (45%)]\tLoss: 0.022498\n",
            "Train Epoch: 6 [27520/60000 (46%)]\tLoss: 0.064520\n",
            "Train Epoch: 6 [28160/60000 (47%)]\tLoss: 0.032066\n",
            "Train Epoch: 6 [28800/60000 (48%)]\tLoss: 0.249954\n",
            "Train Epoch: 6 [29440/60000 (49%)]\tLoss: 0.022997\n",
            "Train Epoch: 6 [30080/60000 (50%)]\tLoss: 0.157543\n",
            "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 0.015588\n",
            "Train Epoch: 6 [31360/60000 (52%)]\tLoss: 0.080415\n",
            "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.013954\n",
            "Train Epoch: 6 [32640/60000 (54%)]\tLoss: 0.037525\n",
            "Train Epoch: 6 [33280/60000 (55%)]\tLoss: 0.116515\n",
            "Train Epoch: 6 [33920/60000 (57%)]\tLoss: 0.147917\n",
            "Train Epoch: 6 [34560/60000 (58%)]\tLoss: 0.099350\n",
            "Train Epoch: 6 [35200/60000 (59%)]\tLoss: 0.012437\n",
            "Train Epoch: 6 [35840/60000 (60%)]\tLoss: 0.063720\n",
            "Train Epoch: 6 [36480/60000 (61%)]\tLoss: 0.053336\n",
            "Train Epoch: 6 [37120/60000 (62%)]\tLoss: 0.021849\n",
            "Train Epoch: 6 [37760/60000 (63%)]\tLoss: 0.146225\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.095997\n",
            "Train Epoch: 6 [39040/60000 (65%)]\tLoss: 0.029226\n",
            "Train Epoch: 6 [39680/60000 (66%)]\tLoss: 0.102557\n",
            "Train Epoch: 6 [40320/60000 (67%)]\tLoss: 0.011448\n",
            "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 0.096052\n",
            "Train Epoch: 6 [41600/60000 (69%)]\tLoss: 0.056123\n",
            "Train Epoch: 6 [42240/60000 (70%)]\tLoss: 0.051047\n",
            "Train Epoch: 6 [42880/60000 (71%)]\tLoss: 0.027959\n",
            "Train Epoch: 6 [43520/60000 (72%)]\tLoss: 0.001281\n",
            "Train Epoch: 6 [44160/60000 (74%)]\tLoss: 0.065024\n",
            "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.057644\n",
            "Train Epoch: 6 [45440/60000 (76%)]\tLoss: 0.007486\n",
            "Train Epoch: 6 [46080/60000 (77%)]\tLoss: 0.013740\n",
            "Train Epoch: 6 [46720/60000 (78%)]\tLoss: 0.129228\n",
            "Train Epoch: 6 [47360/60000 (79%)]\tLoss: 0.096046\n",
            "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.003415\n",
            "Train Epoch: 6 [48640/60000 (81%)]\tLoss: 0.023645\n",
            "Train Epoch: 6 [49280/60000 (82%)]\tLoss: 0.016321\n",
            "Train Epoch: 6 [49920/60000 (83%)]\tLoss: 0.087406\n",
            "Train Epoch: 6 [50560/60000 (84%)]\tLoss: 0.044940\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.134287\n",
            "Train Epoch: 6 [51840/60000 (86%)]\tLoss: 0.086662\n",
            "Train Epoch: 6 [52480/60000 (87%)]\tLoss: 0.145020\n",
            "Train Epoch: 6 [53120/60000 (88%)]\tLoss: 0.049692\n",
            "Train Epoch: 6 [53760/60000 (90%)]\tLoss: 0.039879\n",
            "Train Epoch: 6 [54400/60000 (91%)]\tLoss: 0.113816\n",
            "Train Epoch: 6 [55040/60000 (92%)]\tLoss: 0.070765\n",
            "Train Epoch: 6 [55680/60000 (93%)]\tLoss: 0.141779\n",
            "Train Epoch: 6 [56320/60000 (94%)]\tLoss: 0.013542\n",
            "Train Epoch: 6 [56960/60000 (95%)]\tLoss: 0.051719\n",
            "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.055783\n",
            "Train Epoch: 6 [58240/60000 (97%)]\tLoss: 0.020806\n",
            "Train Epoch: 6 [58880/60000 (98%)]\tLoss: 0.021535\n",
            "Train Epoch: 6 [59520/60000 (99%)]\tLoss: 0.092204\n",
            "\n",
            "Test set: Average loss: 0.0156, Accuracy: 9947/10000 (99%)\n",
            "\n",
            "Model saved with new best test loss: 0.0156 \n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.031919\n",
            "Train Epoch: 7 [640/60000 (1%)]\tLoss: 0.075958\n",
            "Train Epoch: 7 [1280/60000 (2%)]\tLoss: 0.099955\n",
            "Train Epoch: 7 [1920/60000 (3%)]\tLoss: 0.023871\n",
            "Train Epoch: 7 [2560/60000 (4%)]\tLoss: 0.087157\n",
            "Train Epoch: 7 [3200/60000 (5%)]\tLoss: 0.008527\n",
            "Train Epoch: 7 [3840/60000 (6%)]\tLoss: 0.216075\n",
            "Train Epoch: 7 [4480/60000 (7%)]\tLoss: 0.186595\n",
            "Train Epoch: 7 [5120/60000 (9%)]\tLoss: 0.250822\n",
            "Train Epoch: 7 [5760/60000 (10%)]\tLoss: 0.018023\n",
            "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.007697\n",
            "Train Epoch: 7 [7040/60000 (12%)]\tLoss: 0.271783\n",
            "Train Epoch: 7 [7680/60000 (13%)]\tLoss: 0.006485\n",
            "Train Epoch: 7 [8320/60000 (14%)]\tLoss: 0.044946\n",
            "Train Epoch: 7 [8960/60000 (15%)]\tLoss: 0.012367\n",
            "Train Epoch: 7 [9600/60000 (16%)]\tLoss: 0.071029\n",
            "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 0.065862\n",
            "Train Epoch: 7 [10880/60000 (18%)]\tLoss: 0.133722\n",
            "Train Epoch: 7 [11520/60000 (19%)]\tLoss: 0.021848\n",
            "Train Epoch: 7 [12160/60000 (20%)]\tLoss: 0.017060\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.014932\n",
            "Train Epoch: 7 [13440/60000 (22%)]\tLoss: 0.029732\n",
            "Train Epoch: 7 [14080/60000 (23%)]\tLoss: 0.002450\n",
            "Train Epoch: 7 [14720/60000 (25%)]\tLoss: 0.037520\n",
            "Train Epoch: 7 [15360/60000 (26%)]\tLoss: 0.006917\n",
            "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.029632\n",
            "Train Epoch: 7 [16640/60000 (28%)]\tLoss: 0.037089\n",
            "Train Epoch: 7 [17280/60000 (29%)]\tLoss: 0.003043\n",
            "Train Epoch: 7 [17920/60000 (30%)]\tLoss: 0.115775\n",
            "Train Epoch: 7 [18560/60000 (31%)]\tLoss: 0.284907\n",
            "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.018000\n",
            "Train Epoch: 7 [19840/60000 (33%)]\tLoss: 0.025455\n",
            "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 0.042833\n",
            "Train Epoch: 7 [21120/60000 (35%)]\tLoss: 0.008159\n",
            "Train Epoch: 7 [21760/60000 (36%)]\tLoss: 0.013190\n",
            "Train Epoch: 7 [22400/60000 (37%)]\tLoss: 0.025970\n",
            "Train Epoch: 7 [23040/60000 (38%)]\tLoss: 0.114739\n",
            "Train Epoch: 7 [23680/60000 (39%)]\tLoss: 0.020783\n",
            "Train Epoch: 7 [24320/60000 (41%)]\tLoss: 0.023866\n",
            "Train Epoch: 7 [24960/60000 (42%)]\tLoss: 0.008394\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.022729\n",
            "Train Epoch: 7 [26240/60000 (44%)]\tLoss: 0.052682\n",
            "Train Epoch: 7 [26880/60000 (45%)]\tLoss: 0.082316\n",
            "Train Epoch: 7 [27520/60000 (46%)]\tLoss: 0.033872\n",
            "Train Epoch: 7 [28160/60000 (47%)]\tLoss: 0.144407\n",
            "Train Epoch: 7 [28800/60000 (48%)]\tLoss: 0.002471\n",
            "Train Epoch: 7 [29440/60000 (49%)]\tLoss: 0.057904\n",
            "Train Epoch: 7 [30080/60000 (50%)]\tLoss: 0.010289\n",
            "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 0.160677\n",
            "Train Epoch: 7 [31360/60000 (52%)]\tLoss: 0.007153\n",
            "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.039267\n",
            "Train Epoch: 7 [32640/60000 (54%)]\tLoss: 0.062052\n",
            "Train Epoch: 7 [33280/60000 (55%)]\tLoss: 0.123218\n",
            "Train Epoch: 7 [33920/60000 (57%)]\tLoss: 0.077793\n",
            "Train Epoch: 7 [34560/60000 (58%)]\tLoss: 0.004124\n",
            "Train Epoch: 7 [35200/60000 (59%)]\tLoss: 0.049451\n",
            "Train Epoch: 7 [35840/60000 (60%)]\tLoss: 0.034902\n",
            "Train Epoch: 7 [36480/60000 (61%)]\tLoss: 0.300072\n",
            "Train Epoch: 7 [37120/60000 (62%)]\tLoss: 0.050837\n",
            "Train Epoch: 7 [37760/60000 (63%)]\tLoss: 0.095839\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.068723\n",
            "Train Epoch: 7 [39040/60000 (65%)]\tLoss: 0.066244\n",
            "Train Epoch: 7 [39680/60000 (66%)]\tLoss: 0.020426\n",
            "Train Epoch: 7 [40320/60000 (67%)]\tLoss: 0.004215\n",
            "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 0.016008\n",
            "Train Epoch: 7 [41600/60000 (69%)]\tLoss: 0.007401\n",
            "Train Epoch: 7 [42240/60000 (70%)]\tLoss: 0.118398\n",
            "Train Epoch: 7 [42880/60000 (71%)]\tLoss: 0.190058\n",
            "Train Epoch: 7 [43520/60000 (72%)]\tLoss: 0.034499\n",
            "Train Epoch: 7 [44160/60000 (74%)]\tLoss: 0.049911\n",
            "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.050042\n",
            "Train Epoch: 7 [45440/60000 (76%)]\tLoss: 0.011745\n",
            "Train Epoch: 7 [46080/60000 (77%)]\tLoss: 0.092066\n",
            "Train Epoch: 7 [46720/60000 (78%)]\tLoss: 0.027931\n",
            "Train Epoch: 7 [47360/60000 (79%)]\tLoss: 0.001756\n",
            "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.008772\n",
            "Train Epoch: 7 [48640/60000 (81%)]\tLoss: 0.019272\n",
            "Train Epoch: 7 [49280/60000 (82%)]\tLoss: 0.042892\n",
            "Train Epoch: 7 [49920/60000 (83%)]\tLoss: 0.000677\n",
            "Train Epoch: 7 [50560/60000 (84%)]\tLoss: 0.005759\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.225886\n",
            "Train Epoch: 7 [51840/60000 (86%)]\tLoss: 0.040503\n",
            "Train Epoch: 7 [52480/60000 (87%)]\tLoss: 0.181287\n",
            "Train Epoch: 7 [53120/60000 (88%)]\tLoss: 0.032174\n",
            "Train Epoch: 7 [53760/60000 (90%)]\tLoss: 0.004050\n",
            "Train Epoch: 7 [54400/60000 (91%)]\tLoss: 0.021547\n",
            "Train Epoch: 7 [55040/60000 (92%)]\tLoss: 0.006847\n",
            "Train Epoch: 7 [55680/60000 (93%)]\tLoss: 0.060531\n",
            "Train Epoch: 7 [56320/60000 (94%)]\tLoss: 0.005960\n",
            "Train Epoch: 7 [56960/60000 (95%)]\tLoss: 0.164532\n",
            "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.044834\n",
            "Train Epoch: 7 [58240/60000 (97%)]\tLoss: 0.308575\n",
            "Train Epoch: 7 [58880/60000 (98%)]\tLoss: 0.015514\n",
            "Train Epoch: 7 [59520/60000 (99%)]\tLoss: 0.030485\n",
            "\n",
            "Test set: Average loss: 0.0157, Accuracy: 9952/10000 (100%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.000753\n",
            "Train Epoch: 8 [640/60000 (1%)]\tLoss: 0.146509\n",
            "Train Epoch: 8 [1280/60000 (2%)]\tLoss: 0.066089\n",
            "Train Epoch: 8 [1920/60000 (3%)]\tLoss: 0.011348\n",
            "Train Epoch: 8 [2560/60000 (4%)]\tLoss: 0.073438\n",
            "Train Epoch: 8 [3200/60000 (5%)]\tLoss: 0.050551\n",
            "Train Epoch: 8 [3840/60000 (6%)]\tLoss: 0.144782\n",
            "Train Epoch: 8 [4480/60000 (7%)]\tLoss: 0.011119\n",
            "Train Epoch: 8 [5120/60000 (9%)]\tLoss: 0.040417\n",
            "Train Epoch: 8 [5760/60000 (10%)]\tLoss: 0.010914\n",
            "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.035779\n",
            "Train Epoch: 8 [7040/60000 (12%)]\tLoss: 0.014776\n",
            "Train Epoch: 8 [7680/60000 (13%)]\tLoss: 0.070673\n",
            "Train Epoch: 8 [8320/60000 (14%)]\tLoss: 0.040311\n",
            "Train Epoch: 8 [8960/60000 (15%)]\tLoss: 0.091551\n",
            "Train Epoch: 8 [9600/60000 (16%)]\tLoss: 0.054859\n",
            "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 0.041096\n",
            "Train Epoch: 8 [10880/60000 (18%)]\tLoss: 0.012211\n",
            "Train Epoch: 8 [11520/60000 (19%)]\tLoss: 0.000978\n",
            "Train Epoch: 8 [12160/60000 (20%)]\tLoss: 0.019369\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.003230\n",
            "Train Epoch: 8 [13440/60000 (22%)]\tLoss: 0.051235\n",
            "Train Epoch: 8 [14080/60000 (23%)]\tLoss: 0.031747\n",
            "Train Epoch: 8 [14720/60000 (25%)]\tLoss: 0.010036\n",
            "Train Epoch: 8 [15360/60000 (26%)]\tLoss: 0.086951\n",
            "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.076005\n",
            "Train Epoch: 8 [16640/60000 (28%)]\tLoss: 0.004667\n",
            "Train Epoch: 8 [17280/60000 (29%)]\tLoss: 0.027655\n",
            "Train Epoch: 8 [17920/60000 (30%)]\tLoss: 0.009228\n",
            "Train Epoch: 8 [18560/60000 (31%)]\tLoss: 0.065092\n",
            "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.016950\n",
            "Train Epoch: 8 [19840/60000 (33%)]\tLoss: 0.025301\n",
            "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 0.023053\n",
            "Train Epoch: 8 [21120/60000 (35%)]\tLoss: 0.112634\n",
            "Train Epoch: 8 [21760/60000 (36%)]\tLoss: 0.152891\n",
            "Train Epoch: 8 [22400/60000 (37%)]\tLoss: 0.056410\n",
            "Train Epoch: 8 [23040/60000 (38%)]\tLoss: 0.060097\n",
            "Train Epoch: 8 [23680/60000 (39%)]\tLoss: 0.054839\n",
            "Train Epoch: 8 [24320/60000 (41%)]\tLoss: 0.040244\n",
            "Train Epoch: 8 [24960/60000 (42%)]\tLoss: 0.027019\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.199240\n",
            "Train Epoch: 8 [26240/60000 (44%)]\tLoss: 0.039936\n",
            "Train Epoch: 8 [26880/60000 (45%)]\tLoss: 0.064533\n",
            "Train Epoch: 8 [27520/60000 (46%)]\tLoss: 0.060477\n",
            "Train Epoch: 8 [28160/60000 (47%)]\tLoss: 0.006645\n",
            "Train Epoch: 8 [28800/60000 (48%)]\tLoss: 0.029637\n",
            "Train Epoch: 8 [29440/60000 (49%)]\tLoss: 0.014944\n",
            "Train Epoch: 8 [30080/60000 (50%)]\tLoss: 0.015457\n",
            "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 0.033399\n",
            "Train Epoch: 8 [31360/60000 (52%)]\tLoss: 0.072427\n",
            "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.005339\n",
            "Train Epoch: 8 [32640/60000 (54%)]\tLoss: 0.003247\n",
            "Train Epoch: 8 [33280/60000 (55%)]\tLoss: 0.020803\n",
            "Train Epoch: 8 [33920/60000 (57%)]\tLoss: 0.153319\n",
            "Train Epoch: 8 [34560/60000 (58%)]\tLoss: 0.128417\n",
            "Train Epoch: 8 [35200/60000 (59%)]\tLoss: 0.008031\n",
            "Train Epoch: 8 [35840/60000 (60%)]\tLoss: 0.000575\n",
            "Train Epoch: 8 [36480/60000 (61%)]\tLoss: 0.039344\n",
            "Train Epoch: 8 [37120/60000 (62%)]\tLoss: 0.153700\n",
            "Train Epoch: 8 [37760/60000 (63%)]\tLoss: 0.101461\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.001824\n",
            "Train Epoch: 8 [39040/60000 (65%)]\tLoss: 0.053803\n",
            "Train Epoch: 8 [39680/60000 (66%)]\tLoss: 0.006910\n",
            "Train Epoch: 8 [40320/60000 (67%)]\tLoss: 0.148464\n",
            "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 0.114749\n",
            "Train Epoch: 8 [41600/60000 (69%)]\tLoss: 0.045128\n",
            "Train Epoch: 8 [42240/60000 (70%)]\tLoss: 0.051574\n",
            "Train Epoch: 8 [42880/60000 (71%)]\tLoss: 0.105817\n",
            "Train Epoch: 8 [43520/60000 (72%)]\tLoss: 0.001696\n",
            "Train Epoch: 8 [44160/60000 (74%)]\tLoss: 0.012855\n",
            "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.059807\n",
            "Train Epoch: 8 [45440/60000 (76%)]\tLoss: 0.034560\n",
            "Train Epoch: 8 [46080/60000 (77%)]\tLoss: 0.035308\n",
            "Train Epoch: 8 [46720/60000 (78%)]\tLoss: 0.003455\n",
            "Train Epoch: 8 [47360/60000 (79%)]\tLoss: 0.006557\n",
            "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.001760\n",
            "Train Epoch: 8 [48640/60000 (81%)]\tLoss: 0.158204\n",
            "Train Epoch: 8 [49280/60000 (82%)]\tLoss: 0.016323\n",
            "Train Epoch: 8 [49920/60000 (83%)]\tLoss: 0.003856\n",
            "Train Epoch: 8 [50560/60000 (84%)]\tLoss: 0.024979\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.008022\n",
            "Train Epoch: 8 [51840/60000 (86%)]\tLoss: 0.115075\n",
            "Train Epoch: 8 [52480/60000 (87%)]\tLoss: 0.005553\n",
            "Train Epoch: 8 [53120/60000 (88%)]\tLoss: 0.003855\n",
            "Train Epoch: 8 [53760/60000 (90%)]\tLoss: 0.102569\n",
            "Train Epoch: 8 [54400/60000 (91%)]\tLoss: 0.016569\n",
            "Train Epoch: 8 [55040/60000 (92%)]\tLoss: 0.090652\n",
            "Train Epoch: 8 [55680/60000 (93%)]\tLoss: 0.016261\n",
            "Train Epoch: 8 [56320/60000 (94%)]\tLoss: 0.004045\n",
            "Train Epoch: 8 [56960/60000 (95%)]\tLoss: 0.163668\n",
            "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.056596\n",
            "Train Epoch: 8 [58240/60000 (97%)]\tLoss: 0.035840\n",
            "Train Epoch: 8 [58880/60000 (98%)]\tLoss: 0.048926\n",
            "Train Epoch: 8 [59520/60000 (99%)]\tLoss: 0.015275\n",
            "\n",
            "Test set: Average loss: 0.0167, Accuracy: 9950/10000 (100%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.213147\n",
            "Train Epoch: 9 [640/60000 (1%)]\tLoss: 0.120441\n",
            "Train Epoch: 9 [1280/60000 (2%)]\tLoss: 0.046458\n",
            "Train Epoch: 9 [1920/60000 (3%)]\tLoss: 0.011556\n",
            "Train Epoch: 9 [2560/60000 (4%)]\tLoss: 0.001224\n",
            "Train Epoch: 9 [3200/60000 (5%)]\tLoss: 0.074836\n",
            "Train Epoch: 9 [3840/60000 (6%)]\tLoss: 0.020046\n",
            "Train Epoch: 9 [4480/60000 (7%)]\tLoss: 0.009828\n",
            "Train Epoch: 9 [5120/60000 (9%)]\tLoss: 0.114737\n",
            "Train Epoch: 9 [5760/60000 (10%)]\tLoss: 0.006660\n",
            "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.019660\n",
            "Train Epoch: 9 [7040/60000 (12%)]\tLoss: 0.032585\n",
            "Train Epoch: 9 [7680/60000 (13%)]\tLoss: 0.069206\n",
            "Train Epoch: 9 [8320/60000 (14%)]\tLoss: 0.046251\n",
            "Train Epoch: 9 [8960/60000 (15%)]\tLoss: 0.003025\n",
            "Train Epoch: 9 [9600/60000 (16%)]\tLoss: 0.092978\n",
            "Train Epoch: 9 [10240/60000 (17%)]\tLoss: 0.003615\n",
            "Train Epoch: 9 [10880/60000 (18%)]\tLoss: 0.051098\n",
            "Train Epoch: 9 [11520/60000 (19%)]\tLoss: 0.025646\n",
            "Train Epoch: 9 [12160/60000 (20%)]\tLoss: 0.022400\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.009172\n",
            "Train Epoch: 9 [13440/60000 (22%)]\tLoss: 0.059801\n",
            "Train Epoch: 9 [14080/60000 (23%)]\tLoss: 0.096493\n",
            "Train Epoch: 9 [14720/60000 (25%)]\tLoss: 0.053852\n",
            "Train Epoch: 9 [15360/60000 (26%)]\tLoss: 0.019944\n",
            "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 0.009034\n",
            "Train Epoch: 9 [16640/60000 (28%)]\tLoss: 0.004955\n",
            "Train Epoch: 9 [17280/60000 (29%)]\tLoss: 0.191335\n",
            "Train Epoch: 9 [17920/60000 (30%)]\tLoss: 0.035318\n",
            "Train Epoch: 9 [18560/60000 (31%)]\tLoss: 0.088728\n",
            "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.007946\n",
            "Train Epoch: 9 [19840/60000 (33%)]\tLoss: 0.068031\n",
            "Train Epoch: 9 [20480/60000 (34%)]\tLoss: 0.049580\n",
            "Train Epoch: 9 [21120/60000 (35%)]\tLoss: 0.027560\n",
            "Train Epoch: 9 [21760/60000 (36%)]\tLoss: 0.003869\n",
            "Train Epoch: 9 [22400/60000 (37%)]\tLoss: 0.024666\n",
            "Train Epoch: 9 [23040/60000 (38%)]\tLoss: 0.014196\n",
            "Train Epoch: 9 [23680/60000 (39%)]\tLoss: 0.026725\n",
            "Train Epoch: 9 [24320/60000 (41%)]\tLoss: 0.057883\n",
            "Train Epoch: 9 [24960/60000 (42%)]\tLoss: 0.063768\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.070830\n",
            "Train Epoch: 9 [26240/60000 (44%)]\tLoss: 0.013381\n",
            "Train Epoch: 9 [26880/60000 (45%)]\tLoss: 0.071115\n",
            "Train Epoch: 9 [27520/60000 (46%)]\tLoss: 0.007191\n",
            "Train Epoch: 9 [28160/60000 (47%)]\tLoss: 0.016663\n",
            "Train Epoch: 9 [28800/60000 (48%)]\tLoss: 0.048096\n",
            "Train Epoch: 9 [29440/60000 (49%)]\tLoss: 0.059590\n",
            "Train Epoch: 9 [30080/60000 (50%)]\tLoss: 0.021949\n",
            "Train Epoch: 9 [30720/60000 (51%)]\tLoss: 0.076317\n",
            "Train Epoch: 9 [31360/60000 (52%)]\tLoss: 0.026791\n",
            "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.027982\n",
            "Train Epoch: 9 [32640/60000 (54%)]\tLoss: 0.074335\n",
            "Train Epoch: 9 [33280/60000 (55%)]\tLoss: 0.004062\n",
            "Train Epoch: 9 [33920/60000 (57%)]\tLoss: 0.005803\n",
            "Train Epoch: 9 [34560/60000 (58%)]\tLoss: 0.003619\n",
            "Train Epoch: 9 [35200/60000 (59%)]\tLoss: 0.113227\n",
            "Train Epoch: 9 [35840/60000 (60%)]\tLoss: 0.161453\n",
            "Train Epoch: 9 [36480/60000 (61%)]\tLoss: 0.015071\n",
            "Train Epoch: 9 [37120/60000 (62%)]\tLoss: 0.018122\n",
            "Train Epoch: 9 [37760/60000 (63%)]\tLoss: 0.014801\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.099073\n",
            "Train Epoch: 9 [39040/60000 (65%)]\tLoss: 0.062370\n",
            "Train Epoch: 9 [39680/60000 (66%)]\tLoss: 0.110112\n",
            "Train Epoch: 9 [40320/60000 (67%)]\tLoss: 0.048059\n",
            "Train Epoch: 9 [40960/60000 (68%)]\tLoss: 0.009501\n",
            "Train Epoch: 9 [41600/60000 (69%)]\tLoss: 0.019589\n",
            "Train Epoch: 9 [42240/60000 (70%)]\tLoss: 0.027635\n",
            "Train Epoch: 9 [42880/60000 (71%)]\tLoss: 0.122871\n",
            "Train Epoch: 9 [43520/60000 (72%)]\tLoss: 0.034805\n",
            "Train Epoch: 9 [44160/60000 (74%)]\tLoss: 0.008300\n",
            "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.033439\n",
            "Train Epoch: 9 [45440/60000 (76%)]\tLoss: 0.011009\n",
            "Train Epoch: 9 [46080/60000 (77%)]\tLoss: 0.009177\n",
            "Train Epoch: 9 [46720/60000 (78%)]\tLoss: 0.029880\n",
            "Train Epoch: 9 [47360/60000 (79%)]\tLoss: 0.093526\n",
            "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.025395\n",
            "Train Epoch: 9 [48640/60000 (81%)]\tLoss: 0.053396\n",
            "Train Epoch: 9 [49280/60000 (82%)]\tLoss: 0.046803\n",
            "Train Epoch: 9 [49920/60000 (83%)]\tLoss: 0.003905\n",
            "Train Epoch: 9 [50560/60000 (84%)]\tLoss: 0.037462\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.028618\n",
            "Train Epoch: 9 [51840/60000 (86%)]\tLoss: 0.019385\n",
            "Train Epoch: 9 [52480/60000 (87%)]\tLoss: 0.116574\n",
            "Train Epoch: 9 [53120/60000 (88%)]\tLoss: 0.004669\n",
            "Train Epoch: 9 [53760/60000 (90%)]\tLoss: 0.008578\n",
            "Train Epoch: 9 [54400/60000 (91%)]\tLoss: 0.012985\n",
            "Train Epoch: 9 [55040/60000 (92%)]\tLoss: 0.048592\n",
            "Train Epoch: 9 [55680/60000 (93%)]\tLoss: 0.028807\n",
            "Train Epoch: 9 [56320/60000 (94%)]\tLoss: 0.093995\n",
            "Train Epoch: 9 [56960/60000 (95%)]\tLoss: 0.055520\n",
            "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.056433\n",
            "Train Epoch: 9 [58240/60000 (97%)]\tLoss: 0.102293\n",
            "Train Epoch: 9 [58880/60000 (98%)]\tLoss: 0.031933\n",
            "Train Epoch: 9 [59520/60000 (99%)]\tLoss: 0.127865\n",
            "\n",
            "Test set: Average loss: 0.0149, Accuracy: 9955/10000 (100%)\n",
            "\n",
            "Model saved with new best test loss: 0.0149 \n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.028065\n",
            "Train Epoch: 10 [640/60000 (1%)]\tLoss: 0.028407\n",
            "Train Epoch: 10 [1280/60000 (2%)]\tLoss: 0.046590\n",
            "Train Epoch: 10 [1920/60000 (3%)]\tLoss: 0.008850\n",
            "Train Epoch: 10 [2560/60000 (4%)]\tLoss: 0.081650\n",
            "Train Epoch: 10 [3200/60000 (5%)]\tLoss: 0.001438\n",
            "Train Epoch: 10 [3840/60000 (6%)]\tLoss: 0.007221\n",
            "Train Epoch: 10 [4480/60000 (7%)]\tLoss: 0.080613\n",
            "Train Epoch: 10 [5120/60000 (9%)]\tLoss: 0.054087\n",
            "Train Epoch: 10 [5760/60000 (10%)]\tLoss: 0.032629\n",
            "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.014455\n",
            "Train Epoch: 10 [7040/60000 (12%)]\tLoss: 0.015958\n",
            "Train Epoch: 10 [7680/60000 (13%)]\tLoss: 0.032827\n",
            "Train Epoch: 10 [8320/60000 (14%)]\tLoss: 0.008999\n",
            "Train Epoch: 10 [8960/60000 (15%)]\tLoss: 0.025902\n",
            "Train Epoch: 10 [9600/60000 (16%)]\tLoss: 0.054045\n",
            "Train Epoch: 10 [10240/60000 (17%)]\tLoss: 0.008364\n",
            "Train Epoch: 10 [10880/60000 (18%)]\tLoss: 0.030239\n",
            "Train Epoch: 10 [11520/60000 (19%)]\tLoss: 0.096253\n",
            "Train Epoch: 10 [12160/60000 (20%)]\tLoss: 0.020437\n",
            "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.006308\n",
            "Train Epoch: 10 [13440/60000 (22%)]\tLoss: 0.050983\n",
            "Train Epoch: 10 [14080/60000 (23%)]\tLoss: 0.004457\n",
            "Train Epoch: 10 [14720/60000 (25%)]\tLoss: 0.019641\n",
            "Train Epoch: 10 [15360/60000 (26%)]\tLoss: 0.030252\n",
            "Train Epoch: 10 [16000/60000 (27%)]\tLoss: 0.046926\n",
            "Train Epoch: 10 [16640/60000 (28%)]\tLoss: 0.085490\n",
            "Train Epoch: 10 [17280/60000 (29%)]\tLoss: 0.020460\n",
            "Train Epoch: 10 [17920/60000 (30%)]\tLoss: 0.001227\n",
            "Train Epoch: 10 [18560/60000 (31%)]\tLoss: 0.029305\n",
            "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.008757\n",
            "Train Epoch: 10 [19840/60000 (33%)]\tLoss: 0.018895\n",
            "Train Epoch: 10 [20480/60000 (34%)]\tLoss: 0.209521\n",
            "Train Epoch: 10 [21120/60000 (35%)]\tLoss: 0.030251\n",
            "Train Epoch: 10 [21760/60000 (36%)]\tLoss: 0.177372\n",
            "Train Epoch: 10 [22400/60000 (37%)]\tLoss: 0.221548\n",
            "Train Epoch: 10 [23040/60000 (38%)]\tLoss: 0.025908\n",
            "Train Epoch: 10 [23680/60000 (39%)]\tLoss: 0.023918\n",
            "Train Epoch: 10 [24320/60000 (41%)]\tLoss: 0.042660\n",
            "Train Epoch: 10 [24960/60000 (42%)]\tLoss: 0.006675\n",
            "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.017051\n",
            "Train Epoch: 10 [26240/60000 (44%)]\tLoss: 0.025737\n",
            "Train Epoch: 10 [26880/60000 (45%)]\tLoss: 0.069363\n",
            "Train Epoch: 10 [27520/60000 (46%)]\tLoss: 0.109149\n",
            "Train Epoch: 10 [28160/60000 (47%)]\tLoss: 0.056692\n",
            "Train Epoch: 10 [28800/60000 (48%)]\tLoss: 0.065426\n",
            "Train Epoch: 10 [29440/60000 (49%)]\tLoss: 0.007671\n",
            "Train Epoch: 10 [30080/60000 (50%)]\tLoss: 0.005074\n",
            "Train Epoch: 10 [30720/60000 (51%)]\tLoss: 0.006284\n",
            "Train Epoch: 10 [31360/60000 (52%)]\tLoss: 0.114692\n",
            "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.110740\n",
            "Train Epoch: 10 [32640/60000 (54%)]\tLoss: 0.068536\n",
            "Train Epoch: 10 [33280/60000 (55%)]\tLoss: 0.009093\n",
            "Train Epoch: 10 [33920/60000 (57%)]\tLoss: 0.062807\n",
            "Train Epoch: 10 [34560/60000 (58%)]\tLoss: 0.088614\n",
            "Train Epoch: 10 [35200/60000 (59%)]\tLoss: 0.001482\n",
            "Train Epoch: 10 [35840/60000 (60%)]\tLoss: 0.008309\n",
            "Train Epoch: 10 [36480/60000 (61%)]\tLoss: 0.022974\n",
            "Train Epoch: 10 [37120/60000 (62%)]\tLoss: 0.008235\n",
            "Train Epoch: 10 [37760/60000 (63%)]\tLoss: 0.006397\n",
            "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.013271\n",
            "Train Epoch: 10 [39040/60000 (65%)]\tLoss: 0.076968\n",
            "Train Epoch: 10 [39680/60000 (66%)]\tLoss: 0.134538\n",
            "Train Epoch: 10 [40320/60000 (67%)]\tLoss: 0.017597\n",
            "Train Epoch: 10 [40960/60000 (68%)]\tLoss: 0.015207\n",
            "Train Epoch: 10 [41600/60000 (69%)]\tLoss: 0.006218\n",
            "Train Epoch: 10 [42240/60000 (70%)]\tLoss: 0.176742\n",
            "Train Epoch: 10 [42880/60000 (71%)]\tLoss: 0.008646\n",
            "Train Epoch: 10 [43520/60000 (72%)]\tLoss: 0.002872\n",
            "Train Epoch: 10 [44160/60000 (74%)]\tLoss: 0.115936\n",
            "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.034480\n",
            "Train Epoch: 10 [45440/60000 (76%)]\tLoss: 0.057153\n",
            "Train Epoch: 10 [46080/60000 (77%)]\tLoss: 0.000384\n",
            "Train Epoch: 10 [46720/60000 (78%)]\tLoss: 0.027433\n",
            "Train Epoch: 10 [47360/60000 (79%)]\tLoss: 0.022905\n",
            "Train Epoch: 10 [48000/60000 (80%)]\tLoss: 0.006639\n",
            "Train Epoch: 10 [48640/60000 (81%)]\tLoss: 0.012303\n",
            "Train Epoch: 10 [49280/60000 (82%)]\tLoss: 0.093489\n",
            "Train Epoch: 10 [49920/60000 (83%)]\tLoss: 0.021370\n",
            "Train Epoch: 10 [50560/60000 (84%)]\tLoss: 0.029915\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.125607\n",
            "Train Epoch: 10 [51840/60000 (86%)]\tLoss: 0.020476\n",
            "Train Epoch: 10 [52480/60000 (87%)]\tLoss: 0.023100\n",
            "Train Epoch: 10 [53120/60000 (88%)]\tLoss: 0.050179\n",
            "Train Epoch: 10 [53760/60000 (90%)]\tLoss: 0.006840\n",
            "Train Epoch: 10 [54400/60000 (91%)]\tLoss: 0.061327\n",
            "Train Epoch: 10 [55040/60000 (92%)]\tLoss: 0.002427\n",
            "Train Epoch: 10 [55680/60000 (93%)]\tLoss: 0.145886\n",
            "Train Epoch: 10 [56320/60000 (94%)]\tLoss: 0.129767\n",
            "Train Epoch: 10 [56960/60000 (95%)]\tLoss: 0.044278\n",
            "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.001011\n",
            "Train Epoch: 10 [58240/60000 (97%)]\tLoss: 0.115453\n",
            "Train Epoch: 10 [58880/60000 (98%)]\tLoss: 0.006497\n",
            "Train Epoch: 10 [59520/60000 (99%)]\tLoss: 0.095511\n",
            "\n",
            "Test set: Average loss: 0.0145, Accuracy: 9955/10000 (100%)\n",
            "\n",
            "Model saved with new best test loss: 0.0145 \n",
            "\n",
            "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.044037\n",
            "Train Epoch: 11 [640/60000 (1%)]\tLoss: 0.001809\n",
            "Train Epoch: 11 [1280/60000 (2%)]\tLoss: 0.011759\n",
            "Train Epoch: 11 [1920/60000 (3%)]\tLoss: 0.053589\n",
            "Train Epoch: 11 [2560/60000 (4%)]\tLoss: 0.010903\n",
            "Train Epoch: 11 [3200/60000 (5%)]\tLoss: 0.262806\n",
            "Train Epoch: 11 [3840/60000 (6%)]\tLoss: 0.015133\n",
            "Train Epoch: 11 [4480/60000 (7%)]\tLoss: 0.072120\n",
            "Train Epoch: 11 [5120/60000 (9%)]\tLoss: 0.003871\n",
            "Train Epoch: 11 [5760/60000 (10%)]\tLoss: 0.015355\n",
            "Train Epoch: 11 [6400/60000 (11%)]\tLoss: 0.009341\n",
            "Train Epoch: 11 [7040/60000 (12%)]\tLoss: 0.009860\n",
            "Train Epoch: 11 [7680/60000 (13%)]\tLoss: 0.024448\n",
            "Train Epoch: 11 [8320/60000 (14%)]\tLoss: 0.063257\n",
            "Train Epoch: 11 [8960/60000 (15%)]\tLoss: 0.032833\n",
            "Train Epoch: 11 [9600/60000 (16%)]\tLoss: 0.031733\n",
            "Train Epoch: 11 [10240/60000 (17%)]\tLoss: 0.018933\n",
            "Train Epoch: 11 [10880/60000 (18%)]\tLoss: 0.006639\n",
            "Train Epoch: 11 [11520/60000 (19%)]\tLoss: 0.030040\n",
            "Train Epoch: 11 [12160/60000 (20%)]\tLoss: 0.007474\n",
            "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 0.007672\n",
            "Train Epoch: 11 [13440/60000 (22%)]\tLoss: 0.077604\n",
            "Train Epoch: 11 [14080/60000 (23%)]\tLoss: 0.051033\n",
            "Train Epoch: 11 [14720/60000 (25%)]\tLoss: 0.025861\n",
            "Train Epoch: 11 [15360/60000 (26%)]\tLoss: 0.011212\n",
            "Train Epoch: 11 [16000/60000 (27%)]\tLoss: 0.015216\n",
            "Train Epoch: 11 [16640/60000 (28%)]\tLoss: 0.006996\n",
            "Train Epoch: 11 [17280/60000 (29%)]\tLoss: 0.129859\n",
            "Train Epoch: 11 [17920/60000 (30%)]\tLoss: 0.081042\n",
            "Train Epoch: 11 [18560/60000 (31%)]\tLoss: 0.011097\n",
            "Train Epoch: 11 [19200/60000 (32%)]\tLoss: 0.002691\n",
            "Train Epoch: 11 [19840/60000 (33%)]\tLoss: 0.012195\n",
            "Train Epoch: 11 [20480/60000 (34%)]\tLoss: 0.074794\n",
            "Train Epoch: 11 [21120/60000 (35%)]\tLoss: 0.051221\n",
            "Train Epoch: 11 [21760/60000 (36%)]\tLoss: 0.074105\n",
            "Train Epoch: 11 [22400/60000 (37%)]\tLoss: 0.076781\n",
            "Train Epoch: 11 [23040/60000 (38%)]\tLoss: 0.094856\n",
            "Train Epoch: 11 [23680/60000 (39%)]\tLoss: 0.078962\n",
            "Train Epoch: 11 [24320/60000 (41%)]\tLoss: 0.021068\n",
            "Train Epoch: 11 [24960/60000 (42%)]\tLoss: 0.056481\n",
            "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.151462\n",
            "Train Epoch: 11 [26240/60000 (44%)]\tLoss: 0.060301\n",
            "Train Epoch: 11 [26880/60000 (45%)]\tLoss: 0.178163\n",
            "Train Epoch: 11 [27520/60000 (46%)]\tLoss: 0.030932\n",
            "Train Epoch: 11 [28160/60000 (47%)]\tLoss: 0.006223\n",
            "Train Epoch: 11 [28800/60000 (48%)]\tLoss: 0.001977\n",
            "Train Epoch: 11 [29440/60000 (49%)]\tLoss: 0.005249\n",
            "Train Epoch: 11 [30080/60000 (50%)]\tLoss: 0.002932\n",
            "Train Epoch: 11 [30720/60000 (51%)]\tLoss: 0.031921\n",
            "Train Epoch: 11 [31360/60000 (52%)]\tLoss: 0.004140\n",
            "Train Epoch: 11 [32000/60000 (53%)]\tLoss: 0.032968\n",
            "Train Epoch: 11 [32640/60000 (54%)]\tLoss: 0.013515\n",
            "Train Epoch: 11 [33280/60000 (55%)]\tLoss: 0.105713\n",
            "Train Epoch: 11 [33920/60000 (57%)]\tLoss: 0.012488\n",
            "Train Epoch: 11 [34560/60000 (58%)]\tLoss: 0.064513\n",
            "Train Epoch: 11 [35200/60000 (59%)]\tLoss: 0.034533\n",
            "Train Epoch: 11 [35840/60000 (60%)]\tLoss: 0.018293\n",
            "Train Epoch: 11 [36480/60000 (61%)]\tLoss: 0.009203\n",
            "Train Epoch: 11 [37120/60000 (62%)]\tLoss: 0.065094\n",
            "Train Epoch: 11 [37760/60000 (63%)]\tLoss: 0.006573\n",
            "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.074742\n",
            "Train Epoch: 11 [39040/60000 (65%)]\tLoss: 0.338079\n",
            "Train Epoch: 11 [39680/60000 (66%)]\tLoss: 0.008383\n",
            "Train Epoch: 11 [40320/60000 (67%)]\tLoss: 0.021048\n",
            "Train Epoch: 11 [40960/60000 (68%)]\tLoss: 0.071255\n",
            "Train Epoch: 11 [41600/60000 (69%)]\tLoss: 0.067841\n",
            "Train Epoch: 11 [42240/60000 (70%)]\tLoss: 0.056182\n",
            "Train Epoch: 11 [42880/60000 (71%)]\tLoss: 0.067995\n",
            "Train Epoch: 11 [43520/60000 (72%)]\tLoss: 0.067068\n",
            "Train Epoch: 11 [44160/60000 (74%)]\tLoss: 0.002218\n",
            "Train Epoch: 11 [44800/60000 (75%)]\tLoss: 0.102675\n",
            "Train Epoch: 11 [45440/60000 (76%)]\tLoss: 0.144352\n",
            "Train Epoch: 11 [46080/60000 (77%)]\tLoss: 0.041351\n",
            "Train Epoch: 11 [46720/60000 (78%)]\tLoss: 0.041839\n",
            "Train Epoch: 11 [47360/60000 (79%)]\tLoss: 0.041959\n",
            "Train Epoch: 11 [48000/60000 (80%)]\tLoss: 0.034629\n",
            "Train Epoch: 11 [48640/60000 (81%)]\tLoss: 0.026210\n",
            "Train Epoch: 11 [49280/60000 (82%)]\tLoss: 0.015019\n",
            "Train Epoch: 11 [49920/60000 (83%)]\tLoss: 0.007473\n",
            "Train Epoch: 11 [50560/60000 (84%)]\tLoss: 0.190222\n",
            "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.077776\n",
            "Train Epoch: 11 [51840/60000 (86%)]\tLoss: 0.011997\n",
            "Train Epoch: 11 [52480/60000 (87%)]\tLoss: 0.048194\n",
            "Train Epoch: 11 [53120/60000 (88%)]\tLoss: 0.059865\n",
            "Train Epoch: 11 [53760/60000 (90%)]\tLoss: 0.010255\n",
            "Train Epoch: 11 [54400/60000 (91%)]\tLoss: 0.014108\n",
            "Train Epoch: 11 [55040/60000 (92%)]\tLoss: 0.023676\n",
            "Train Epoch: 11 [55680/60000 (93%)]\tLoss: 0.010480\n",
            "Train Epoch: 11 [56320/60000 (94%)]\tLoss: 0.047506\n",
            "Train Epoch: 11 [56960/60000 (95%)]\tLoss: 0.044298\n",
            "Train Epoch: 11 [57600/60000 (96%)]\tLoss: 0.006490\n",
            "Train Epoch: 11 [58240/60000 (97%)]\tLoss: 0.024963\n",
            "Train Epoch: 11 [58880/60000 (98%)]\tLoss: 0.010430\n",
            "Train Epoch: 11 [59520/60000 (99%)]\tLoss: 0.089946\n",
            "\n",
            "Test set: Average loss: 0.0177, Accuracy: 9943/10000 (99%)\n",
            "\n",
            "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.075771\n",
            "Train Epoch: 12 [640/60000 (1%)]\tLoss: 0.030737\n",
            "Train Epoch: 12 [1280/60000 (2%)]\tLoss: 0.012597\n",
            "Train Epoch: 12 [1920/60000 (3%)]\tLoss: 0.019961\n",
            "Train Epoch: 12 [2560/60000 (4%)]\tLoss: 0.017371\n",
            "Train Epoch: 12 [3200/60000 (5%)]\tLoss: 0.006836\n",
            "Train Epoch: 12 [3840/60000 (6%)]\tLoss: 0.035557\n",
            "Train Epoch: 12 [4480/60000 (7%)]\tLoss: 0.044196\n",
            "Train Epoch: 12 [5120/60000 (9%)]\tLoss: 0.143466\n",
            "Train Epoch: 12 [5760/60000 (10%)]\tLoss: 0.053333\n",
            "Train Epoch: 12 [6400/60000 (11%)]\tLoss: 0.017799\n",
            "Train Epoch: 12 [7040/60000 (12%)]\tLoss: 0.003603\n",
            "Train Epoch: 12 [7680/60000 (13%)]\tLoss: 0.007822\n",
            "Train Epoch: 12 [8320/60000 (14%)]\tLoss: 0.120556\n",
            "Train Epoch: 12 [8960/60000 (15%)]\tLoss: 0.011986\n",
            "Train Epoch: 12 [9600/60000 (16%)]\tLoss: 0.121218\n",
            "Train Epoch: 12 [10240/60000 (17%)]\tLoss: 0.005159\n",
            "Train Epoch: 12 [10880/60000 (18%)]\tLoss: 0.032207\n",
            "Train Epoch: 12 [11520/60000 (19%)]\tLoss: 0.039488\n",
            "Train Epoch: 12 [12160/60000 (20%)]\tLoss: 0.073263\n",
            "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 0.001917\n",
            "Train Epoch: 12 [13440/60000 (22%)]\tLoss: 0.032664\n",
            "Train Epoch: 12 [14080/60000 (23%)]\tLoss: 0.001371\n",
            "Train Epoch: 12 [14720/60000 (25%)]\tLoss: 0.094088\n",
            "Train Epoch: 12 [15360/60000 (26%)]\tLoss: 0.235495\n",
            "Train Epoch: 12 [16000/60000 (27%)]\tLoss: 0.014311\n",
            "Train Epoch: 12 [16640/60000 (28%)]\tLoss: 0.029295\n",
            "Train Epoch: 12 [17280/60000 (29%)]\tLoss: 0.012902\n",
            "Train Epoch: 12 [17920/60000 (30%)]\tLoss: 0.033101\n",
            "Train Epoch: 12 [18560/60000 (31%)]\tLoss: 0.068505\n",
            "Train Epoch: 12 [19200/60000 (32%)]\tLoss: 0.021215\n",
            "Train Epoch: 12 [19840/60000 (33%)]\tLoss: 0.004710\n",
            "Train Epoch: 12 [20480/60000 (34%)]\tLoss: 0.085034\n",
            "Train Epoch: 12 [21120/60000 (35%)]\tLoss: 0.048553\n",
            "Train Epoch: 12 [21760/60000 (36%)]\tLoss: 0.025454\n",
            "Train Epoch: 12 [22400/60000 (37%)]\tLoss: 0.023477\n",
            "Train Epoch: 12 [23040/60000 (38%)]\tLoss: 0.031731\n",
            "Train Epoch: 12 [23680/60000 (39%)]\tLoss: 0.025039\n",
            "Train Epoch: 12 [24320/60000 (41%)]\tLoss: 0.110267\n",
            "Train Epoch: 12 [24960/60000 (42%)]\tLoss: 0.002920\n",
            "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 0.007322\n",
            "Train Epoch: 12 [26240/60000 (44%)]\tLoss: 0.144317\n",
            "Train Epoch: 12 [26880/60000 (45%)]\tLoss: 0.073768\n",
            "Train Epoch: 12 [27520/60000 (46%)]\tLoss: 0.010051\n",
            "Train Epoch: 12 [28160/60000 (47%)]\tLoss: 0.039268\n",
            "Train Epoch: 12 [28800/60000 (48%)]\tLoss: 0.001902\n",
            "Train Epoch: 12 [29440/60000 (49%)]\tLoss: 0.007322\n",
            "Train Epoch: 12 [30080/60000 (50%)]\tLoss: 0.002664\n",
            "Train Epoch: 12 [30720/60000 (51%)]\tLoss: 0.006289\n",
            "Train Epoch: 12 [31360/60000 (52%)]\tLoss: 0.003966\n",
            "Train Epoch: 12 [32000/60000 (53%)]\tLoss: 0.010752\n",
            "Train Epoch: 12 [32640/60000 (54%)]\tLoss: 0.064338\n",
            "Train Epoch: 12 [33280/60000 (55%)]\tLoss: 0.044499\n",
            "Train Epoch: 12 [33920/60000 (57%)]\tLoss: 0.114596\n",
            "Train Epoch: 12 [34560/60000 (58%)]\tLoss: 0.025077\n",
            "Train Epoch: 12 [35200/60000 (59%)]\tLoss: 0.000827\n",
            "Train Epoch: 12 [35840/60000 (60%)]\tLoss: 0.011201\n",
            "Train Epoch: 12 [36480/60000 (61%)]\tLoss: 0.007298\n",
            "Train Epoch: 12 [37120/60000 (62%)]\tLoss: 0.069809\n",
            "Train Epoch: 12 [37760/60000 (63%)]\tLoss: 0.003808\n",
            "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.125974\n",
            "Train Epoch: 12 [39040/60000 (65%)]\tLoss: 0.119623\n",
            "Train Epoch: 12 [39680/60000 (66%)]\tLoss: 0.087714\n",
            "Train Epoch: 12 [40320/60000 (67%)]\tLoss: 0.017929\n",
            "Train Epoch: 12 [40960/60000 (68%)]\tLoss: 0.004035\n",
            "Train Epoch: 12 [41600/60000 (69%)]\tLoss: 0.001416\n",
            "Train Epoch: 12 [42240/60000 (70%)]\tLoss: 0.044975\n",
            "Train Epoch: 12 [42880/60000 (71%)]\tLoss: 0.047080\n",
            "Train Epoch: 12 [43520/60000 (72%)]\tLoss: 0.002202\n",
            "Train Epoch: 12 [44160/60000 (74%)]\tLoss: 0.025736\n",
            "Train Epoch: 12 [44800/60000 (75%)]\tLoss: 0.017918\n",
            "Train Epoch: 12 [45440/60000 (76%)]\tLoss: 0.113289\n",
            "Train Epoch: 12 [46080/60000 (77%)]\tLoss: 0.000695\n",
            "Train Epoch: 12 [46720/60000 (78%)]\tLoss: 0.022540\n",
            "Train Epoch: 12 [47360/60000 (79%)]\tLoss: 0.128074\n",
            "Train Epoch: 12 [48000/60000 (80%)]\tLoss: 0.035877\n",
            "Train Epoch: 12 [48640/60000 (81%)]\tLoss: 0.007051\n",
            "Train Epoch: 12 [49280/60000 (82%)]\tLoss: 0.010810\n",
            "Train Epoch: 12 [49920/60000 (83%)]\tLoss: 0.016916\n",
            "Train Epoch: 12 [50560/60000 (84%)]\tLoss: 0.018296\n",
            "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.101287\n",
            "Train Epoch: 12 [51840/60000 (86%)]\tLoss: 0.013396\n",
            "Train Epoch: 12 [52480/60000 (87%)]\tLoss: 0.090949\n",
            "Train Epoch: 12 [53120/60000 (88%)]\tLoss: 0.023910\n",
            "Train Epoch: 12 [53760/60000 (90%)]\tLoss: 0.007720\n",
            "Train Epoch: 12 [54400/60000 (91%)]\tLoss: 0.028435\n",
            "Train Epoch: 12 [55040/60000 (92%)]\tLoss: 0.001628\n",
            "Train Epoch: 12 [55680/60000 (93%)]\tLoss: 0.010686\n",
            "Train Epoch: 12 [56320/60000 (94%)]\tLoss: 0.015086\n",
            "Train Epoch: 12 [56960/60000 (95%)]\tLoss: 0.038756\n",
            "Train Epoch: 12 [57600/60000 (96%)]\tLoss: 0.042485\n",
            "Train Epoch: 12 [58240/60000 (97%)]\tLoss: 0.000658\n",
            "Train Epoch: 12 [58880/60000 (98%)]\tLoss: 0.007392\n",
            "Train Epoch: 12 [59520/60000 (99%)]\tLoss: 0.026910\n",
            "\n",
            "Test set: Average loss: 0.0149, Accuracy: 9959/10000 (100%)\n",
            "\n",
            "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.001331\n",
            "Train Epoch: 13 [640/60000 (1%)]\tLoss: 0.009280\n",
            "Train Epoch: 13 [1280/60000 (2%)]\tLoss: 0.004884\n",
            "Train Epoch: 13 [1920/60000 (3%)]\tLoss: 0.065744\n",
            "Train Epoch: 13 [2560/60000 (4%)]\tLoss: 0.223916\n",
            "Train Epoch: 13 [3200/60000 (5%)]\tLoss: 0.024801\n",
            "Train Epoch: 13 [3840/60000 (6%)]\tLoss: 0.010218\n",
            "Train Epoch: 13 [4480/60000 (7%)]\tLoss: 0.061937\n",
            "Train Epoch: 13 [5120/60000 (9%)]\tLoss: 0.003698\n",
            "Train Epoch: 13 [5760/60000 (10%)]\tLoss: 0.017844\n",
            "Train Epoch: 13 [6400/60000 (11%)]\tLoss: 0.021903\n",
            "Train Epoch: 13 [7040/60000 (12%)]\tLoss: 0.001914\n",
            "Train Epoch: 13 [7680/60000 (13%)]\tLoss: 0.011835\n",
            "Train Epoch: 13 [8320/60000 (14%)]\tLoss: 0.088176\n",
            "Train Epoch: 13 [8960/60000 (15%)]\tLoss: 0.131802\n",
            "Train Epoch: 13 [9600/60000 (16%)]\tLoss: 0.132860\n",
            "Train Epoch: 13 [10240/60000 (17%)]\tLoss: 0.026440\n",
            "Train Epoch: 13 [10880/60000 (18%)]\tLoss: 0.015154\n",
            "Train Epoch: 13 [11520/60000 (19%)]\tLoss: 0.008299\n",
            "Train Epoch: 13 [12160/60000 (20%)]\tLoss: 0.018654\n",
            "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 0.114835\n",
            "Train Epoch: 13 [13440/60000 (22%)]\tLoss: 0.039414\n",
            "Train Epoch: 13 [14080/60000 (23%)]\tLoss: 0.017785\n",
            "Train Epoch: 13 [14720/60000 (25%)]\tLoss: 0.016212\n",
            "Train Epoch: 13 [15360/60000 (26%)]\tLoss: 0.017988\n",
            "Train Epoch: 13 [16000/60000 (27%)]\tLoss: 0.021704\n",
            "Train Epoch: 13 [16640/60000 (28%)]\tLoss: 0.039065\n",
            "Train Epoch: 13 [17280/60000 (29%)]\tLoss: 0.088223\n",
            "Train Epoch: 13 [17920/60000 (30%)]\tLoss: 0.022161\n",
            "Train Epoch: 13 [18560/60000 (31%)]\tLoss: 0.017671\n",
            "Train Epoch: 13 [19200/60000 (32%)]\tLoss: 0.006893\n",
            "Train Epoch: 13 [19840/60000 (33%)]\tLoss: 0.029693\n",
            "Train Epoch: 13 [20480/60000 (34%)]\tLoss: 0.004673\n",
            "Train Epoch: 13 [21120/60000 (35%)]\tLoss: 0.032994\n",
            "Train Epoch: 13 [21760/60000 (36%)]\tLoss: 0.000334\n",
            "Train Epoch: 13 [22400/60000 (37%)]\tLoss: 0.002592\n",
            "Train Epoch: 13 [23040/60000 (38%)]\tLoss: 0.012859\n",
            "Train Epoch: 13 [23680/60000 (39%)]\tLoss: 0.058844\n",
            "Train Epoch: 13 [24320/60000 (41%)]\tLoss: 0.068403\n",
            "Train Epoch: 13 [24960/60000 (42%)]\tLoss: 0.015120\n",
            "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 0.081113\n",
            "Train Epoch: 13 [26240/60000 (44%)]\tLoss: 0.007080\n",
            "Train Epoch: 13 [26880/60000 (45%)]\tLoss: 0.023637\n",
            "Train Epoch: 13 [27520/60000 (46%)]\tLoss: 0.007608\n",
            "Train Epoch: 13 [28160/60000 (47%)]\tLoss: 0.001913\n",
            "Train Epoch: 13 [28800/60000 (48%)]\tLoss: 0.034497\n",
            "Train Epoch: 13 [29440/60000 (49%)]\tLoss: 0.014234\n",
            "Train Epoch: 13 [30080/60000 (50%)]\tLoss: 0.008283\n",
            "Train Epoch: 13 [30720/60000 (51%)]\tLoss: 0.002283\n",
            "Train Epoch: 13 [31360/60000 (52%)]\tLoss: 0.003074\n",
            "Train Epoch: 13 [32000/60000 (53%)]\tLoss: 0.049944\n",
            "Train Epoch: 13 [32640/60000 (54%)]\tLoss: 0.006434\n",
            "Train Epoch: 13 [33280/60000 (55%)]\tLoss: 0.074898\n",
            "Train Epoch: 13 [33920/60000 (57%)]\tLoss: 0.097506\n",
            "Train Epoch: 13 [34560/60000 (58%)]\tLoss: 0.006220\n",
            "Train Epoch: 13 [35200/60000 (59%)]\tLoss: 0.009304\n",
            "Train Epoch: 13 [35840/60000 (60%)]\tLoss: 0.050922\n",
            "Train Epoch: 13 [36480/60000 (61%)]\tLoss: 0.049260\n",
            "Train Epoch: 13 [37120/60000 (62%)]\tLoss: 0.023418\n",
            "Train Epoch: 13 [37760/60000 (63%)]\tLoss: 0.113511\n",
            "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 0.009185\n",
            "Train Epoch: 13 [39040/60000 (65%)]\tLoss: 0.002093\n",
            "Train Epoch: 13 [39680/60000 (66%)]\tLoss: 0.002589\n",
            "Train Epoch: 13 [40320/60000 (67%)]\tLoss: 0.057357\n",
            "Train Epoch: 13 [40960/60000 (68%)]\tLoss: 0.031500\n",
            "Train Epoch: 13 [41600/60000 (69%)]\tLoss: 0.003879\n",
            "Train Epoch: 13 [42240/60000 (70%)]\tLoss: 0.032297\n",
            "Train Epoch: 13 [42880/60000 (71%)]\tLoss: 0.088304\n",
            "Train Epoch: 13 [43520/60000 (72%)]\tLoss: 0.086645\n",
            "Train Epoch: 13 [44160/60000 (74%)]\tLoss: 0.030041\n",
            "Train Epoch: 13 [44800/60000 (75%)]\tLoss: 0.030232\n",
            "Train Epoch: 13 [45440/60000 (76%)]\tLoss: 0.063570\n",
            "Train Epoch: 13 [46080/60000 (77%)]\tLoss: 0.016611\n",
            "Train Epoch: 13 [46720/60000 (78%)]\tLoss: 0.054400\n",
            "Train Epoch: 13 [47360/60000 (79%)]\tLoss: 0.103653\n",
            "Train Epoch: 13 [48000/60000 (80%)]\tLoss: 0.019371\n",
            "Train Epoch: 13 [48640/60000 (81%)]\tLoss: 0.098063\n",
            "Train Epoch: 13 [49280/60000 (82%)]\tLoss: 0.053338\n",
            "Train Epoch: 13 [49920/60000 (83%)]\tLoss: 0.011990\n",
            "Train Epoch: 13 [50560/60000 (84%)]\tLoss: 0.015769\n",
            "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.068042\n",
            "Train Epoch: 13 [51840/60000 (86%)]\tLoss: 0.087492\n",
            "Train Epoch: 13 [52480/60000 (87%)]\tLoss: 0.233489\n",
            "Train Epoch: 13 [53120/60000 (88%)]\tLoss: 0.008554\n",
            "Train Epoch: 13 [53760/60000 (90%)]\tLoss: 0.062153\n",
            "Train Epoch: 13 [54400/60000 (91%)]\tLoss: 0.001415\n",
            "Train Epoch: 13 [55040/60000 (92%)]\tLoss: 0.003583\n",
            "Train Epoch: 13 [55680/60000 (93%)]\tLoss: 0.046343\n",
            "Train Epoch: 13 [56320/60000 (94%)]\tLoss: 0.004973\n",
            "Train Epoch: 13 [56960/60000 (95%)]\tLoss: 0.017777\n",
            "Train Epoch: 13 [57600/60000 (96%)]\tLoss: 0.008987\n",
            "Train Epoch: 13 [58240/60000 (97%)]\tLoss: 0.003151\n",
            "Train Epoch: 13 [58880/60000 (98%)]\tLoss: 0.007352\n",
            "Train Epoch: 13 [59520/60000 (99%)]\tLoss: 0.004174\n",
            "\n",
            "Test set: Average loss: 0.0140, Accuracy: 9961/10000 (100%)\n",
            "\n",
            "Model saved with new best test loss: 0.0140 \n",
            "\n",
            "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.037066\n",
            "Train Epoch: 14 [640/60000 (1%)]\tLoss: 0.004124\n",
            "Train Epoch: 14 [1280/60000 (2%)]\tLoss: 0.034264\n",
            "Train Epoch: 14 [1920/60000 (3%)]\tLoss: 0.050497\n",
            "Train Epoch: 14 [2560/60000 (4%)]\tLoss: 0.017636\n",
            "Train Epoch: 14 [3200/60000 (5%)]\tLoss: 0.016688\n",
            "Train Epoch: 14 [3840/60000 (6%)]\tLoss: 0.056484\n",
            "Train Epoch: 14 [4480/60000 (7%)]\tLoss: 0.049204\n",
            "Train Epoch: 14 [5120/60000 (9%)]\tLoss: 0.004292\n",
            "Train Epoch: 14 [5760/60000 (10%)]\tLoss: 0.003452\n",
            "Train Epoch: 14 [6400/60000 (11%)]\tLoss: 0.002061\n",
            "Train Epoch: 14 [7040/60000 (12%)]\tLoss: 0.025241\n",
            "Train Epoch: 14 [7680/60000 (13%)]\tLoss: 0.026952\n",
            "Train Epoch: 14 [8320/60000 (14%)]\tLoss: 0.070599\n",
            "Train Epoch: 14 [8960/60000 (15%)]\tLoss: 0.001107\n",
            "Train Epoch: 14 [9600/60000 (16%)]\tLoss: 0.007278\n",
            "Train Epoch: 14 [10240/60000 (17%)]\tLoss: 0.027600\n",
            "Train Epoch: 14 [10880/60000 (18%)]\tLoss: 0.053903\n",
            "Train Epoch: 14 [11520/60000 (19%)]\tLoss: 0.030419\n",
            "Train Epoch: 14 [12160/60000 (20%)]\tLoss: 0.006268\n",
            "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.002981\n",
            "Train Epoch: 14 [13440/60000 (22%)]\tLoss: 0.066516\n",
            "Train Epoch: 14 [14080/60000 (23%)]\tLoss: 0.080722\n",
            "Train Epoch: 14 [14720/60000 (25%)]\tLoss: 0.047830\n",
            "Train Epoch: 14 [15360/60000 (26%)]\tLoss: 0.005691\n",
            "Train Epoch: 14 [16000/60000 (27%)]\tLoss: 0.013269\n",
            "Train Epoch: 14 [16640/60000 (28%)]\tLoss: 0.009895\n",
            "Train Epoch: 14 [17280/60000 (29%)]\tLoss: 0.115019\n",
            "Train Epoch: 14 [17920/60000 (30%)]\tLoss: 0.005871\n",
            "Train Epoch: 14 [18560/60000 (31%)]\tLoss: 0.030010\n",
            "Train Epoch: 14 [19200/60000 (32%)]\tLoss: 0.000357\n",
            "Train Epoch: 14 [19840/60000 (33%)]\tLoss: 0.050203\n",
            "Train Epoch: 14 [20480/60000 (34%)]\tLoss: 0.032076\n",
            "Train Epoch: 14 [21120/60000 (35%)]\tLoss: 0.092245\n",
            "Train Epoch: 14 [21760/60000 (36%)]\tLoss: 0.038297\n",
            "Train Epoch: 14 [22400/60000 (37%)]\tLoss: 0.007514\n",
            "Train Epoch: 14 [23040/60000 (38%)]\tLoss: 0.008992\n",
            "Train Epoch: 14 [23680/60000 (39%)]\tLoss: 0.006291\n",
            "Train Epoch: 14 [24320/60000 (41%)]\tLoss: 0.007625\n",
            "Train Epoch: 14 [24960/60000 (42%)]\tLoss: 0.029195\n",
            "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.007367\n",
            "Train Epoch: 14 [26240/60000 (44%)]\tLoss: 0.039268\n",
            "Train Epoch: 14 [26880/60000 (45%)]\tLoss: 0.146019\n",
            "Train Epoch: 14 [27520/60000 (46%)]\tLoss: 0.007492\n",
            "Train Epoch: 14 [28160/60000 (47%)]\tLoss: 0.082296\n",
            "Train Epoch: 14 [28800/60000 (48%)]\tLoss: 0.003723\n",
            "Train Epoch: 14 [29440/60000 (49%)]\tLoss: 0.054150\n",
            "Train Epoch: 14 [30080/60000 (50%)]\tLoss: 0.073446\n",
            "Train Epoch: 14 [30720/60000 (51%)]\tLoss: 0.016684\n",
            "Train Epoch: 14 [31360/60000 (52%)]\tLoss: 0.024190\n",
            "Train Epoch: 14 [32000/60000 (53%)]\tLoss: 0.042283\n",
            "Train Epoch: 14 [32640/60000 (54%)]\tLoss: 0.021326\n",
            "Train Epoch: 14 [33280/60000 (55%)]\tLoss: 0.016538\n",
            "Train Epoch: 14 [33920/60000 (57%)]\tLoss: 0.010015\n",
            "Train Epoch: 14 [34560/60000 (58%)]\tLoss: 0.040189\n",
            "Train Epoch: 14 [35200/60000 (59%)]\tLoss: 0.000985\n",
            "Train Epoch: 14 [35840/60000 (60%)]\tLoss: 0.238282\n",
            "Train Epoch: 14 [36480/60000 (61%)]\tLoss: 0.089764\n",
            "Train Epoch: 14 [37120/60000 (62%)]\tLoss: 0.003999\n",
            "Train Epoch: 14 [37760/60000 (63%)]\tLoss: 0.035237\n",
            "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.013380\n",
            "Train Epoch: 14 [39040/60000 (65%)]\tLoss: 0.009843\n",
            "Train Epoch: 14 [39680/60000 (66%)]\tLoss: 0.058909\n",
            "Train Epoch: 14 [40320/60000 (67%)]\tLoss: 0.017237\n",
            "Train Epoch: 14 [40960/60000 (68%)]\tLoss: 0.017004\n",
            "Train Epoch: 14 [41600/60000 (69%)]\tLoss: 0.198443\n",
            "Train Epoch: 14 [42240/60000 (70%)]\tLoss: 0.004841\n",
            "Train Epoch: 14 [42880/60000 (71%)]\tLoss: 0.015638\n",
            "Train Epoch: 14 [43520/60000 (72%)]\tLoss: 0.048779\n",
            "Train Epoch: 14 [44160/60000 (74%)]\tLoss: 0.002755\n",
            "Train Epoch: 14 [44800/60000 (75%)]\tLoss: 0.002034\n",
            "Train Epoch: 14 [45440/60000 (76%)]\tLoss: 0.063341\n",
            "Train Epoch: 14 [46080/60000 (77%)]\tLoss: 0.044906\n",
            "Train Epoch: 14 [46720/60000 (78%)]\tLoss: 0.052850\n",
            "Train Epoch: 14 [47360/60000 (79%)]\tLoss: 0.053419\n",
            "Train Epoch: 14 [48000/60000 (80%)]\tLoss: 0.022483\n",
            "Train Epoch: 14 [48640/60000 (81%)]\tLoss: 0.015861\n",
            "Train Epoch: 14 [49280/60000 (82%)]\tLoss: 0.002246\n",
            "Train Epoch: 14 [49920/60000 (83%)]\tLoss: 0.107917\n",
            "Train Epoch: 14 [50560/60000 (84%)]\tLoss: 0.012758\n",
            "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.005309\n",
            "Train Epoch: 14 [51840/60000 (86%)]\tLoss: 0.007192\n",
            "Train Epoch: 14 [52480/60000 (87%)]\tLoss: 0.012456\n",
            "Train Epoch: 14 [53120/60000 (88%)]\tLoss: 0.026654\n",
            "Train Epoch: 14 [53760/60000 (90%)]\tLoss: 0.101267\n",
            "Train Epoch: 14 [54400/60000 (91%)]\tLoss: 0.003900\n",
            "Train Epoch: 14 [55040/60000 (92%)]\tLoss: 0.005894\n",
            "Train Epoch: 14 [55680/60000 (93%)]\tLoss: 0.034229\n",
            "Train Epoch: 14 [56320/60000 (94%)]\tLoss: 0.098355\n",
            "Train Epoch: 14 [56960/60000 (95%)]\tLoss: 0.026967\n",
            "Train Epoch: 14 [57600/60000 (96%)]\tLoss: 0.021728\n",
            "Train Epoch: 14 [58240/60000 (97%)]\tLoss: 0.041670\n",
            "Train Epoch: 14 [58880/60000 (98%)]\tLoss: 0.005737\n",
            "Train Epoch: 14 [59520/60000 (99%)]\tLoss: 0.006275\n",
            "\n",
            "Test set: Average loss: 0.0142, Accuracy: 9959/10000 (100%)\n",
            "\n",
            "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.003426\n",
            "Train Epoch: 15 [640/60000 (1%)]\tLoss: 0.011129\n",
            "Train Epoch: 15 [1280/60000 (2%)]\tLoss: 0.035735\n",
            "Train Epoch: 15 [1920/60000 (3%)]\tLoss: 0.006117\n",
            "Train Epoch: 15 [2560/60000 (4%)]\tLoss: 0.000847\n",
            "Train Epoch: 15 [3200/60000 (5%)]\tLoss: 0.004245\n",
            "Train Epoch: 15 [3840/60000 (6%)]\tLoss: 0.037833\n",
            "Train Epoch: 15 [4480/60000 (7%)]\tLoss: 0.006430\n",
            "Train Epoch: 15 [5120/60000 (9%)]\tLoss: 0.366673\n",
            "Train Epoch: 15 [5760/60000 (10%)]\tLoss: 0.038849\n",
            "Train Epoch: 15 [6400/60000 (11%)]\tLoss: 0.059484\n",
            "Train Epoch: 15 [7040/60000 (12%)]\tLoss: 0.055104\n",
            "Train Epoch: 15 [7680/60000 (13%)]\tLoss: 0.008034\n",
            "Train Epoch: 15 [8320/60000 (14%)]\tLoss: 0.049002\n",
            "Train Epoch: 15 [8960/60000 (15%)]\tLoss: 0.171882\n",
            "Train Epoch: 15 [9600/60000 (16%)]\tLoss: 0.073412\n",
            "Train Epoch: 15 [10240/60000 (17%)]\tLoss: 0.040797\n",
            "Train Epoch: 15 [10880/60000 (18%)]\tLoss: 0.023891\n",
            "Train Epoch: 15 [11520/60000 (19%)]\tLoss: 0.093447\n",
            "Train Epoch: 15 [12160/60000 (20%)]\tLoss: 0.143776\n",
            "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 0.200898\n",
            "Train Epoch: 15 [13440/60000 (22%)]\tLoss: 0.004724\n",
            "Train Epoch: 15 [14080/60000 (23%)]\tLoss: 0.030011\n",
            "Train Epoch: 15 [14720/60000 (25%)]\tLoss: 0.035322\n",
            "Train Epoch: 15 [15360/60000 (26%)]\tLoss: 0.041815\n",
            "Train Epoch: 15 [16000/60000 (27%)]\tLoss: 0.043770\n",
            "Train Epoch: 15 [16640/60000 (28%)]\tLoss: 0.003643\n",
            "Train Epoch: 15 [17280/60000 (29%)]\tLoss: 0.007456\n",
            "Train Epoch: 15 [17920/60000 (30%)]\tLoss: 0.003512\n",
            "Train Epoch: 15 [18560/60000 (31%)]\tLoss: 0.055811\n",
            "Train Epoch: 15 [19200/60000 (32%)]\tLoss: 0.001651\n",
            "Train Epoch: 15 [19840/60000 (33%)]\tLoss: 0.006702\n",
            "Train Epoch: 15 [20480/60000 (34%)]\tLoss: 0.005986\n",
            "Train Epoch: 15 [21120/60000 (35%)]\tLoss: 0.006339\n",
            "Train Epoch: 15 [21760/60000 (36%)]\tLoss: 0.000758\n",
            "Train Epoch: 15 [22400/60000 (37%)]\tLoss: 0.077393\n",
            "Train Epoch: 15 [23040/60000 (38%)]\tLoss: 0.015338\n",
            "Train Epoch: 15 [23680/60000 (39%)]\tLoss: 0.009958\n",
            "Train Epoch: 15 [24320/60000 (41%)]\tLoss: 0.004650\n",
            "Train Epoch: 15 [24960/60000 (42%)]\tLoss: 0.002559\n",
            "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 0.001273\n",
            "Train Epoch: 15 [26240/60000 (44%)]\tLoss: 0.015105\n",
            "Train Epoch: 15 [26880/60000 (45%)]\tLoss: 0.139441\n",
            "Train Epoch: 15 [27520/60000 (46%)]\tLoss: 0.089582\n",
            "Train Epoch: 15 [28160/60000 (47%)]\tLoss: 0.003892\n",
            "Train Epoch: 15 [28800/60000 (48%)]\tLoss: 0.001197\n",
            "Train Epoch: 15 [29440/60000 (49%)]\tLoss: 0.057546\n",
            "Train Epoch: 15 [30080/60000 (50%)]\tLoss: 0.012900\n",
            "Train Epoch: 15 [30720/60000 (51%)]\tLoss: 0.011336\n",
            "Train Epoch: 15 [31360/60000 (52%)]\tLoss: 0.004378\n",
            "Train Epoch: 15 [32000/60000 (53%)]\tLoss: 0.202232\n",
            "Train Epoch: 15 [32640/60000 (54%)]\tLoss: 0.001877\n",
            "Train Epoch: 15 [33280/60000 (55%)]\tLoss: 0.110786\n",
            "Train Epoch: 15 [33920/60000 (57%)]\tLoss: 0.083485\n",
            "Train Epoch: 15 [34560/60000 (58%)]\tLoss: 0.022169\n",
            "Train Epoch: 15 [35200/60000 (59%)]\tLoss: 0.068608\n",
            "Train Epoch: 15 [35840/60000 (60%)]\tLoss: 0.033728\n",
            "Train Epoch: 15 [36480/60000 (61%)]\tLoss: 0.065170\n",
            "Train Epoch: 15 [37120/60000 (62%)]\tLoss: 0.149617\n",
            "Train Epoch: 15 [37760/60000 (63%)]\tLoss: 0.012480\n",
            "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 0.003425\n",
            "Train Epoch: 15 [39040/60000 (65%)]\tLoss: 0.032845\n",
            "Train Epoch: 15 [39680/60000 (66%)]\tLoss: 0.145789\n",
            "Train Epoch: 15 [40320/60000 (67%)]\tLoss: 0.030072\n",
            "Train Epoch: 15 [40960/60000 (68%)]\tLoss: 0.027081\n",
            "Train Epoch: 15 [41600/60000 (69%)]\tLoss: 0.022338\n",
            "Train Epoch: 15 [42240/60000 (70%)]\tLoss: 0.026596\n",
            "Train Epoch: 15 [42880/60000 (71%)]\tLoss: 0.007389\n",
            "Train Epoch: 15 [43520/60000 (72%)]\tLoss: 0.040135\n",
            "Train Epoch: 15 [44160/60000 (74%)]\tLoss: 0.093895\n",
            "Train Epoch: 15 [44800/60000 (75%)]\tLoss: 0.111125\n",
            "Train Epoch: 15 [45440/60000 (76%)]\tLoss: 0.016378\n",
            "Train Epoch: 15 [46080/60000 (77%)]\tLoss: 0.048125\n",
            "Train Epoch: 15 [46720/60000 (78%)]\tLoss: 0.002141\n",
            "Train Epoch: 15 [47360/60000 (79%)]\tLoss: 0.074147\n",
            "Train Epoch: 15 [48000/60000 (80%)]\tLoss: 0.048912\n",
            "Train Epoch: 15 [48640/60000 (81%)]\tLoss: 0.035420\n",
            "Train Epoch: 15 [49280/60000 (82%)]\tLoss: 0.003573\n",
            "Train Epoch: 15 [49920/60000 (83%)]\tLoss: 0.018565\n",
            "Train Epoch: 15 [50560/60000 (84%)]\tLoss: 0.008344\n",
            "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 0.011137\n",
            "Train Epoch: 15 [51840/60000 (86%)]\tLoss: 0.079517\n",
            "Train Epoch: 15 [52480/60000 (87%)]\tLoss: 0.002938\n",
            "Train Epoch: 15 [53120/60000 (88%)]\tLoss: 0.087414\n",
            "Train Epoch: 15 [53760/60000 (90%)]\tLoss: 0.034700\n",
            "Train Epoch: 15 [54400/60000 (91%)]\tLoss: 0.014688\n",
            "Train Epoch: 15 [55040/60000 (92%)]\tLoss: 0.003919\n",
            "Train Epoch: 15 [55680/60000 (93%)]\tLoss: 0.031951\n",
            "Train Epoch: 15 [56320/60000 (94%)]\tLoss: 0.031724\n",
            "Train Epoch: 15 [56960/60000 (95%)]\tLoss: 0.018937\n",
            "Train Epoch: 15 [57600/60000 (96%)]\tLoss: 0.052197\n",
            "Train Epoch: 15 [58240/60000 (97%)]\tLoss: 0.000717\n",
            "Train Epoch: 15 [58880/60000 (98%)]\tLoss: 0.020452\n",
            "Train Epoch: 15 [59520/60000 (99%)]\tLoss: 0.005226\n",
            "\n",
            "Test set: Average loss: 0.0132, Accuracy: 9960/10000 (100%)\n",
            "\n",
            "Model saved with new best test loss: 0.0132 \n",
            "\n",
            "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.079526\n",
            "Train Epoch: 16 [640/60000 (1%)]\tLoss: 0.002431\n",
            "Train Epoch: 16 [1280/60000 (2%)]\tLoss: 0.048976\n",
            "Train Epoch: 16 [1920/60000 (3%)]\tLoss: 0.002902\n",
            "Train Epoch: 16 [2560/60000 (4%)]\tLoss: 0.016420\n",
            "Train Epoch: 16 [3200/60000 (5%)]\tLoss: 0.125458\n",
            "Train Epoch: 16 [3840/60000 (6%)]\tLoss: 0.096635\n",
            "Train Epoch: 16 [4480/60000 (7%)]\tLoss: 0.001123\n",
            "Train Epoch: 16 [5120/60000 (9%)]\tLoss: 0.016693\n",
            "Train Epoch: 16 [5760/60000 (10%)]\tLoss: 0.197284\n",
            "Train Epoch: 16 [6400/60000 (11%)]\tLoss: 0.035058\n",
            "Train Epoch: 16 [7040/60000 (12%)]\tLoss: 0.015788\n",
            "Train Epoch: 16 [7680/60000 (13%)]\tLoss: 0.033003\n",
            "Train Epoch: 16 [8320/60000 (14%)]\tLoss: 0.007265\n",
            "Train Epoch: 16 [8960/60000 (15%)]\tLoss: 0.035036\n",
            "Train Epoch: 16 [9600/60000 (16%)]\tLoss: 0.013837\n",
            "Train Epoch: 16 [10240/60000 (17%)]\tLoss: 0.002493\n",
            "Train Epoch: 16 [10880/60000 (18%)]\tLoss: 0.086796\n",
            "Train Epoch: 16 [11520/60000 (19%)]\tLoss: 0.010784\n",
            "Train Epoch: 16 [12160/60000 (20%)]\tLoss: 0.005389\n",
            "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 0.007638\n",
            "Train Epoch: 16 [13440/60000 (22%)]\tLoss: 0.009298\n",
            "Train Epoch: 16 [14080/60000 (23%)]\tLoss: 0.022327\n",
            "Train Epoch: 16 [14720/60000 (25%)]\tLoss: 0.040297\n",
            "Train Epoch: 16 [15360/60000 (26%)]\tLoss: 0.024075\n",
            "Train Epoch: 16 [16000/60000 (27%)]\tLoss: 0.016664\n",
            "Train Epoch: 16 [16640/60000 (28%)]\tLoss: 0.050627\n",
            "Train Epoch: 16 [17280/60000 (29%)]\tLoss: 0.025597\n",
            "Train Epoch: 16 [17920/60000 (30%)]\tLoss: 0.080853\n",
            "Train Epoch: 16 [18560/60000 (31%)]\tLoss: 0.016427\n",
            "Train Epoch: 16 [19200/60000 (32%)]\tLoss: 0.016002\n",
            "Train Epoch: 16 [19840/60000 (33%)]\tLoss: 0.029616\n",
            "Train Epoch: 16 [20480/60000 (34%)]\tLoss: 0.029069\n",
            "Train Epoch: 16 [21120/60000 (35%)]\tLoss: 0.032521\n",
            "Train Epoch: 16 [21760/60000 (36%)]\tLoss: 0.004016\n",
            "Train Epoch: 16 [22400/60000 (37%)]\tLoss: 0.075353\n",
            "Train Epoch: 16 [23040/60000 (38%)]\tLoss: 0.004318\n",
            "Train Epoch: 16 [23680/60000 (39%)]\tLoss: 0.044404\n",
            "Train Epoch: 16 [24320/60000 (41%)]\tLoss: 0.002557\n",
            "Train Epoch: 16 [24960/60000 (42%)]\tLoss: 0.022995\n",
            "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 0.027900\n",
            "Train Epoch: 16 [26240/60000 (44%)]\tLoss: 0.035488\n",
            "Train Epoch: 16 [26880/60000 (45%)]\tLoss: 0.053458\n",
            "Train Epoch: 16 [27520/60000 (46%)]\tLoss: 0.000278\n",
            "Train Epoch: 16 [28160/60000 (47%)]\tLoss: 0.340474\n",
            "Train Epoch: 16 [28800/60000 (48%)]\tLoss: 0.035759\n",
            "Train Epoch: 16 [29440/60000 (49%)]\tLoss: 0.091265\n",
            "Train Epoch: 16 [30080/60000 (50%)]\tLoss: 0.183778\n",
            "Train Epoch: 16 [30720/60000 (51%)]\tLoss: 0.003523\n",
            "Train Epoch: 16 [31360/60000 (52%)]\tLoss: 0.001351\n",
            "Train Epoch: 16 [32000/60000 (53%)]\tLoss: 0.169978\n",
            "Train Epoch: 16 [32640/60000 (54%)]\tLoss: 0.030911\n",
            "Train Epoch: 16 [33280/60000 (55%)]\tLoss: 0.032493\n",
            "Train Epoch: 16 [33920/60000 (57%)]\tLoss: 0.012795\n",
            "Train Epoch: 16 [34560/60000 (58%)]\tLoss: 0.082873\n",
            "Train Epoch: 16 [35200/60000 (59%)]\tLoss: 0.013637\n",
            "Train Epoch: 16 [35840/60000 (60%)]\tLoss: 0.038367\n",
            "Train Epoch: 16 [36480/60000 (61%)]\tLoss: 0.000563\n",
            "Train Epoch: 16 [37120/60000 (62%)]\tLoss: 0.013585\n",
            "Train Epoch: 16 [37760/60000 (63%)]\tLoss: 0.004779\n",
            "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 0.015327\n",
            "Train Epoch: 16 [39040/60000 (65%)]\tLoss: 0.000658\n",
            "Train Epoch: 16 [39680/60000 (66%)]\tLoss: 0.043919\n",
            "Train Epoch: 16 [40320/60000 (67%)]\tLoss: 0.071467\n",
            "Train Epoch: 16 [40960/60000 (68%)]\tLoss: 0.096151\n",
            "Train Epoch: 16 [41600/60000 (69%)]\tLoss: 0.050123\n",
            "Train Epoch: 16 [42240/60000 (70%)]\tLoss: 0.026282\n",
            "Train Epoch: 16 [42880/60000 (71%)]\tLoss: 0.033491\n",
            "Train Epoch: 16 [43520/60000 (72%)]\tLoss: 0.041082\n",
            "Train Epoch: 16 [44160/60000 (74%)]\tLoss: 0.000705\n",
            "Train Epoch: 16 [44800/60000 (75%)]\tLoss: 0.056212\n",
            "Train Epoch: 16 [45440/60000 (76%)]\tLoss: 0.012667\n",
            "Train Epoch: 16 [46080/60000 (77%)]\tLoss: 0.001692\n",
            "Train Epoch: 16 [46720/60000 (78%)]\tLoss: 0.035389\n",
            "Train Epoch: 16 [47360/60000 (79%)]\tLoss: 0.019949\n",
            "Train Epoch: 16 [48000/60000 (80%)]\tLoss: 0.133115\n",
            "Train Epoch: 16 [48640/60000 (81%)]\tLoss: 0.098211\n",
            "Train Epoch: 16 [49280/60000 (82%)]\tLoss: 0.068351\n",
            "Train Epoch: 16 [49920/60000 (83%)]\tLoss: 0.064052\n",
            "Train Epoch: 16 [50560/60000 (84%)]\tLoss: 0.003537\n",
            "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 0.002185\n",
            "Train Epoch: 16 [51840/60000 (86%)]\tLoss: 0.006536\n",
            "Train Epoch: 16 [52480/60000 (87%)]\tLoss: 0.011155\n",
            "Train Epoch: 16 [53120/60000 (88%)]\tLoss: 0.025857\n",
            "Train Epoch: 16 [53760/60000 (90%)]\tLoss: 0.010886\n",
            "Train Epoch: 16 [54400/60000 (91%)]\tLoss: 0.009367\n",
            "Train Epoch: 16 [55040/60000 (92%)]\tLoss: 0.141245\n",
            "Train Epoch: 16 [55680/60000 (93%)]\tLoss: 0.003142\n",
            "Train Epoch: 16 [56320/60000 (94%)]\tLoss: 0.002343\n",
            "Train Epoch: 16 [56960/60000 (95%)]\tLoss: 0.002491\n",
            "Train Epoch: 16 [57600/60000 (96%)]\tLoss: 0.054195\n",
            "Train Epoch: 16 [58240/60000 (97%)]\tLoss: 0.007763\n",
            "Train Epoch: 16 [58880/60000 (98%)]\tLoss: 0.062190\n",
            "Train Epoch: 16 [59520/60000 (99%)]\tLoss: 0.028725\n",
            "\n",
            "Test set: Average loss: 0.0136, Accuracy: 9959/10000 (100%)\n",
            "\n",
            "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.027260\n",
            "Train Epoch: 17 [640/60000 (1%)]\tLoss: 0.015106\n",
            "Train Epoch: 17 [1280/60000 (2%)]\tLoss: 0.014389\n",
            "Train Epoch: 17 [1920/60000 (3%)]\tLoss: 0.042506\n",
            "Train Epoch: 17 [2560/60000 (4%)]\tLoss: 0.012371\n",
            "Train Epoch: 17 [3200/60000 (5%)]\tLoss: 0.066501\n",
            "Train Epoch: 17 [3840/60000 (6%)]\tLoss: 0.028439\n",
            "Train Epoch: 17 [4480/60000 (7%)]\tLoss: 0.006919\n",
            "Train Epoch: 17 [5120/60000 (9%)]\tLoss: 0.041824\n",
            "Train Epoch: 17 [5760/60000 (10%)]\tLoss: 0.011961\n",
            "Train Epoch: 17 [6400/60000 (11%)]\tLoss: 0.023492\n",
            "Train Epoch: 17 [7040/60000 (12%)]\tLoss: 0.005896\n",
            "Train Epoch: 17 [7680/60000 (13%)]\tLoss: 0.024436\n",
            "Train Epoch: 17 [8320/60000 (14%)]\tLoss: 0.076737\n",
            "Train Epoch: 17 [8960/60000 (15%)]\tLoss: 0.020401\n",
            "Train Epoch: 17 [9600/60000 (16%)]\tLoss: 0.014473\n",
            "Train Epoch: 17 [10240/60000 (17%)]\tLoss: 0.000577\n",
            "Train Epoch: 17 [10880/60000 (18%)]\tLoss: 0.012931\n",
            "Train Epoch: 17 [11520/60000 (19%)]\tLoss: 0.012465\n",
            "Train Epoch: 17 [12160/60000 (20%)]\tLoss: 0.094258\n",
            "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 0.006993\n",
            "Train Epoch: 17 [13440/60000 (22%)]\tLoss: 0.031685\n",
            "Train Epoch: 17 [14080/60000 (23%)]\tLoss: 0.027612\n",
            "Train Epoch: 17 [14720/60000 (25%)]\tLoss: 0.056689\n",
            "Train Epoch: 17 [15360/60000 (26%)]\tLoss: 0.003278\n",
            "Train Epoch: 17 [16000/60000 (27%)]\tLoss: 0.015842\n",
            "Train Epoch: 17 [16640/60000 (28%)]\tLoss: 0.002521\n",
            "Train Epoch: 17 [17280/60000 (29%)]\tLoss: 0.231774\n",
            "Train Epoch: 17 [17920/60000 (30%)]\tLoss: 0.002166\n",
            "Train Epoch: 17 [18560/60000 (31%)]\tLoss: 0.011571\n",
            "Train Epoch: 17 [19200/60000 (32%)]\tLoss: 0.004933\n",
            "Train Epoch: 17 [19840/60000 (33%)]\tLoss: 0.054991\n",
            "Train Epoch: 17 [20480/60000 (34%)]\tLoss: 0.002116\n",
            "Train Epoch: 17 [21120/60000 (35%)]\tLoss: 0.001194\n",
            "Train Epoch: 17 [21760/60000 (36%)]\tLoss: 0.008443\n",
            "Train Epoch: 17 [22400/60000 (37%)]\tLoss: 0.001446\n",
            "Train Epoch: 17 [23040/60000 (38%)]\tLoss: 0.001034\n",
            "Train Epoch: 17 [23680/60000 (39%)]\tLoss: 0.089077\n",
            "Train Epoch: 17 [24320/60000 (41%)]\tLoss: 0.002043\n",
            "Train Epoch: 17 [24960/60000 (42%)]\tLoss: 0.004971\n",
            "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 0.071832\n",
            "Train Epoch: 17 [26240/60000 (44%)]\tLoss: 0.004375\n",
            "Train Epoch: 17 [26880/60000 (45%)]\tLoss: 0.073255\n",
            "Train Epoch: 17 [27520/60000 (46%)]\tLoss: 0.000819\n",
            "Train Epoch: 17 [28160/60000 (47%)]\tLoss: 0.004001\n",
            "Train Epoch: 17 [28800/60000 (48%)]\tLoss: 0.031837\n",
            "Train Epoch: 17 [29440/60000 (49%)]\tLoss: 0.132731\n",
            "Train Epoch: 17 [30080/60000 (50%)]\tLoss: 0.014000\n",
            "Train Epoch: 17 [30720/60000 (51%)]\tLoss: 0.016223\n",
            "Train Epoch: 17 [31360/60000 (52%)]\tLoss: 0.003074\n",
            "Train Epoch: 17 [32000/60000 (53%)]\tLoss: 0.029823\n",
            "Train Epoch: 17 [32640/60000 (54%)]\tLoss: 0.017146\n",
            "Train Epoch: 17 [33280/60000 (55%)]\tLoss: 0.000794\n",
            "Train Epoch: 17 [33920/60000 (57%)]\tLoss: 0.004709\n",
            "Train Epoch: 17 [34560/60000 (58%)]\tLoss: 0.102307\n",
            "Train Epoch: 17 [35200/60000 (59%)]\tLoss: 0.138400\n",
            "Train Epoch: 17 [35840/60000 (60%)]\tLoss: 0.024507\n",
            "Train Epoch: 17 [36480/60000 (61%)]\tLoss: 0.095537\n",
            "Train Epoch: 17 [37120/60000 (62%)]\tLoss: 0.015156\n",
            "Train Epoch: 17 [37760/60000 (63%)]\tLoss: 0.017654\n",
            "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 0.013714\n",
            "Train Epoch: 17 [39040/60000 (65%)]\tLoss: 0.028433\n",
            "Train Epoch: 17 [39680/60000 (66%)]\tLoss: 0.020207\n",
            "Train Epoch: 17 [40320/60000 (67%)]\tLoss: 0.018764\n",
            "Train Epoch: 17 [40960/60000 (68%)]\tLoss: 0.020071\n",
            "Train Epoch: 17 [41600/60000 (69%)]\tLoss: 0.100590\n",
            "Train Epoch: 17 [42240/60000 (70%)]\tLoss: 0.015961\n",
            "Train Epoch: 17 [42880/60000 (71%)]\tLoss: 0.001633\n",
            "Train Epoch: 17 [43520/60000 (72%)]\tLoss: 0.006383\n",
            "Train Epoch: 17 [44160/60000 (74%)]\tLoss: 0.006354\n",
            "Train Epoch: 17 [44800/60000 (75%)]\tLoss: 0.016113\n",
            "Train Epoch: 17 [45440/60000 (76%)]\tLoss: 0.061423\n",
            "Train Epoch: 17 [46080/60000 (77%)]\tLoss: 0.015717\n",
            "Train Epoch: 17 [46720/60000 (78%)]\tLoss: 0.000732\n",
            "Train Epoch: 17 [47360/60000 (79%)]\tLoss: 0.001877\n",
            "Train Epoch: 17 [48000/60000 (80%)]\tLoss: 0.001304\n",
            "Train Epoch: 17 [48640/60000 (81%)]\tLoss: 0.174191\n",
            "Train Epoch: 17 [49280/60000 (82%)]\tLoss: 0.089096\n",
            "Train Epoch: 17 [49920/60000 (83%)]\tLoss: 0.120244\n",
            "Train Epoch: 17 [50560/60000 (84%)]\tLoss: 0.019204\n",
            "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 0.012404\n",
            "Train Epoch: 17 [51840/60000 (86%)]\tLoss: 0.083717\n",
            "Train Epoch: 17 [52480/60000 (87%)]\tLoss: 0.001515\n",
            "Train Epoch: 17 [53120/60000 (88%)]\tLoss: 0.168384\n",
            "Train Epoch: 17 [53760/60000 (90%)]\tLoss: 0.006914\n",
            "Train Epoch: 17 [54400/60000 (91%)]\tLoss: 0.008182\n",
            "Train Epoch: 17 [55040/60000 (92%)]\tLoss: 0.010836\n",
            "Train Epoch: 17 [55680/60000 (93%)]\tLoss: 0.006474\n",
            "Train Epoch: 17 [56320/60000 (94%)]\tLoss: 0.019756\n",
            "Train Epoch: 17 [56960/60000 (95%)]\tLoss: 0.003240\n",
            "Train Epoch: 17 [57600/60000 (96%)]\tLoss: 0.017706\n",
            "Train Epoch: 17 [58240/60000 (97%)]\tLoss: 0.015239\n",
            "Train Epoch: 17 [58880/60000 (98%)]\tLoss: 0.193543\n",
            "Train Epoch: 17 [59520/60000 (99%)]\tLoss: 0.014979\n",
            "\n",
            "Test set: Average loss: 0.0140, Accuracy: 9960/10000 (100%)\n",
            "\n",
            "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.002942\n",
            "Train Epoch: 18 [640/60000 (1%)]\tLoss: 0.018274\n",
            "Train Epoch: 18 [1280/60000 (2%)]\tLoss: 0.012889\n",
            "Train Epoch: 18 [1920/60000 (3%)]\tLoss: 0.097076\n",
            "Train Epoch: 18 [2560/60000 (4%)]\tLoss: 0.004206\n",
            "Train Epoch: 18 [3200/60000 (5%)]\tLoss: 0.000932\n",
            "Train Epoch: 18 [3840/60000 (6%)]\tLoss: 0.000575\n",
            "Train Epoch: 18 [4480/60000 (7%)]\tLoss: 0.020893\n",
            "Train Epoch: 18 [5120/60000 (9%)]\tLoss: 0.024713\n",
            "Train Epoch: 18 [5760/60000 (10%)]\tLoss: 0.154521\n",
            "Train Epoch: 18 [6400/60000 (11%)]\tLoss: 0.014954\n",
            "Train Epoch: 18 [7040/60000 (12%)]\tLoss: 0.010618\n",
            "Train Epoch: 18 [7680/60000 (13%)]\tLoss: 0.020587\n",
            "Train Epoch: 18 [8320/60000 (14%)]\tLoss: 0.000173\n",
            "Train Epoch: 18 [8960/60000 (15%)]\tLoss: 0.092057\n",
            "Train Epoch: 18 [9600/60000 (16%)]\tLoss: 0.027484\n",
            "Train Epoch: 18 [10240/60000 (17%)]\tLoss: 0.002093\n",
            "Train Epoch: 18 [10880/60000 (18%)]\tLoss: 0.022434\n",
            "Train Epoch: 18 [11520/60000 (19%)]\tLoss: 0.015261\n",
            "Train Epoch: 18 [12160/60000 (20%)]\tLoss: 0.006985\n",
            "Train Epoch: 18 [12800/60000 (21%)]\tLoss: 0.002358\n",
            "Train Epoch: 18 [13440/60000 (22%)]\tLoss: 0.025941\n",
            "Train Epoch: 18 [14080/60000 (23%)]\tLoss: 0.085644\n",
            "Train Epoch: 18 [14720/60000 (25%)]\tLoss: 0.053415\n",
            "Train Epoch: 18 [15360/60000 (26%)]\tLoss: 0.017299\n",
            "Train Epoch: 18 [16000/60000 (27%)]\tLoss: 0.050447\n",
            "Train Epoch: 18 [16640/60000 (28%)]\tLoss: 0.009479\n",
            "Train Epoch: 18 [17280/60000 (29%)]\tLoss: 0.000639\n",
            "Train Epoch: 18 [17920/60000 (30%)]\tLoss: 0.040270\n",
            "Train Epoch: 18 [18560/60000 (31%)]\tLoss: 0.095379\n",
            "Train Epoch: 18 [19200/60000 (32%)]\tLoss: 0.028173\n",
            "Train Epoch: 18 [19840/60000 (33%)]\tLoss: 0.002498\n",
            "Train Epoch: 18 [20480/60000 (34%)]\tLoss: 0.009389\n",
            "Train Epoch: 18 [21120/60000 (35%)]\tLoss: 0.010761\n",
            "Train Epoch: 18 [21760/60000 (36%)]\tLoss: 0.036048\n",
            "Train Epoch: 18 [22400/60000 (37%)]\tLoss: 0.014355\n",
            "Train Epoch: 18 [23040/60000 (38%)]\tLoss: 0.021686\n",
            "Train Epoch: 18 [23680/60000 (39%)]\tLoss: 0.056245\n",
            "Train Epoch: 18 [24320/60000 (41%)]\tLoss: 0.006160\n",
            "Train Epoch: 18 [24960/60000 (42%)]\tLoss: 0.029565\n",
            "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 0.003430\n",
            "Train Epoch: 18 [26240/60000 (44%)]\tLoss: 0.035448\n",
            "Train Epoch: 18 [26880/60000 (45%)]\tLoss: 0.007708\n",
            "Train Epoch: 18 [27520/60000 (46%)]\tLoss: 0.004964\n",
            "Train Epoch: 18 [28160/60000 (47%)]\tLoss: 0.014197\n",
            "Train Epoch: 18 [28800/60000 (48%)]\tLoss: 0.104846\n",
            "Train Epoch: 18 [29440/60000 (49%)]\tLoss: 0.053756\n",
            "Train Epoch: 18 [30080/60000 (50%)]\tLoss: 0.141401\n",
            "Train Epoch: 18 [30720/60000 (51%)]\tLoss: 0.008310\n",
            "Train Epoch: 18 [31360/60000 (52%)]\tLoss: 0.025127\n",
            "Train Epoch: 18 [32000/60000 (53%)]\tLoss: 0.022632\n",
            "Train Epoch: 18 [32640/60000 (54%)]\tLoss: 0.030982\n",
            "Train Epoch: 18 [33280/60000 (55%)]\tLoss: 0.013976\n",
            "Train Epoch: 18 [33920/60000 (57%)]\tLoss: 0.076584\n",
            "Train Epoch: 18 [34560/60000 (58%)]\tLoss: 0.054737\n",
            "Train Epoch: 18 [35200/60000 (59%)]\tLoss: 0.007048\n",
            "Train Epoch: 18 [35840/60000 (60%)]\tLoss: 0.000515\n",
            "Train Epoch: 18 [36480/60000 (61%)]\tLoss: 0.031609\n",
            "Train Epoch: 18 [37120/60000 (62%)]\tLoss: 0.010443\n",
            "Train Epoch: 18 [37760/60000 (63%)]\tLoss: 0.001623\n",
            "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 0.017316\n",
            "Train Epoch: 18 [39040/60000 (65%)]\tLoss: 0.076795\n",
            "Train Epoch: 18 [39680/60000 (66%)]\tLoss: 0.327290\n",
            "Train Epoch: 18 [40320/60000 (67%)]\tLoss: 0.014820\n",
            "Train Epoch: 18 [40960/60000 (68%)]\tLoss: 0.028780\n",
            "Train Epoch: 18 [41600/60000 (69%)]\tLoss: 0.115361\n",
            "Train Epoch: 18 [42240/60000 (70%)]\tLoss: 0.010662\n",
            "Train Epoch: 18 [42880/60000 (71%)]\tLoss: 0.052913\n",
            "Train Epoch: 18 [43520/60000 (72%)]\tLoss: 0.135938\n",
            "Train Epoch: 18 [44160/60000 (74%)]\tLoss: 0.075102\n",
            "Train Epoch: 18 [44800/60000 (75%)]\tLoss: 0.010650\n",
            "Train Epoch: 18 [45440/60000 (76%)]\tLoss: 0.059321\n",
            "Train Epoch: 18 [46080/60000 (77%)]\tLoss: 0.059408\n",
            "Train Epoch: 18 [46720/60000 (78%)]\tLoss: 0.007322\n",
            "Train Epoch: 18 [47360/60000 (79%)]\tLoss: 0.001787\n",
            "Train Epoch: 18 [48000/60000 (80%)]\tLoss: 0.045828\n",
            "Train Epoch: 18 [48640/60000 (81%)]\tLoss: 0.071067\n",
            "Train Epoch: 18 [49280/60000 (82%)]\tLoss: 0.047847\n",
            "Train Epoch: 18 [49920/60000 (83%)]\tLoss: 0.010235\n",
            "Train Epoch: 18 [50560/60000 (84%)]\tLoss: 0.026978\n",
            "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 0.002726\n",
            "Train Epoch: 18 [51840/60000 (86%)]\tLoss: 0.013132\n",
            "Train Epoch: 18 [52480/60000 (87%)]\tLoss: 0.002773\n",
            "Train Epoch: 18 [53120/60000 (88%)]\tLoss: 0.111635\n",
            "Train Epoch: 18 [53760/60000 (90%)]\tLoss: 0.071230\n",
            "Train Epoch: 18 [54400/60000 (91%)]\tLoss: 0.016501\n",
            "Train Epoch: 18 [55040/60000 (92%)]\tLoss: 0.009564\n",
            "Train Epoch: 18 [55680/60000 (93%)]\tLoss: 0.046711\n",
            "Train Epoch: 18 [56320/60000 (94%)]\tLoss: 0.005668\n",
            "Train Epoch: 18 [56960/60000 (95%)]\tLoss: 0.000999\n",
            "Train Epoch: 18 [57600/60000 (96%)]\tLoss: 0.030167\n",
            "Train Epoch: 18 [58240/60000 (97%)]\tLoss: 0.017236\n",
            "Train Epoch: 18 [58880/60000 (98%)]\tLoss: 0.139148\n",
            "Train Epoch: 18 [59520/60000 (99%)]\tLoss: 0.015125\n",
            "\n",
            "Test set: Average loss: 0.0135, Accuracy: 9964/10000 (100%)\n",
            "\n",
            "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.022987\n",
            "Train Epoch: 19 [640/60000 (1%)]\tLoss: 0.088024\n",
            "Train Epoch: 19 [1280/60000 (2%)]\tLoss: 0.043548\n",
            "Train Epoch: 19 [1920/60000 (3%)]\tLoss: 0.148913\n",
            "Train Epoch: 19 [2560/60000 (4%)]\tLoss: 0.002717\n",
            "Train Epoch: 19 [3200/60000 (5%)]\tLoss: 0.003337\n",
            "Train Epoch: 19 [3840/60000 (6%)]\tLoss: 0.107263\n",
            "Train Epoch: 19 [4480/60000 (7%)]\tLoss: 0.013061\n",
            "Train Epoch: 19 [5120/60000 (9%)]\tLoss: 0.090596\n",
            "Train Epoch: 19 [5760/60000 (10%)]\tLoss: 0.207294\n",
            "Train Epoch: 19 [6400/60000 (11%)]\tLoss: 0.124792\n",
            "Train Epoch: 19 [7040/60000 (12%)]\tLoss: 0.074073\n",
            "Train Epoch: 19 [7680/60000 (13%)]\tLoss: 0.000863\n",
            "Train Epoch: 19 [8320/60000 (14%)]\tLoss: 0.060509\n",
            "Train Epoch: 19 [8960/60000 (15%)]\tLoss: 0.004693\n",
            "Train Epoch: 19 [9600/60000 (16%)]\tLoss: 0.137373\n",
            "Train Epoch: 19 [10240/60000 (17%)]\tLoss: 0.013275\n",
            "Train Epoch: 19 [10880/60000 (18%)]\tLoss: 0.000834\n",
            "Train Epoch: 19 [11520/60000 (19%)]\tLoss: 0.019782\n",
            "Train Epoch: 19 [12160/60000 (20%)]\tLoss: 0.000880\n",
            "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 0.001034\n",
            "Train Epoch: 19 [13440/60000 (22%)]\tLoss: 0.118043\n",
            "Train Epoch: 19 [14080/60000 (23%)]\tLoss: 0.001087\n",
            "Train Epoch: 19 [14720/60000 (25%)]\tLoss: 0.087688\n",
            "Train Epoch: 19 [15360/60000 (26%)]\tLoss: 0.005619\n",
            "Train Epoch: 19 [16000/60000 (27%)]\tLoss: 0.012146\n",
            "Train Epoch: 19 [16640/60000 (28%)]\tLoss: 0.015456\n",
            "Train Epoch: 19 [17280/60000 (29%)]\tLoss: 0.067191\n",
            "Train Epoch: 19 [17920/60000 (30%)]\tLoss: 0.004987\n",
            "Train Epoch: 19 [18560/60000 (31%)]\tLoss: 0.006397\n",
            "Train Epoch: 19 [19200/60000 (32%)]\tLoss: 0.011256\n",
            "Train Epoch: 19 [19840/60000 (33%)]\tLoss: 0.001189\n",
            "Train Epoch: 19 [20480/60000 (34%)]\tLoss: 0.014448\n",
            "Train Epoch: 19 [21120/60000 (35%)]\tLoss: 0.014786\n",
            "Train Epoch: 19 [21760/60000 (36%)]\tLoss: 0.037587\n",
            "Train Epoch: 19 [22400/60000 (37%)]\tLoss: 0.010576\n",
            "Train Epoch: 19 [23040/60000 (38%)]\tLoss: 0.048321\n",
            "Train Epoch: 19 [23680/60000 (39%)]\tLoss: 0.009988\n",
            "Train Epoch: 19 [24320/60000 (41%)]\tLoss: 0.002167\n",
            "Train Epoch: 19 [24960/60000 (42%)]\tLoss: 0.001475\n",
            "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 0.005553\n",
            "Train Epoch: 19 [26240/60000 (44%)]\tLoss: 0.000398\n",
            "Train Epoch: 19 [26880/60000 (45%)]\tLoss: 0.200291\n",
            "Train Epoch: 19 [27520/60000 (46%)]\tLoss: 0.001571\n",
            "Train Epoch: 19 [28160/60000 (47%)]\tLoss: 0.002268\n",
            "Train Epoch: 19 [28800/60000 (48%)]\tLoss: 0.000922\n",
            "Train Epoch: 19 [29440/60000 (49%)]\tLoss: 0.132104\n",
            "Train Epoch: 19 [30080/60000 (50%)]\tLoss: 0.120689\n",
            "Train Epoch: 19 [30720/60000 (51%)]\tLoss: 0.020770\n",
            "Train Epoch: 19 [31360/60000 (52%)]\tLoss: 0.011220\n",
            "Train Epoch: 19 [32000/60000 (53%)]\tLoss: 0.023819\n",
            "Train Epoch: 19 [32640/60000 (54%)]\tLoss: 0.060681\n",
            "Train Epoch: 19 [33280/60000 (55%)]\tLoss: 0.002204\n",
            "Train Epoch: 19 [33920/60000 (57%)]\tLoss: 0.018326\n",
            "Train Epoch: 19 [34560/60000 (58%)]\tLoss: 0.107855\n",
            "Train Epoch: 19 [35200/60000 (59%)]\tLoss: 0.002337\n",
            "Train Epoch: 19 [35840/60000 (60%)]\tLoss: 0.024174\n",
            "Train Epoch: 19 [36480/60000 (61%)]\tLoss: 0.005342\n",
            "Train Epoch: 19 [37120/60000 (62%)]\tLoss: 0.027203\n",
            "Train Epoch: 19 [37760/60000 (63%)]\tLoss: 0.004355\n",
            "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 0.002591\n",
            "Train Epoch: 19 [39040/60000 (65%)]\tLoss: 0.007362\n",
            "Train Epoch: 19 [39680/60000 (66%)]\tLoss: 0.087423\n",
            "Train Epoch: 19 [40320/60000 (67%)]\tLoss: 0.002110\n",
            "Train Epoch: 19 [40960/60000 (68%)]\tLoss: 0.103295\n",
            "Train Epoch: 19 [41600/60000 (69%)]\tLoss: 0.053289\n",
            "Train Epoch: 19 [42240/60000 (70%)]\tLoss: 0.083714\n",
            "Train Epoch: 19 [42880/60000 (71%)]\tLoss: 0.163541\n",
            "Train Epoch: 19 [43520/60000 (72%)]\tLoss: 0.003608\n",
            "Train Epoch: 19 [44160/60000 (74%)]\tLoss: 0.099700\n",
            "Train Epoch: 19 [44800/60000 (75%)]\tLoss: 0.005968\n",
            "Train Epoch: 19 [45440/60000 (76%)]\tLoss: 0.003861\n",
            "Train Epoch: 19 [46080/60000 (77%)]\tLoss: 0.004093\n",
            "Train Epoch: 19 [46720/60000 (78%)]\tLoss: 0.004521\n",
            "Train Epoch: 19 [47360/60000 (79%)]\tLoss: 0.001947\n",
            "Train Epoch: 19 [48000/60000 (80%)]\tLoss: 0.069262\n",
            "Train Epoch: 19 [48640/60000 (81%)]\tLoss: 0.047690\n",
            "Train Epoch: 19 [49280/60000 (82%)]\tLoss: 0.012700\n",
            "Train Epoch: 19 [49920/60000 (83%)]\tLoss: 0.071061\n",
            "Train Epoch: 19 [50560/60000 (84%)]\tLoss: 0.004340\n",
            "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 0.032264\n",
            "Train Epoch: 19 [51840/60000 (86%)]\tLoss: 0.006818\n",
            "Train Epoch: 19 [52480/60000 (87%)]\tLoss: 0.163541\n",
            "Train Epoch: 19 [53120/60000 (88%)]\tLoss: 0.011304\n",
            "Train Epoch: 19 [53760/60000 (90%)]\tLoss: 0.017018\n",
            "Train Epoch: 19 [54400/60000 (91%)]\tLoss: 0.018840\n",
            "Train Epoch: 19 [55040/60000 (92%)]\tLoss: 0.005190\n",
            "Train Epoch: 19 [55680/60000 (93%)]\tLoss: 0.073516\n",
            "Train Epoch: 19 [56320/60000 (94%)]\tLoss: 0.044146\n",
            "Train Epoch: 19 [56960/60000 (95%)]\tLoss: 0.091467\n",
            "Train Epoch: 19 [57600/60000 (96%)]\tLoss: 0.012859\n",
            "Train Epoch: 19 [58240/60000 (97%)]\tLoss: 0.006137\n",
            "Train Epoch: 19 [58880/60000 (98%)]\tLoss: 0.008770\n",
            "Train Epoch: 19 [59520/60000 (99%)]\tLoss: 0.008018\n",
            "\n",
            "Test set: Average loss: 0.0138, Accuracy: 9961/10000 (100%)\n",
            "\n",
            "Train Epoch: 20 [0/60000 (0%)]\tLoss: 0.019451\n",
            "Train Epoch: 20 [640/60000 (1%)]\tLoss: 0.115158\n",
            "Train Epoch: 20 [1280/60000 (2%)]\tLoss: 0.032351\n",
            "Train Epoch: 20 [1920/60000 (3%)]\tLoss: 0.013587\n",
            "Train Epoch: 20 [2560/60000 (4%)]\tLoss: 0.023934\n",
            "Train Epoch: 20 [3200/60000 (5%)]\tLoss: 0.165991\n",
            "Train Epoch: 20 [3840/60000 (6%)]\tLoss: 0.102245\n",
            "Train Epoch: 20 [4480/60000 (7%)]\tLoss: 0.038949\n",
            "Train Epoch: 20 [5120/60000 (9%)]\tLoss: 0.030811\n",
            "Train Epoch: 20 [5760/60000 (10%)]\tLoss: 0.026529\n",
            "Train Epoch: 20 [6400/60000 (11%)]\tLoss: 0.003431\n",
            "Train Epoch: 20 [7040/60000 (12%)]\tLoss: 0.000387\n",
            "Train Epoch: 20 [7680/60000 (13%)]\tLoss: 0.011554\n",
            "Train Epoch: 20 [8320/60000 (14%)]\tLoss: 0.001334\n",
            "Train Epoch: 20 [8960/60000 (15%)]\tLoss: 0.154078\n",
            "Train Epoch: 20 [9600/60000 (16%)]\tLoss: 0.036922\n",
            "Train Epoch: 20 [10240/60000 (17%)]\tLoss: 0.040392\n",
            "Train Epoch: 20 [10880/60000 (18%)]\tLoss: 0.002794\n",
            "Train Epoch: 20 [11520/60000 (19%)]\tLoss: 0.068453\n",
            "Train Epoch: 20 [12160/60000 (20%)]\tLoss: 0.009745\n",
            "Train Epoch: 20 [12800/60000 (21%)]\tLoss: 0.016837\n",
            "Train Epoch: 20 [13440/60000 (22%)]\tLoss: 0.017984\n",
            "Train Epoch: 20 [14080/60000 (23%)]\tLoss: 0.004481\n",
            "Train Epoch: 20 [14720/60000 (25%)]\tLoss: 0.000785\n",
            "Train Epoch: 20 [15360/60000 (26%)]\tLoss: 0.079692\n",
            "Train Epoch: 20 [16000/60000 (27%)]\tLoss: 0.058849\n",
            "Train Epoch: 20 [16640/60000 (28%)]\tLoss: 0.021477\n",
            "Train Epoch: 20 [17280/60000 (29%)]\tLoss: 0.002221\n",
            "Train Epoch: 20 [17920/60000 (30%)]\tLoss: 0.004116\n",
            "Train Epoch: 20 [18560/60000 (31%)]\tLoss: 0.009359\n",
            "Train Epoch: 20 [19200/60000 (32%)]\tLoss: 0.007330\n",
            "Train Epoch: 20 [19840/60000 (33%)]\tLoss: 0.011685\n",
            "Train Epoch: 20 [20480/60000 (34%)]\tLoss: 0.018551\n",
            "Train Epoch: 20 [21120/60000 (35%)]\tLoss: 0.026611\n",
            "Train Epoch: 20 [21760/60000 (36%)]\tLoss: 0.006572\n",
            "Train Epoch: 20 [22400/60000 (37%)]\tLoss: 0.040448\n",
            "Train Epoch: 20 [23040/60000 (38%)]\tLoss: 0.049938\n",
            "Train Epoch: 20 [23680/60000 (39%)]\tLoss: 0.005433\n",
            "Train Epoch: 20 [24320/60000 (41%)]\tLoss: 0.002099\n",
            "Train Epoch: 20 [24960/60000 (42%)]\tLoss: 0.017201\n",
            "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 0.054480\n",
            "Train Epoch: 20 [26240/60000 (44%)]\tLoss: 0.007736\n",
            "Train Epoch: 20 [26880/60000 (45%)]\tLoss: 0.020539\n",
            "Train Epoch: 20 [27520/60000 (46%)]\tLoss: 0.044240\n",
            "Train Epoch: 20 [28160/60000 (47%)]\tLoss: 0.148817\n",
            "Train Epoch: 20 [28800/60000 (48%)]\tLoss: 0.038993\n",
            "Train Epoch: 20 [29440/60000 (49%)]\tLoss: 0.038847\n",
            "Train Epoch: 20 [30080/60000 (50%)]\tLoss: 0.084168\n",
            "Train Epoch: 20 [30720/60000 (51%)]\tLoss: 0.048120\n",
            "Train Epoch: 20 [31360/60000 (52%)]\tLoss: 0.051990\n",
            "Train Epoch: 20 [32000/60000 (53%)]\tLoss: 0.055236\n",
            "Train Epoch: 20 [32640/60000 (54%)]\tLoss: 0.010744\n",
            "Train Epoch: 20 [33280/60000 (55%)]\tLoss: 0.000570\n",
            "Train Epoch: 20 [33920/60000 (57%)]\tLoss: 0.004495\n",
            "Train Epoch: 20 [34560/60000 (58%)]\tLoss: 0.014477\n",
            "Train Epoch: 20 [35200/60000 (59%)]\tLoss: 0.005272\n",
            "Train Epoch: 20 [35840/60000 (60%)]\tLoss: 0.045814\n",
            "Train Epoch: 20 [36480/60000 (61%)]\tLoss: 0.000551\n",
            "Train Epoch: 20 [37120/60000 (62%)]\tLoss: 0.003306\n",
            "Train Epoch: 20 [37760/60000 (63%)]\tLoss: 0.009982\n",
            "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 0.074669\n",
            "Train Epoch: 20 [39040/60000 (65%)]\tLoss: 0.013988\n",
            "Train Epoch: 20 [39680/60000 (66%)]\tLoss: 0.040455\n",
            "Train Epoch: 20 [40320/60000 (67%)]\tLoss: 0.006881\n",
            "Train Epoch: 20 [40960/60000 (68%)]\tLoss: 0.000758\n",
            "Train Epoch: 20 [41600/60000 (69%)]\tLoss: 0.113427\n",
            "Train Epoch: 20 [42240/60000 (70%)]\tLoss: 0.032112\n",
            "Train Epoch: 20 [42880/60000 (71%)]\tLoss: 0.012941\n",
            "Train Epoch: 20 [43520/60000 (72%)]\tLoss: 0.113695\n",
            "Train Epoch: 20 [44160/60000 (74%)]\tLoss: 0.002253\n",
            "Train Epoch: 20 [44800/60000 (75%)]\tLoss: 0.009767\n",
            "Train Epoch: 20 [45440/60000 (76%)]\tLoss: 0.063582\n",
            "Train Epoch: 20 [46080/60000 (77%)]\tLoss: 0.009590\n",
            "Train Epoch: 20 [46720/60000 (78%)]\tLoss: 0.031255\n",
            "Train Epoch: 20 [47360/60000 (79%)]\tLoss: 0.002377\n",
            "Train Epoch: 20 [48000/60000 (80%)]\tLoss: 0.010162\n",
            "Train Epoch: 20 [48640/60000 (81%)]\tLoss: 0.024568\n",
            "Train Epoch: 20 [49280/60000 (82%)]\tLoss: 0.007489\n",
            "Train Epoch: 20 [49920/60000 (83%)]\tLoss: 0.032393\n",
            "Train Epoch: 20 [50560/60000 (84%)]\tLoss: 0.107777\n",
            "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 0.002850\n",
            "Train Epoch: 20 [51840/60000 (86%)]\tLoss: 0.004304\n",
            "Train Epoch: 20 [52480/60000 (87%)]\tLoss: 0.069317\n",
            "Train Epoch: 20 [53120/60000 (88%)]\tLoss: 0.006685\n",
            "Train Epoch: 20 [53760/60000 (90%)]\tLoss: 0.125463\n",
            "Train Epoch: 20 [54400/60000 (91%)]\tLoss: 0.013141\n",
            "Train Epoch: 20 [55040/60000 (92%)]\tLoss: 0.037028\n",
            "Train Epoch: 20 [55680/60000 (93%)]\tLoss: 0.000261\n",
            "Train Epoch: 20 [56320/60000 (94%)]\tLoss: 0.052700\n",
            "Train Epoch: 20 [56960/60000 (95%)]\tLoss: 0.000951\n",
            "Train Epoch: 20 [57600/60000 (96%)]\tLoss: 0.023951\n",
            "Train Epoch: 20 [58240/60000 (97%)]\tLoss: 0.017891\n",
            "Train Epoch: 20 [58880/60000 (98%)]\tLoss: 0.030965\n",
            "Train Epoch: 20 [59520/60000 (99%)]\tLoss: 0.027197\n",
            "\n",
            "Test set: Average loss: 0.0132, Accuracy: 9960/10000 (100%)\n",
            "\n",
            "Train Epoch: 21 [0/60000 (0%)]\tLoss: 0.008992\n",
            "Train Epoch: 21 [640/60000 (1%)]\tLoss: 0.005973\n",
            "Train Epoch: 21 [1280/60000 (2%)]\tLoss: 0.010226\n",
            "Train Epoch: 21 [1920/60000 (3%)]\tLoss: 0.068830\n",
            "Train Epoch: 21 [2560/60000 (4%)]\tLoss: 0.000652\n",
            "Train Epoch: 21 [3200/60000 (5%)]\tLoss: 0.013507\n",
            "Train Epoch: 21 [3840/60000 (6%)]\tLoss: 0.022465\n",
            "Train Epoch: 21 [4480/60000 (7%)]\tLoss: 0.026205\n",
            "Train Epoch: 21 [5120/60000 (9%)]\tLoss: 0.050102\n",
            "Train Epoch: 21 [5760/60000 (10%)]\tLoss: 0.008040\n",
            "Train Epoch: 21 [6400/60000 (11%)]\tLoss: 0.196331\n",
            "Train Epoch: 21 [7040/60000 (12%)]\tLoss: 0.004307\n",
            "Train Epoch: 21 [7680/60000 (13%)]\tLoss: 0.008904\n",
            "Train Epoch: 21 [8320/60000 (14%)]\tLoss: 0.011184\n",
            "Train Epoch: 21 [8960/60000 (15%)]\tLoss: 0.163563\n",
            "Train Epoch: 21 [9600/60000 (16%)]\tLoss: 0.018068\n",
            "Train Epoch: 21 [10240/60000 (17%)]\tLoss: 0.038170\n",
            "Train Epoch: 21 [10880/60000 (18%)]\tLoss: 0.007824\n",
            "Train Epoch: 21 [11520/60000 (19%)]\tLoss: 0.000675\n",
            "Train Epoch: 21 [12160/60000 (20%)]\tLoss: 0.007790\n",
            "Train Epoch: 21 [12800/60000 (21%)]\tLoss: 0.003329\n",
            "Train Epoch: 21 [13440/60000 (22%)]\tLoss: 0.002503\n",
            "Train Epoch: 21 [14080/60000 (23%)]\tLoss: 0.005300\n",
            "Train Epoch: 21 [14720/60000 (25%)]\tLoss: 0.000461\n",
            "Train Epoch: 21 [15360/60000 (26%)]\tLoss: 0.001325\n",
            "Train Epoch: 21 [16000/60000 (27%)]\tLoss: 0.009554\n",
            "Train Epoch: 21 [16640/60000 (28%)]\tLoss: 0.010860\n",
            "Train Epoch: 21 [17280/60000 (29%)]\tLoss: 0.287462\n",
            "Train Epoch: 21 [17920/60000 (30%)]\tLoss: 0.037292\n",
            "Train Epoch: 21 [18560/60000 (31%)]\tLoss: 0.009907\n",
            "Train Epoch: 21 [19200/60000 (32%)]\tLoss: 0.036502\n",
            "Train Epoch: 21 [19840/60000 (33%)]\tLoss: 0.000351\n",
            "Train Epoch: 21 [20480/60000 (34%)]\tLoss: 0.023005\n",
            "Train Epoch: 21 [21120/60000 (35%)]\tLoss: 0.125422\n",
            "Train Epoch: 21 [21760/60000 (36%)]\tLoss: 0.000463\n",
            "Train Epoch: 21 [22400/60000 (37%)]\tLoss: 0.049312\n",
            "Train Epoch: 21 [23040/60000 (38%)]\tLoss: 0.001594\n",
            "Train Epoch: 21 [23680/60000 (39%)]\tLoss: 0.005906\n",
            "Train Epoch: 21 [24320/60000 (41%)]\tLoss: 0.142076\n",
            "Train Epoch: 21 [24960/60000 (42%)]\tLoss: 0.036556\n",
            "Train Epoch: 21 [25600/60000 (43%)]\tLoss: 0.004656\n",
            "Train Epoch: 21 [26240/60000 (44%)]\tLoss: 0.005548\n",
            "Train Epoch: 21 [26880/60000 (45%)]\tLoss: 0.002203\n",
            "Train Epoch: 21 [27520/60000 (46%)]\tLoss: 0.000895\n",
            "Train Epoch: 21 [28160/60000 (47%)]\tLoss: 0.359195\n",
            "Train Epoch: 21 [28800/60000 (48%)]\tLoss: 0.003420\n",
            "Train Epoch: 21 [29440/60000 (49%)]\tLoss: 0.049914\n",
            "Train Epoch: 21 [30080/60000 (50%)]\tLoss: 0.004578\n",
            "Train Epoch: 21 [30720/60000 (51%)]\tLoss: 0.003275\n",
            "Train Epoch: 21 [31360/60000 (52%)]\tLoss: 0.038699\n",
            "Train Epoch: 21 [32000/60000 (53%)]\tLoss: 0.102086\n",
            "Train Epoch: 21 [32640/60000 (54%)]\tLoss: 0.047355\n",
            "Train Epoch: 21 [33280/60000 (55%)]\tLoss: 0.007030\n",
            "Train Epoch: 21 [33920/60000 (57%)]\tLoss: 0.001424\n",
            "Train Epoch: 21 [34560/60000 (58%)]\tLoss: 0.020523\n",
            "Train Epoch: 21 [35200/60000 (59%)]\tLoss: 0.003369\n",
            "Train Epoch: 21 [35840/60000 (60%)]\tLoss: 0.112279\n",
            "Train Epoch: 21 [36480/60000 (61%)]\tLoss: 0.076542\n",
            "Train Epoch: 21 [37120/60000 (62%)]\tLoss: 0.017859\n",
            "Train Epoch: 21 [37760/60000 (63%)]\tLoss: 0.060763\n",
            "Train Epoch: 21 [38400/60000 (64%)]\tLoss: 0.003170\n",
            "Train Epoch: 21 [39040/60000 (65%)]\tLoss: 0.118343\n",
            "Train Epoch: 21 [39680/60000 (66%)]\tLoss: 0.000519\n",
            "Train Epoch: 21 [40320/60000 (67%)]\tLoss: 0.016744\n",
            "Train Epoch: 21 [40960/60000 (68%)]\tLoss: 0.032486\n",
            "Train Epoch: 21 [41600/60000 (69%)]\tLoss: 0.001017\n",
            "Train Epoch: 21 [42240/60000 (70%)]\tLoss: 0.026046\n",
            "Train Epoch: 21 [42880/60000 (71%)]\tLoss: 0.006688\n",
            "Train Epoch: 21 [43520/60000 (72%)]\tLoss: 0.050833\n",
            "Train Epoch: 21 [44160/60000 (74%)]\tLoss: 0.083416\n",
            "Train Epoch: 21 [44800/60000 (75%)]\tLoss: 0.000948\n",
            "Train Epoch: 21 [45440/60000 (76%)]\tLoss: 0.003583\n",
            "Train Epoch: 21 [46080/60000 (77%)]\tLoss: 0.105780\n",
            "Train Epoch: 21 [46720/60000 (78%)]\tLoss: 0.000736\n",
            "Train Epoch: 21 [47360/60000 (79%)]\tLoss: 0.002781\n",
            "Train Epoch: 21 [48000/60000 (80%)]\tLoss: 0.001881\n",
            "Train Epoch: 21 [48640/60000 (81%)]\tLoss: 0.006639\n",
            "Train Epoch: 21 [49280/60000 (82%)]\tLoss: 0.018856\n",
            "Train Epoch: 21 [49920/60000 (83%)]\tLoss: 0.005969\n",
            "Train Epoch: 21 [50560/60000 (84%)]\tLoss: 0.002818\n",
            "Train Epoch: 21 [51200/60000 (85%)]\tLoss: 0.081645\n",
            "Train Epoch: 21 [51840/60000 (86%)]\tLoss: 0.001425\n",
            "Train Epoch: 21 [52480/60000 (87%)]\tLoss: 0.007879\n",
            "Train Epoch: 21 [53120/60000 (88%)]\tLoss: 0.188007\n",
            "Train Epoch: 21 [53760/60000 (90%)]\tLoss: 0.000749\n",
            "Train Epoch: 21 [54400/60000 (91%)]\tLoss: 0.012479\n",
            "Train Epoch: 21 [55040/60000 (92%)]\tLoss: 0.008929\n",
            "Train Epoch: 21 [55680/60000 (93%)]\tLoss: 0.002807\n",
            "Train Epoch: 21 [56320/60000 (94%)]\tLoss: 0.026401\n",
            "Train Epoch: 21 [56960/60000 (95%)]\tLoss: 0.047056\n",
            "Train Epoch: 21 [57600/60000 (96%)]\tLoss: 0.035920\n",
            "Train Epoch: 21 [58240/60000 (97%)]\tLoss: 0.006000\n",
            "Train Epoch: 21 [58880/60000 (98%)]\tLoss: 0.053569\n",
            "Train Epoch: 21 [59520/60000 (99%)]\tLoss: 0.091711\n",
            "\n",
            "Test set: Average loss: 0.0129, Accuracy: 9962/10000 (100%)\n",
            "\n",
            "Model saved with new best test loss: 0.0129 \n",
            "\n",
            "Train Epoch: 22 [0/60000 (0%)]\tLoss: 0.052323\n",
            "Train Epoch: 22 [640/60000 (1%)]\tLoss: 0.007797\n",
            "Train Epoch: 22 [1280/60000 (2%)]\tLoss: 0.016419\n",
            "Train Epoch: 22 [1920/60000 (3%)]\tLoss: 0.048939\n",
            "Train Epoch: 22 [2560/60000 (4%)]\tLoss: 0.112968\n",
            "Train Epoch: 22 [3200/60000 (5%)]\tLoss: 0.000372\n",
            "Train Epoch: 22 [3840/60000 (6%)]\tLoss: 0.123412\n",
            "Train Epoch: 22 [4480/60000 (7%)]\tLoss: 0.002370\n",
            "Train Epoch: 22 [5120/60000 (9%)]\tLoss: 0.066910\n",
            "Train Epoch: 22 [5760/60000 (10%)]\tLoss: 0.150968\n",
            "Train Epoch: 22 [6400/60000 (11%)]\tLoss: 0.015683\n",
            "Train Epoch: 22 [7040/60000 (12%)]\tLoss: 0.003831\n",
            "Train Epoch: 22 [7680/60000 (13%)]\tLoss: 0.055484\n",
            "Train Epoch: 22 [8320/60000 (14%)]\tLoss: 0.036820\n",
            "Train Epoch: 22 [8960/60000 (15%)]\tLoss: 0.067406\n",
            "Train Epoch: 22 [9600/60000 (16%)]\tLoss: 0.037691\n",
            "Train Epoch: 22 [10240/60000 (17%)]\tLoss: 0.179520\n",
            "Train Epoch: 22 [10880/60000 (18%)]\tLoss: 0.003520\n",
            "Train Epoch: 22 [11520/60000 (19%)]\tLoss: 0.250882\n",
            "Train Epoch: 22 [12160/60000 (20%)]\tLoss: 0.014979\n",
            "Train Epoch: 22 [12800/60000 (21%)]\tLoss: 0.048144\n",
            "Train Epoch: 22 [13440/60000 (22%)]\tLoss: 0.004269\n",
            "Train Epoch: 22 [14080/60000 (23%)]\tLoss: 0.002991\n",
            "Train Epoch: 22 [14720/60000 (25%)]\tLoss: 0.020103\n",
            "Train Epoch: 22 [15360/60000 (26%)]\tLoss: 0.040060\n",
            "Train Epoch: 22 [16000/60000 (27%)]\tLoss: 0.013667\n",
            "Train Epoch: 22 [16640/60000 (28%)]\tLoss: 0.012363\n",
            "Train Epoch: 22 [17280/60000 (29%)]\tLoss: 0.062628\n",
            "Train Epoch: 22 [17920/60000 (30%)]\tLoss: 0.037769\n",
            "Train Epoch: 22 [18560/60000 (31%)]\tLoss: 0.012351\n",
            "Train Epoch: 22 [19200/60000 (32%)]\tLoss: 0.111982\n",
            "Train Epoch: 22 [19840/60000 (33%)]\tLoss: 0.018276\n",
            "Train Epoch: 22 [20480/60000 (34%)]\tLoss: 0.183228\n",
            "Train Epoch: 22 [21120/60000 (35%)]\tLoss: 0.104314\n",
            "Train Epoch: 22 [21760/60000 (36%)]\tLoss: 0.029280\n",
            "Train Epoch: 22 [22400/60000 (37%)]\tLoss: 0.033509\n",
            "Train Epoch: 22 [23040/60000 (38%)]\tLoss: 0.016869\n",
            "Train Epoch: 22 [23680/60000 (39%)]\tLoss: 0.022390\n",
            "Train Epoch: 22 [24320/60000 (41%)]\tLoss: 0.134929\n",
            "Train Epoch: 22 [24960/60000 (42%)]\tLoss: 0.024913\n",
            "Train Epoch: 22 [25600/60000 (43%)]\tLoss: 0.004400\n",
            "Train Epoch: 22 [26240/60000 (44%)]\tLoss: 0.023207\n",
            "Train Epoch: 22 [26880/60000 (45%)]\tLoss: 0.005961\n",
            "Train Epoch: 22 [27520/60000 (46%)]\tLoss: 0.028668\n",
            "Train Epoch: 22 [28160/60000 (47%)]\tLoss: 0.024389\n",
            "Train Epoch: 22 [28800/60000 (48%)]\tLoss: 0.001308\n",
            "Train Epoch: 22 [29440/60000 (49%)]\tLoss: 0.000471\n",
            "Train Epoch: 22 [30080/60000 (50%)]\tLoss: 0.009342\n",
            "Train Epoch: 22 [30720/60000 (51%)]\tLoss: 0.017130\n",
            "Train Epoch: 22 [31360/60000 (52%)]\tLoss: 0.001160\n",
            "Train Epoch: 22 [32000/60000 (53%)]\tLoss: 0.011858\n",
            "Train Epoch: 22 [32640/60000 (54%)]\tLoss: 0.060994\n",
            "Train Epoch: 22 [33280/60000 (55%)]\tLoss: 0.015068\n",
            "Train Epoch: 22 [33920/60000 (57%)]\tLoss: 0.002309\n",
            "Train Epoch: 22 [34560/60000 (58%)]\tLoss: 0.017046\n",
            "Train Epoch: 22 [35200/60000 (59%)]\tLoss: 0.078718\n",
            "Train Epoch: 22 [35840/60000 (60%)]\tLoss: 0.010441\n",
            "Train Epoch: 22 [36480/60000 (61%)]\tLoss: 0.029016\n",
            "Train Epoch: 22 [37120/60000 (62%)]\tLoss: 0.131367\n",
            "Train Epoch: 22 [37760/60000 (63%)]\tLoss: 0.059935\n",
            "Train Epoch: 22 [38400/60000 (64%)]\tLoss: 0.007812\n",
            "Train Epoch: 22 [39040/60000 (65%)]\tLoss: 0.145560\n",
            "Train Epoch: 22 [39680/60000 (66%)]\tLoss: 0.004732\n",
            "Train Epoch: 22 [40320/60000 (67%)]\tLoss: 0.003524\n",
            "Train Epoch: 22 [40960/60000 (68%)]\tLoss: 0.037885\n",
            "Train Epoch: 22 [41600/60000 (69%)]\tLoss: 0.015877\n",
            "Train Epoch: 22 [42240/60000 (70%)]\tLoss: 0.011737\n",
            "Train Epoch: 22 [42880/60000 (71%)]\tLoss: 0.001230\n",
            "Train Epoch: 22 [43520/60000 (72%)]\tLoss: 0.005820\n",
            "Train Epoch: 22 [44160/60000 (74%)]\tLoss: 0.042200\n",
            "Train Epoch: 22 [44800/60000 (75%)]\tLoss: 0.041513\n",
            "Train Epoch: 22 [45440/60000 (76%)]\tLoss: 0.016703\n",
            "Train Epoch: 22 [46080/60000 (77%)]\tLoss: 0.003147\n",
            "Train Epoch: 22 [46720/60000 (78%)]\tLoss: 0.001035\n",
            "Train Epoch: 22 [47360/60000 (79%)]\tLoss: 0.006461\n",
            "Train Epoch: 22 [48000/60000 (80%)]\tLoss: 0.118932\n",
            "Train Epoch: 22 [48640/60000 (81%)]\tLoss: 0.056641\n",
            "Train Epoch: 22 [49280/60000 (82%)]\tLoss: 0.029310\n",
            "Train Epoch: 22 [49920/60000 (83%)]\tLoss: 0.010004\n",
            "Train Epoch: 22 [50560/60000 (84%)]\tLoss: 0.066235\n",
            "Train Epoch: 22 [51200/60000 (85%)]\tLoss: 0.000990\n",
            "Train Epoch: 22 [51840/60000 (86%)]\tLoss: 0.006377\n",
            "Train Epoch: 22 [52480/60000 (87%)]\tLoss: 0.019179\n",
            "Train Epoch: 22 [53120/60000 (88%)]\tLoss: 0.016502\n",
            "Train Epoch: 22 [53760/60000 (90%)]\tLoss: 0.066640\n",
            "Train Epoch: 22 [54400/60000 (91%)]\tLoss: 0.104155\n",
            "Train Epoch: 22 [55040/60000 (92%)]\tLoss: 0.012365\n",
            "Train Epoch: 22 [55680/60000 (93%)]\tLoss: 0.000158\n",
            "Train Epoch: 22 [56320/60000 (94%)]\tLoss: 0.011718\n",
            "Train Epoch: 22 [56960/60000 (95%)]\tLoss: 0.012487\n",
            "Train Epoch: 22 [57600/60000 (96%)]\tLoss: 0.041671\n",
            "Train Epoch: 22 [58240/60000 (97%)]\tLoss: 0.027984\n",
            "Train Epoch: 22 [58880/60000 (98%)]\tLoss: 0.003070\n",
            "Train Epoch: 22 [59520/60000 (99%)]\tLoss: 0.104046\n",
            "\n",
            "Test set: Average loss: 0.0119, Accuracy: 9965/10000 (100%)\n",
            "\n",
            "Model saved with new best test loss: 0.0119 \n",
            "\n",
            "Train Epoch: 23 [0/60000 (0%)]\tLoss: 0.013580\n",
            "Train Epoch: 23 [640/60000 (1%)]\tLoss: 0.046530\n",
            "Train Epoch: 23 [1280/60000 (2%)]\tLoss: 0.019325\n",
            "Train Epoch: 23 [1920/60000 (3%)]\tLoss: 0.009442\n",
            "Train Epoch: 23 [2560/60000 (4%)]\tLoss: 0.008915\n",
            "Train Epoch: 23 [3200/60000 (5%)]\tLoss: 0.000480\n",
            "Train Epoch: 23 [3840/60000 (6%)]\tLoss: 0.002055\n",
            "Train Epoch: 23 [4480/60000 (7%)]\tLoss: 0.020665\n",
            "Train Epoch: 23 [5120/60000 (9%)]\tLoss: 0.037343\n",
            "Train Epoch: 23 [5760/60000 (10%)]\tLoss: 0.001365\n",
            "Train Epoch: 23 [6400/60000 (11%)]\tLoss: 0.006399\n",
            "Train Epoch: 23 [7040/60000 (12%)]\tLoss: 0.001370\n",
            "Train Epoch: 23 [7680/60000 (13%)]\tLoss: 0.011199\n",
            "Train Epoch: 23 [8320/60000 (14%)]\tLoss: 0.002487\n",
            "Train Epoch: 23 [8960/60000 (15%)]\tLoss: 0.074950\n",
            "Train Epoch: 23 [9600/60000 (16%)]\tLoss: 0.084409\n",
            "Train Epoch: 23 [10240/60000 (17%)]\tLoss: 0.005832\n",
            "Train Epoch: 23 [10880/60000 (18%)]\tLoss: 0.004076\n",
            "Train Epoch: 23 [11520/60000 (19%)]\tLoss: 0.041577\n",
            "Train Epoch: 23 [12160/60000 (20%)]\tLoss: 0.013053\n",
            "Train Epoch: 23 [12800/60000 (21%)]\tLoss: 0.008387\n",
            "Train Epoch: 23 [13440/60000 (22%)]\tLoss: 0.003010\n",
            "Train Epoch: 23 [14080/60000 (23%)]\tLoss: 0.103781\n",
            "Train Epoch: 23 [14720/60000 (25%)]\tLoss: 0.022382\n",
            "Train Epoch: 23 [15360/60000 (26%)]\tLoss: 0.038431\n",
            "Train Epoch: 23 [16000/60000 (27%)]\tLoss: 0.002459\n",
            "Train Epoch: 23 [16640/60000 (28%)]\tLoss: 0.021446\n",
            "Train Epoch: 23 [17280/60000 (29%)]\tLoss: 0.012378\n",
            "Train Epoch: 23 [17920/60000 (30%)]\tLoss: 0.055499\n",
            "Train Epoch: 23 [18560/60000 (31%)]\tLoss: 0.007244\n",
            "Train Epoch: 23 [19200/60000 (32%)]\tLoss: 0.013966\n",
            "Train Epoch: 23 [19840/60000 (33%)]\tLoss: 0.009499\n",
            "Train Epoch: 23 [20480/60000 (34%)]\tLoss: 0.004052\n",
            "Train Epoch: 23 [21120/60000 (35%)]\tLoss: 0.084899\n",
            "Train Epoch: 23 [21760/60000 (36%)]\tLoss: 0.005318\n",
            "Train Epoch: 23 [22400/60000 (37%)]\tLoss: 0.059257\n",
            "Train Epoch: 23 [23040/60000 (38%)]\tLoss: 0.041280\n",
            "Train Epoch: 23 [23680/60000 (39%)]\tLoss: 0.017646\n",
            "Train Epoch: 23 [24320/60000 (41%)]\tLoss: 0.009201\n",
            "Train Epoch: 23 [24960/60000 (42%)]\tLoss: 0.002405\n",
            "Train Epoch: 23 [25600/60000 (43%)]\tLoss: 0.002836\n",
            "Train Epoch: 23 [26240/60000 (44%)]\tLoss: 0.009382\n",
            "Train Epoch: 23 [26880/60000 (45%)]\tLoss: 0.007460\n",
            "Train Epoch: 23 [27520/60000 (46%)]\tLoss: 0.003470\n",
            "Train Epoch: 23 [28160/60000 (47%)]\tLoss: 0.097195\n",
            "Train Epoch: 23 [28800/60000 (48%)]\tLoss: 0.021612\n",
            "Train Epoch: 23 [29440/60000 (49%)]\tLoss: 0.019879\n",
            "Train Epoch: 23 [30080/60000 (50%)]\tLoss: 0.003788\n",
            "Train Epoch: 23 [30720/60000 (51%)]\tLoss: 0.007930\n",
            "Train Epoch: 23 [31360/60000 (52%)]\tLoss: 0.001862\n",
            "Train Epoch: 23 [32000/60000 (53%)]\tLoss: 0.000781\n",
            "Train Epoch: 23 [32640/60000 (54%)]\tLoss: 0.047336\n",
            "Train Epoch: 23 [33280/60000 (55%)]\tLoss: 0.054744\n",
            "Train Epoch: 23 [33920/60000 (57%)]\tLoss: 0.197229\n",
            "Train Epoch: 23 [34560/60000 (58%)]\tLoss: 0.037028\n",
            "Train Epoch: 23 [35200/60000 (59%)]\tLoss: 0.004813\n",
            "Train Epoch: 23 [35840/60000 (60%)]\tLoss: 0.021283\n",
            "Train Epoch: 23 [36480/60000 (61%)]\tLoss: 0.028548\n",
            "Train Epoch: 23 [37120/60000 (62%)]\tLoss: 0.031305\n",
            "Train Epoch: 23 [37760/60000 (63%)]\tLoss: 0.004369\n",
            "Train Epoch: 23 [38400/60000 (64%)]\tLoss: 0.002003\n",
            "Train Epoch: 23 [39040/60000 (65%)]\tLoss: 0.012485\n",
            "Train Epoch: 23 [39680/60000 (66%)]\tLoss: 0.004613\n",
            "Train Epoch: 23 [40320/60000 (67%)]\tLoss: 0.021696\n",
            "Train Epoch: 23 [40960/60000 (68%)]\tLoss: 0.135506\n",
            "Train Epoch: 23 [41600/60000 (69%)]\tLoss: 0.016926\n",
            "Train Epoch: 23 [42240/60000 (70%)]\tLoss: 0.069167\n",
            "Train Epoch: 23 [42880/60000 (71%)]\tLoss: 0.007381\n",
            "Train Epoch: 23 [43520/60000 (72%)]\tLoss: 0.002812\n",
            "Train Epoch: 23 [44160/60000 (74%)]\tLoss: 0.009065\n",
            "Train Epoch: 23 [44800/60000 (75%)]\tLoss: 0.089090\n",
            "Train Epoch: 23 [45440/60000 (76%)]\tLoss: 0.037729\n",
            "Train Epoch: 23 [46080/60000 (77%)]\tLoss: 0.157671\n",
            "Train Epoch: 23 [46720/60000 (78%)]\tLoss: 0.038419\n",
            "Train Epoch: 23 [47360/60000 (79%)]\tLoss: 0.006112\n",
            "Train Epoch: 23 [48000/60000 (80%)]\tLoss: 0.016596\n",
            "Train Epoch: 23 [48640/60000 (81%)]\tLoss: 0.002924\n",
            "Train Epoch: 23 [49280/60000 (82%)]\tLoss: 0.108058\n",
            "Train Epoch: 23 [49920/60000 (83%)]\tLoss: 0.037494\n",
            "Train Epoch: 23 [50560/60000 (84%)]\tLoss: 0.184930\n",
            "Train Epoch: 23 [51200/60000 (85%)]\tLoss: 0.030632\n",
            "Train Epoch: 23 [51840/60000 (86%)]\tLoss: 0.051294\n",
            "Train Epoch: 23 [52480/60000 (87%)]\tLoss: 0.021477\n",
            "Train Epoch: 23 [53120/60000 (88%)]\tLoss: 0.002809\n",
            "Train Epoch: 23 [53760/60000 (90%)]\tLoss: 0.020127\n",
            "Train Epoch: 23 [54400/60000 (91%)]\tLoss: 0.015746\n",
            "Train Epoch: 23 [55040/60000 (92%)]\tLoss: 0.109207\n",
            "Train Epoch: 23 [55680/60000 (93%)]\tLoss: 0.005563\n",
            "Train Epoch: 23 [56320/60000 (94%)]\tLoss: 0.056909\n",
            "Train Epoch: 23 [56960/60000 (95%)]\tLoss: 0.026960\n",
            "Train Epoch: 23 [57600/60000 (96%)]\tLoss: 0.001904\n",
            "Train Epoch: 23 [58240/60000 (97%)]\tLoss: 0.067781\n",
            "Train Epoch: 23 [58880/60000 (98%)]\tLoss: 0.006753\n",
            "Train Epoch: 23 [59520/60000 (99%)]\tLoss: 0.094690\n",
            "\n",
            "Test set: Average loss: 0.0125, Accuracy: 9967/10000 (100%)\n",
            "\n",
            "Train Epoch: 24 [0/60000 (0%)]\tLoss: 0.005805\n",
            "Train Epoch: 24 [640/60000 (1%)]\tLoss: 0.005114\n",
            "Train Epoch: 24 [1280/60000 (2%)]\tLoss: 0.025306\n",
            "Train Epoch: 24 [1920/60000 (3%)]\tLoss: 0.015103\n",
            "Train Epoch: 24 [2560/60000 (4%)]\tLoss: 0.087535\n",
            "Train Epoch: 24 [3200/60000 (5%)]\tLoss: 0.034941\n",
            "Train Epoch: 24 [3840/60000 (6%)]\tLoss: 0.079692\n",
            "Train Epoch: 24 [4480/60000 (7%)]\tLoss: 0.006346\n",
            "Train Epoch: 24 [5120/60000 (9%)]\tLoss: 0.004925\n",
            "Train Epoch: 24 [5760/60000 (10%)]\tLoss: 0.036544\n",
            "Train Epoch: 24 [6400/60000 (11%)]\tLoss: 0.008580\n",
            "Train Epoch: 24 [7040/60000 (12%)]\tLoss: 0.013430\n",
            "Train Epoch: 24 [7680/60000 (13%)]\tLoss: 0.020442\n",
            "Train Epoch: 24 [8320/60000 (14%)]\tLoss: 0.011567\n",
            "Train Epoch: 24 [8960/60000 (15%)]\tLoss: 0.001491\n",
            "Train Epoch: 24 [9600/60000 (16%)]\tLoss: 0.054051\n",
            "Train Epoch: 24 [10240/60000 (17%)]\tLoss: 0.002179\n",
            "Train Epoch: 24 [10880/60000 (18%)]\tLoss: 0.001076\n",
            "Train Epoch: 24 [11520/60000 (19%)]\tLoss: 0.059681\n",
            "Train Epoch: 24 [12160/60000 (20%)]\tLoss: 0.000686\n",
            "Train Epoch: 24 [12800/60000 (21%)]\tLoss: 0.079726\n",
            "Train Epoch: 24 [13440/60000 (22%)]\tLoss: 0.042593\n",
            "Train Epoch: 24 [14080/60000 (23%)]\tLoss: 0.077389\n",
            "Train Epoch: 24 [14720/60000 (25%)]\tLoss: 0.017475\n",
            "Train Epoch: 24 [15360/60000 (26%)]\tLoss: 0.040493\n",
            "Train Epoch: 24 [16000/60000 (27%)]\tLoss: 0.011346\n",
            "Train Epoch: 24 [16640/60000 (28%)]\tLoss: 0.005765\n",
            "Train Epoch: 24 [17280/60000 (29%)]\tLoss: 0.002816\n",
            "Train Epoch: 24 [17920/60000 (30%)]\tLoss: 0.004672\n",
            "Train Epoch: 24 [18560/60000 (31%)]\tLoss: 0.014056\n",
            "Train Epoch: 24 [19200/60000 (32%)]\tLoss: 0.227286\n",
            "Train Epoch: 24 [19840/60000 (33%)]\tLoss: 0.013332\n",
            "Train Epoch: 24 [20480/60000 (34%)]\tLoss: 0.135092\n",
            "Train Epoch: 24 [21120/60000 (35%)]\tLoss: 0.028963\n",
            "Train Epoch: 24 [21760/60000 (36%)]\tLoss: 0.001805\n",
            "Train Epoch: 24 [22400/60000 (37%)]\tLoss: 0.001451\n",
            "Train Epoch: 24 [23040/60000 (38%)]\tLoss: 0.011776\n",
            "Train Epoch: 24 [23680/60000 (39%)]\tLoss: 0.001721\n",
            "Train Epoch: 24 [24320/60000 (41%)]\tLoss: 0.089700\n",
            "Train Epoch: 24 [24960/60000 (42%)]\tLoss: 0.009332\n",
            "Train Epoch: 24 [25600/60000 (43%)]\tLoss: 0.000486\n",
            "Train Epoch: 24 [26240/60000 (44%)]\tLoss: 0.006975\n",
            "Train Epoch: 24 [26880/60000 (45%)]\tLoss: 0.010323\n",
            "Train Epoch: 24 [27520/60000 (46%)]\tLoss: 0.010125\n",
            "Train Epoch: 24 [28160/60000 (47%)]\tLoss: 0.019083\n",
            "Train Epoch: 24 [28800/60000 (48%)]\tLoss: 0.000169\n",
            "Train Epoch: 24 [29440/60000 (49%)]\tLoss: 0.001209\n",
            "Train Epoch: 24 [30080/60000 (50%)]\tLoss: 0.007509\n",
            "Train Epoch: 24 [30720/60000 (51%)]\tLoss: 0.108804\n",
            "Train Epoch: 24 [31360/60000 (52%)]\tLoss: 0.132536\n",
            "Train Epoch: 24 [32000/60000 (53%)]\tLoss: 0.006329\n",
            "Train Epoch: 24 [32640/60000 (54%)]\tLoss: 0.001118\n",
            "Train Epoch: 24 [33280/60000 (55%)]\tLoss: 0.005057\n",
            "Train Epoch: 24 [33920/60000 (57%)]\tLoss: 0.001861\n",
            "Train Epoch: 24 [34560/60000 (58%)]\tLoss: 0.000979\n",
            "Train Epoch: 24 [35200/60000 (59%)]\tLoss: 0.002126\n",
            "Train Epoch: 24 [35840/60000 (60%)]\tLoss: 0.003621\n",
            "Train Epoch: 24 [36480/60000 (61%)]\tLoss: 0.017569\n",
            "Train Epoch: 24 [37120/60000 (62%)]\tLoss: 0.032645\n",
            "Train Epoch: 24 [37760/60000 (63%)]\tLoss: 0.001944\n",
            "Train Epoch: 24 [38400/60000 (64%)]\tLoss: 0.043787\n",
            "Train Epoch: 24 [39040/60000 (65%)]\tLoss: 0.064761\n",
            "Train Epoch: 24 [39680/60000 (66%)]\tLoss: 0.000134\n",
            "Train Epoch: 24 [40320/60000 (67%)]\tLoss: 0.000334\n",
            "Train Epoch: 24 [40960/60000 (68%)]\tLoss: 0.061886\n",
            "Train Epoch: 24 [41600/60000 (69%)]\tLoss: 0.037443\n",
            "Train Epoch: 24 [42240/60000 (70%)]\tLoss: 0.031337\n",
            "Train Epoch: 24 [42880/60000 (71%)]\tLoss: 0.005060\n",
            "Train Epoch: 24 [43520/60000 (72%)]\tLoss: 0.049067\n",
            "Train Epoch: 24 [44160/60000 (74%)]\tLoss: 0.049651\n",
            "Train Epoch: 24 [44800/60000 (75%)]\tLoss: 0.006467\n",
            "Train Epoch: 24 [45440/60000 (76%)]\tLoss: 0.022833\n",
            "Train Epoch: 24 [46080/60000 (77%)]\tLoss: 0.007302\n",
            "Train Epoch: 24 [46720/60000 (78%)]\tLoss: 0.001940\n",
            "Train Epoch: 24 [47360/60000 (79%)]\tLoss: 0.012867\n",
            "Train Epoch: 24 [48000/60000 (80%)]\tLoss: 0.002405\n",
            "Train Epoch: 24 [48640/60000 (81%)]\tLoss: 0.003293\n",
            "Train Epoch: 24 [49280/60000 (82%)]\tLoss: 0.002623\n",
            "Train Epoch: 24 [49920/60000 (83%)]\tLoss: 0.002316\n",
            "Train Epoch: 24 [50560/60000 (84%)]\tLoss: 0.021487\n",
            "Train Epoch: 24 [51200/60000 (85%)]\tLoss: 0.015375\n",
            "Train Epoch: 24 [51840/60000 (86%)]\tLoss: 0.008045\n",
            "Train Epoch: 24 [52480/60000 (87%)]\tLoss: 0.071513\n",
            "Train Epoch: 24 [53120/60000 (88%)]\tLoss: 0.001855\n",
            "Train Epoch: 24 [53760/60000 (90%)]\tLoss: 0.012614\n",
            "Train Epoch: 24 [54400/60000 (91%)]\tLoss: 0.043290\n",
            "Train Epoch: 24 [55040/60000 (92%)]\tLoss: 0.001010\n",
            "Train Epoch: 24 [55680/60000 (93%)]\tLoss: 0.001783\n",
            "Train Epoch: 24 [56320/60000 (94%)]\tLoss: 0.014545\n",
            "Train Epoch: 24 [56960/60000 (95%)]\tLoss: 0.021519\n",
            "Train Epoch: 24 [57600/60000 (96%)]\tLoss: 0.046997\n",
            "Train Epoch: 24 [58240/60000 (97%)]\tLoss: 0.032483\n",
            "Train Epoch: 24 [58880/60000 (98%)]\tLoss: 0.019795\n",
            "Train Epoch: 24 [59520/60000 (99%)]\tLoss: 0.002312\n",
            "\n",
            "Test set: Average loss: 0.0126, Accuracy: 9966/10000 (100%)\n",
            "\n",
            "Train Epoch: 25 [0/60000 (0%)]\tLoss: 0.130695\n",
            "Train Epoch: 25 [640/60000 (1%)]\tLoss: 0.065582\n",
            "Train Epoch: 25 [1280/60000 (2%)]\tLoss: 0.015180\n",
            "Train Epoch: 25 [1920/60000 (3%)]\tLoss: 0.001579\n",
            "Train Epoch: 25 [2560/60000 (4%)]\tLoss: 0.091121\n",
            "Train Epoch: 25 [3200/60000 (5%)]\tLoss: 0.089950\n",
            "Train Epoch: 25 [3840/60000 (6%)]\tLoss: 0.005423\n",
            "Train Epoch: 25 [4480/60000 (7%)]\tLoss: 0.071113\n",
            "Train Epoch: 25 [5120/60000 (9%)]\tLoss: 0.042319\n",
            "Train Epoch: 25 [5760/60000 (10%)]\tLoss: 0.001392\n",
            "Train Epoch: 25 [6400/60000 (11%)]\tLoss: 0.030798\n",
            "Train Epoch: 25 [7040/60000 (12%)]\tLoss: 0.013439\n",
            "Train Epoch: 25 [7680/60000 (13%)]\tLoss: 0.024570\n",
            "Train Epoch: 25 [8320/60000 (14%)]\tLoss: 0.000672\n",
            "Train Epoch: 25 [8960/60000 (15%)]\tLoss: 0.016546\n",
            "Train Epoch: 25 [9600/60000 (16%)]\tLoss: 0.000200\n",
            "Train Epoch: 25 [10240/60000 (17%)]\tLoss: 0.101854\n",
            "Train Epoch: 25 [10880/60000 (18%)]\tLoss: 0.003813\n",
            "Train Epoch: 25 [11520/60000 (19%)]\tLoss: 0.005748\n",
            "Train Epoch: 25 [12160/60000 (20%)]\tLoss: 0.028519\n",
            "Train Epoch: 25 [12800/60000 (21%)]\tLoss: 0.003932\n",
            "Train Epoch: 25 [13440/60000 (22%)]\tLoss: 0.106334\n",
            "Train Epoch: 25 [14080/60000 (23%)]\tLoss: 0.069696\n",
            "Train Epoch: 25 [14720/60000 (25%)]\tLoss: 0.018867\n",
            "Train Epoch: 25 [15360/60000 (26%)]\tLoss: 0.010562\n",
            "Train Epoch: 25 [16000/60000 (27%)]\tLoss: 0.106386\n",
            "Train Epoch: 25 [16640/60000 (28%)]\tLoss: 0.015691\n",
            "Train Epoch: 25 [17280/60000 (29%)]\tLoss: 0.089062\n",
            "Train Epoch: 25 [17920/60000 (30%)]\tLoss: 0.014625\n",
            "Train Epoch: 25 [18560/60000 (31%)]\tLoss: 0.032827\n",
            "Train Epoch: 25 [19200/60000 (32%)]\tLoss: 0.001503\n",
            "Train Epoch: 25 [19840/60000 (33%)]\tLoss: 0.059891\n",
            "Train Epoch: 25 [20480/60000 (34%)]\tLoss: 0.002439\n",
            "Train Epoch: 25 [21120/60000 (35%)]\tLoss: 0.000335\n",
            "Train Epoch: 25 [21760/60000 (36%)]\tLoss: 0.053782\n",
            "Train Epoch: 25 [22400/60000 (37%)]\tLoss: 0.254373\n",
            "Train Epoch: 25 [23040/60000 (38%)]\tLoss: 0.010532\n",
            "Train Epoch: 25 [23680/60000 (39%)]\tLoss: 0.077997\n",
            "Train Epoch: 25 [24320/60000 (41%)]\tLoss: 0.133085\n",
            "Train Epoch: 25 [24960/60000 (42%)]\tLoss: 0.018639\n",
            "Train Epoch: 25 [25600/60000 (43%)]\tLoss: 0.046022\n",
            "Train Epoch: 25 [26240/60000 (44%)]\tLoss: 0.011561\n",
            "Train Epoch: 25 [26880/60000 (45%)]\tLoss: 0.003494\n",
            "Train Epoch: 25 [27520/60000 (46%)]\tLoss: 0.025164\n",
            "Train Epoch: 25 [28160/60000 (47%)]\tLoss: 0.015366\n",
            "Train Epoch: 25 [28800/60000 (48%)]\tLoss: 0.009202\n",
            "Train Epoch: 25 [29440/60000 (49%)]\tLoss: 0.004587\n",
            "Train Epoch: 25 [30080/60000 (50%)]\tLoss: 0.001481\n",
            "Train Epoch: 25 [30720/60000 (51%)]\tLoss: 0.004074\n",
            "Train Epoch: 25 [31360/60000 (52%)]\tLoss: 0.103552\n",
            "Train Epoch: 25 [32000/60000 (53%)]\tLoss: 0.070130\n",
            "Train Epoch: 25 [32640/60000 (54%)]\tLoss: 0.017986\n",
            "Train Epoch: 25 [33280/60000 (55%)]\tLoss: 0.025866\n",
            "Train Epoch: 25 [33920/60000 (57%)]\tLoss: 0.013261\n",
            "Train Epoch: 25 [34560/60000 (58%)]\tLoss: 0.096518\n",
            "Train Epoch: 25 [35200/60000 (59%)]\tLoss: 0.009584\n",
            "Train Epoch: 25 [35840/60000 (60%)]\tLoss: 0.001553\n",
            "Train Epoch: 25 [36480/60000 (61%)]\tLoss: 0.074975\n",
            "Train Epoch: 25 [37120/60000 (62%)]\tLoss: 0.007819\n",
            "Train Epoch: 25 [37760/60000 (63%)]\tLoss: 0.003894\n",
            "Train Epoch: 25 [38400/60000 (64%)]\tLoss: 0.004944\n",
            "Train Epoch: 25 [39040/60000 (65%)]\tLoss: 0.016562\n",
            "Train Epoch: 25 [39680/60000 (66%)]\tLoss: 0.025054\n",
            "Train Epoch: 25 [40320/60000 (67%)]\tLoss: 0.008465\n",
            "Train Epoch: 25 [40960/60000 (68%)]\tLoss: 0.101927\n",
            "Train Epoch: 25 [41600/60000 (69%)]\tLoss: 0.023786\n",
            "Train Epoch: 25 [42240/60000 (70%)]\tLoss: 0.006330\n",
            "Train Epoch: 25 [42880/60000 (71%)]\tLoss: 0.134853\n",
            "Train Epoch: 25 [43520/60000 (72%)]\tLoss: 0.007052\n",
            "Train Epoch: 25 [44160/60000 (74%)]\tLoss: 0.008434\n",
            "Train Epoch: 25 [44800/60000 (75%)]\tLoss: 0.007285\n",
            "Train Epoch: 25 [45440/60000 (76%)]\tLoss: 0.021096\n",
            "Train Epoch: 25 [46080/60000 (77%)]\tLoss: 0.104411\n",
            "Train Epoch: 25 [46720/60000 (78%)]\tLoss: 0.040638\n",
            "Train Epoch: 25 [47360/60000 (79%)]\tLoss: 0.082153\n",
            "Train Epoch: 25 [48000/60000 (80%)]\tLoss: 0.085312\n",
            "Train Epoch: 25 [48640/60000 (81%)]\tLoss: 0.006241\n",
            "Train Epoch: 25 [49280/60000 (82%)]\tLoss: 0.064554\n",
            "Train Epoch: 25 [49920/60000 (83%)]\tLoss: 0.001057\n",
            "Train Epoch: 25 [50560/60000 (84%)]\tLoss: 0.035370\n",
            "Train Epoch: 25 [51200/60000 (85%)]\tLoss: 0.002706\n",
            "Train Epoch: 25 [51840/60000 (86%)]\tLoss: 0.002871\n",
            "Train Epoch: 25 [52480/60000 (87%)]\tLoss: 0.053829\n",
            "Train Epoch: 25 [53120/60000 (88%)]\tLoss: 0.143416\n",
            "Train Epoch: 25 [53760/60000 (90%)]\tLoss: 0.001057\n",
            "Train Epoch: 25 [54400/60000 (91%)]\tLoss: 0.050690\n",
            "Train Epoch: 25 [55040/60000 (92%)]\tLoss: 0.042794\n",
            "Train Epoch: 25 [55680/60000 (93%)]\tLoss: 0.047926\n",
            "Train Epoch: 25 [56320/60000 (94%)]\tLoss: 0.066226\n",
            "Train Epoch: 25 [56960/60000 (95%)]\tLoss: 0.007724\n",
            "Train Epoch: 25 [57600/60000 (96%)]\tLoss: 0.008072\n",
            "Train Epoch: 25 [58240/60000 (97%)]\tLoss: 0.001526\n",
            "Train Epoch: 25 [58880/60000 (98%)]\tLoss: 0.002349\n",
            "Train Epoch: 25 [59520/60000 (99%)]\tLoss: 0.003475\n",
            "\n",
            "Test set: Average loss: 0.0139, Accuracy: 9963/10000 (100%)\n",
            "\n",
            "Train Epoch: 26 [0/60000 (0%)]\tLoss: 0.020792\n",
            "Train Epoch: 26 [640/60000 (1%)]\tLoss: 0.010634\n",
            "Train Epoch: 26 [1280/60000 (2%)]\tLoss: 0.078840\n",
            "Train Epoch: 26 [1920/60000 (3%)]\tLoss: 0.018254\n",
            "Train Epoch: 26 [2560/60000 (4%)]\tLoss: 0.007003\n",
            "Train Epoch: 26 [3200/60000 (5%)]\tLoss: 0.001794\n",
            "Train Epoch: 26 [3840/60000 (6%)]\tLoss: 0.033356\n",
            "Train Epoch: 26 [4480/60000 (7%)]\tLoss: 0.056712\n",
            "Train Epoch: 26 [5120/60000 (9%)]\tLoss: 0.010915\n",
            "Train Epoch: 26 [5760/60000 (10%)]\tLoss: 0.094460\n",
            "Train Epoch: 26 [6400/60000 (11%)]\tLoss: 0.002406\n",
            "Train Epoch: 26 [7040/60000 (12%)]\tLoss: 0.043620\n",
            "Train Epoch: 26 [7680/60000 (13%)]\tLoss: 0.008196\n",
            "Train Epoch: 26 [8320/60000 (14%)]\tLoss: 0.094265\n",
            "Train Epoch: 26 [8960/60000 (15%)]\tLoss: 0.154625\n",
            "Train Epoch: 26 [9600/60000 (16%)]\tLoss: 0.033606\n",
            "Train Epoch: 26 [10240/60000 (17%)]\tLoss: 0.040654\n",
            "Train Epoch: 26 [10880/60000 (18%)]\tLoss: 0.024466\n",
            "Train Epoch: 26 [11520/60000 (19%)]\tLoss: 0.003042\n",
            "Train Epoch: 26 [12160/60000 (20%)]\tLoss: 0.003659\n",
            "Train Epoch: 26 [12800/60000 (21%)]\tLoss: 0.001802\n",
            "Train Epoch: 26 [13440/60000 (22%)]\tLoss: 0.000432\n",
            "Train Epoch: 26 [14080/60000 (23%)]\tLoss: 0.036168\n",
            "Train Epoch: 26 [14720/60000 (25%)]\tLoss: 0.007798\n",
            "Train Epoch: 26 [15360/60000 (26%)]\tLoss: 0.042749\n",
            "Train Epoch: 26 [16000/60000 (27%)]\tLoss: 0.033980\n",
            "Train Epoch: 26 [16640/60000 (28%)]\tLoss: 0.013337\n",
            "Train Epoch: 26 [17280/60000 (29%)]\tLoss: 0.025010\n",
            "Train Epoch: 26 [17920/60000 (30%)]\tLoss: 0.083862\n",
            "Train Epoch: 26 [18560/60000 (31%)]\tLoss: 0.023153\n",
            "Train Epoch: 26 [19200/60000 (32%)]\tLoss: 0.000226\n",
            "Train Epoch: 26 [19840/60000 (33%)]\tLoss: 0.060638\n",
            "Train Epoch: 26 [20480/60000 (34%)]\tLoss: 0.011159\n",
            "Train Epoch: 26 [21120/60000 (35%)]\tLoss: 0.023599\n",
            "Train Epoch: 26 [21760/60000 (36%)]\tLoss: 0.023755\n",
            "Train Epoch: 26 [22400/60000 (37%)]\tLoss: 0.008144\n",
            "Train Epoch: 26 [23040/60000 (38%)]\tLoss: 0.000865\n",
            "Train Epoch: 26 [23680/60000 (39%)]\tLoss: 0.004267\n",
            "Train Epoch: 26 [24320/60000 (41%)]\tLoss: 0.005598\n",
            "Train Epoch: 26 [24960/60000 (42%)]\tLoss: 0.013901\n",
            "Train Epoch: 26 [25600/60000 (43%)]\tLoss: 0.003138\n",
            "Train Epoch: 26 [26240/60000 (44%)]\tLoss: 0.179842\n",
            "Train Epoch: 26 [26880/60000 (45%)]\tLoss: 0.022499\n",
            "Train Epoch: 26 [27520/60000 (46%)]\tLoss: 0.009400\n",
            "Train Epoch: 26 [28160/60000 (47%)]\tLoss: 0.017186\n",
            "Train Epoch: 26 [28800/60000 (48%)]\tLoss: 0.009198\n",
            "Train Epoch: 26 [29440/60000 (49%)]\tLoss: 0.001819\n",
            "Train Epoch: 26 [30080/60000 (50%)]\tLoss: 0.177631\n",
            "Train Epoch: 26 [30720/60000 (51%)]\tLoss: 0.004025\n",
            "Train Epoch: 26 [31360/60000 (52%)]\tLoss: 0.005205\n",
            "Train Epoch: 26 [32000/60000 (53%)]\tLoss: 0.004222\n",
            "Train Epoch: 26 [32640/60000 (54%)]\tLoss: 0.017902\n",
            "Train Epoch: 26 [33280/60000 (55%)]\tLoss: 0.031712\n",
            "Train Epoch: 26 [33920/60000 (57%)]\tLoss: 0.003353\n",
            "Train Epoch: 26 [34560/60000 (58%)]\tLoss: 0.001914\n",
            "Train Epoch: 26 [35200/60000 (59%)]\tLoss: 0.001832\n",
            "Train Epoch: 26 [35840/60000 (60%)]\tLoss: 0.027046\n",
            "Train Epoch: 26 [36480/60000 (61%)]\tLoss: 0.042412\n",
            "Train Epoch: 26 [37120/60000 (62%)]\tLoss: 0.146000\n",
            "Train Epoch: 26 [37760/60000 (63%)]\tLoss: 0.001617\n",
            "Train Epoch: 26 [38400/60000 (64%)]\tLoss: 0.000222\n",
            "Train Epoch: 26 [39040/60000 (65%)]\tLoss: 0.010654\n",
            "Train Epoch: 26 [39680/60000 (66%)]\tLoss: 0.088458\n",
            "Train Epoch: 26 [40320/60000 (67%)]\tLoss: 0.104950\n",
            "Train Epoch: 26 [40960/60000 (68%)]\tLoss: 0.003702\n",
            "Train Epoch: 26 [41600/60000 (69%)]\tLoss: 0.039518\n",
            "Train Epoch: 26 [42240/60000 (70%)]\tLoss: 0.033618\n",
            "Train Epoch: 26 [42880/60000 (71%)]\tLoss: 0.069690\n",
            "Train Epoch: 26 [43520/60000 (72%)]\tLoss: 0.001420\n",
            "Train Epoch: 26 [44160/60000 (74%)]\tLoss: 0.003655\n",
            "Train Epoch: 26 [44800/60000 (75%)]\tLoss: 0.002478\n",
            "Train Epoch: 26 [45440/60000 (76%)]\tLoss: 0.000406\n",
            "Train Epoch: 26 [46080/60000 (77%)]\tLoss: 0.001972\n",
            "Train Epoch: 26 [46720/60000 (78%)]\tLoss: 0.091957\n",
            "Train Epoch: 26 [47360/60000 (79%)]\tLoss: 0.083509\n",
            "Train Epoch: 26 [48000/60000 (80%)]\tLoss: 0.021741\n",
            "Train Epoch: 26 [48640/60000 (81%)]\tLoss: 0.051812\n",
            "Train Epoch: 26 [49280/60000 (82%)]\tLoss: 0.001510\n",
            "Train Epoch: 26 [49920/60000 (83%)]\tLoss: 0.028603\n",
            "Train Epoch: 26 [50560/60000 (84%)]\tLoss: 0.009190\n",
            "Train Epoch: 26 [51200/60000 (85%)]\tLoss: 0.000402\n",
            "Train Epoch: 26 [51840/60000 (86%)]\tLoss: 0.119640\n",
            "Train Epoch: 26 [52480/60000 (87%)]\tLoss: 0.001150\n",
            "Train Epoch: 26 [53120/60000 (88%)]\tLoss: 0.006529\n",
            "Train Epoch: 26 [53760/60000 (90%)]\tLoss: 0.009284\n",
            "Train Epoch: 26 [54400/60000 (91%)]\tLoss: 0.006417\n",
            "Train Epoch: 26 [55040/60000 (92%)]\tLoss: 0.114863\n",
            "Train Epoch: 26 [55680/60000 (93%)]\tLoss: 0.007372\n",
            "Train Epoch: 26 [56320/60000 (94%)]\tLoss: 0.020077\n",
            "Train Epoch: 26 [56960/60000 (95%)]\tLoss: 0.011014\n",
            "Train Epoch: 26 [57600/60000 (96%)]\tLoss: 0.008912\n",
            "Train Epoch: 26 [58240/60000 (97%)]\tLoss: 0.006640\n",
            "Train Epoch: 26 [58880/60000 (98%)]\tLoss: 0.064686\n",
            "Train Epoch: 26 [59520/60000 (99%)]\tLoss: 0.008969\n",
            "\n",
            "Test set: Average loss: 0.0136, Accuracy: 9964/10000 (100%)\n",
            "\n",
            "Train Epoch: 27 [0/60000 (0%)]\tLoss: 0.015857\n",
            "Train Epoch: 27 [640/60000 (1%)]\tLoss: 0.037910\n",
            "Train Epoch: 27 [1280/60000 (2%)]\tLoss: 0.045707\n",
            "Train Epoch: 27 [1920/60000 (3%)]\tLoss: 0.001858\n",
            "Train Epoch: 27 [2560/60000 (4%)]\tLoss: 0.013027\n",
            "Train Epoch: 27 [3200/60000 (5%)]\tLoss: 0.001374\n",
            "Train Epoch: 27 [3840/60000 (6%)]\tLoss: 0.009708\n",
            "Train Epoch: 27 [4480/60000 (7%)]\tLoss: 0.033272\n",
            "Train Epoch: 27 [5120/60000 (9%)]\tLoss: 0.014156\n",
            "Train Epoch: 27 [5760/60000 (10%)]\tLoss: 0.029432\n",
            "Train Epoch: 27 [6400/60000 (11%)]\tLoss: 0.035868\n",
            "Train Epoch: 27 [7040/60000 (12%)]\tLoss: 0.031924\n",
            "Train Epoch: 27 [7680/60000 (13%)]\tLoss: 0.026196\n",
            "Train Epoch: 27 [8320/60000 (14%)]\tLoss: 0.024085\n",
            "Train Epoch: 27 [8960/60000 (15%)]\tLoss: 0.001539\n",
            "Train Epoch: 27 [9600/60000 (16%)]\tLoss: 0.001064\n",
            "Train Epoch: 27 [10240/60000 (17%)]\tLoss: 0.003552\n",
            "Train Epoch: 27 [10880/60000 (18%)]\tLoss: 0.018781\n",
            "Train Epoch: 27 [11520/60000 (19%)]\tLoss: 0.009175\n",
            "Train Epoch: 27 [12160/60000 (20%)]\tLoss: 0.036939\n",
            "Train Epoch: 27 [12800/60000 (21%)]\tLoss: 0.019987\n",
            "Train Epoch: 27 [13440/60000 (22%)]\tLoss: 0.014663\n",
            "Train Epoch: 27 [14080/60000 (23%)]\tLoss: 0.024703\n",
            "Train Epoch: 27 [14720/60000 (25%)]\tLoss: 0.017986\n",
            "Train Epoch: 27 [15360/60000 (26%)]\tLoss: 0.007826\n",
            "Train Epoch: 27 [16000/60000 (27%)]\tLoss: 0.004626\n",
            "Train Epoch: 27 [16640/60000 (28%)]\tLoss: 0.003241\n",
            "Train Epoch: 27 [17280/60000 (29%)]\tLoss: 0.084330\n",
            "Train Epoch: 27 [17920/60000 (30%)]\tLoss: 0.029699\n",
            "Train Epoch: 27 [18560/60000 (31%)]\tLoss: 0.008518\n",
            "Train Epoch: 27 [19200/60000 (32%)]\tLoss: 0.003353\n",
            "Train Epoch: 27 [19840/60000 (33%)]\tLoss: 0.024656\n",
            "Train Epoch: 27 [20480/60000 (34%)]\tLoss: 0.005450\n",
            "Train Epoch: 27 [21120/60000 (35%)]\tLoss: 0.006443\n",
            "Train Epoch: 27 [21760/60000 (36%)]\tLoss: 0.011148\n",
            "Train Epoch: 27 [22400/60000 (37%)]\tLoss: 0.000645\n",
            "Train Epoch: 27 [23040/60000 (38%)]\tLoss: 0.185209\n",
            "Train Epoch: 27 [23680/60000 (39%)]\tLoss: 0.003194\n",
            "Train Epoch: 27 [24320/60000 (41%)]\tLoss: 0.006623\n",
            "Train Epoch: 27 [24960/60000 (42%)]\tLoss: 0.033926\n",
            "Train Epoch: 27 [25600/60000 (43%)]\tLoss: 0.002911\n",
            "Train Epoch: 27 [26240/60000 (44%)]\tLoss: 0.080037\n",
            "Train Epoch: 27 [26880/60000 (45%)]\tLoss: 0.049125\n",
            "Train Epoch: 27 [27520/60000 (46%)]\tLoss: 0.050477\n",
            "Train Epoch: 27 [28160/60000 (47%)]\tLoss: 0.025220\n",
            "Train Epoch: 27 [28800/60000 (48%)]\tLoss: 0.026629\n",
            "Train Epoch: 27 [29440/60000 (49%)]\tLoss: 0.019851\n",
            "Train Epoch: 27 [30080/60000 (50%)]\tLoss: 0.006333\n",
            "Train Epoch: 27 [30720/60000 (51%)]\tLoss: 0.007470\n",
            "Train Epoch: 27 [31360/60000 (52%)]\tLoss: 0.001761\n",
            "Train Epoch: 27 [32000/60000 (53%)]\tLoss: 0.001774\n",
            "Train Epoch: 27 [32640/60000 (54%)]\tLoss: 0.024595\n",
            "Train Epoch: 27 [33280/60000 (55%)]\tLoss: 0.001198\n",
            "Train Epoch: 27 [33920/60000 (57%)]\tLoss: 0.015341\n",
            "Train Epoch: 27 [34560/60000 (58%)]\tLoss: 0.004242\n",
            "Train Epoch: 27 [35200/60000 (59%)]\tLoss: 0.042649\n",
            "Train Epoch: 27 [35840/60000 (60%)]\tLoss: 0.035822\n",
            "Train Epoch: 27 [36480/60000 (61%)]\tLoss: 0.024762\n",
            "Train Epoch: 27 [37120/60000 (62%)]\tLoss: 0.019471\n",
            "Train Epoch: 27 [37760/60000 (63%)]\tLoss: 0.037485\n",
            "Train Epoch: 27 [38400/60000 (64%)]\tLoss: 0.005422\n",
            "Train Epoch: 27 [39040/60000 (65%)]\tLoss: 0.020688\n",
            "Train Epoch: 27 [39680/60000 (66%)]\tLoss: 0.165423\n",
            "Train Epoch: 27 [40320/60000 (67%)]\tLoss: 0.076296\n",
            "Train Epoch: 27 [40960/60000 (68%)]\tLoss: 0.053547\n",
            "Train Epoch: 27 [41600/60000 (69%)]\tLoss: 0.020920\n",
            "Train Epoch: 27 [42240/60000 (70%)]\tLoss: 0.012831\n",
            "Train Epoch: 27 [42880/60000 (71%)]\tLoss: 0.046821\n",
            "Train Epoch: 27 [43520/60000 (72%)]\tLoss: 0.003003\n",
            "Train Epoch: 27 [44160/60000 (74%)]\tLoss: 0.004305\n",
            "Train Epoch: 27 [44800/60000 (75%)]\tLoss: 0.017908\n",
            "Train Epoch: 27 [45440/60000 (76%)]\tLoss: 0.001980\n",
            "Train Epoch: 27 [46080/60000 (77%)]\tLoss: 0.015150\n",
            "Train Epoch: 27 [46720/60000 (78%)]\tLoss: 0.024900\n",
            "Train Epoch: 27 [47360/60000 (79%)]\tLoss: 0.000538\n",
            "Train Epoch: 27 [48000/60000 (80%)]\tLoss: 0.054780\n",
            "Train Epoch: 27 [48640/60000 (81%)]\tLoss: 0.006702\n",
            "Train Epoch: 27 [49280/60000 (82%)]\tLoss: 0.000405\n",
            "Train Epoch: 27 [49920/60000 (83%)]\tLoss: 0.000389\n",
            "Train Epoch: 27 [50560/60000 (84%)]\tLoss: 0.057231\n",
            "Train Epoch: 27 [51200/60000 (85%)]\tLoss: 0.024366\n",
            "Train Epoch: 27 [51840/60000 (86%)]\tLoss: 0.006359\n",
            "Train Epoch: 27 [52480/60000 (87%)]\tLoss: 0.004769\n",
            "Train Epoch: 27 [53120/60000 (88%)]\tLoss: 0.011771\n",
            "Train Epoch: 27 [53760/60000 (90%)]\tLoss: 0.005423\n",
            "Train Epoch: 27 [54400/60000 (91%)]\tLoss: 0.060872\n",
            "Train Epoch: 27 [55040/60000 (92%)]\tLoss: 0.000296\n",
            "Train Epoch: 27 [55680/60000 (93%)]\tLoss: 0.019538\n",
            "Train Epoch: 27 [56320/60000 (94%)]\tLoss: 0.001462\n",
            "Train Epoch: 27 [56960/60000 (95%)]\tLoss: 0.118910\n",
            "Train Epoch: 27 [57600/60000 (96%)]\tLoss: 0.002337\n",
            "Train Epoch: 27 [58240/60000 (97%)]\tLoss: 0.006046\n",
            "Train Epoch: 27 [58880/60000 (98%)]\tLoss: 0.006038\n",
            "Train Epoch: 27 [59520/60000 (99%)]\tLoss: 0.012828\n",
            "\n",
            "Test set: Average loss: 0.0135, Accuracy: 9962/10000 (100%)\n",
            "\n",
            "Train Epoch: 28 [0/60000 (0%)]\tLoss: 0.068645\n",
            "Train Epoch: 28 [640/60000 (1%)]\tLoss: 0.009216\n",
            "Train Epoch: 28 [1280/60000 (2%)]\tLoss: 0.074860\n",
            "Train Epoch: 28 [1920/60000 (3%)]\tLoss: 0.008335\n",
            "Train Epoch: 28 [2560/60000 (4%)]\tLoss: 0.006130\n",
            "Train Epoch: 28 [3200/60000 (5%)]\tLoss: 0.003931\n",
            "Train Epoch: 28 [3840/60000 (6%)]\tLoss: 0.013446\n",
            "Train Epoch: 28 [4480/60000 (7%)]\tLoss: 0.004587\n",
            "Train Epoch: 28 [5120/60000 (9%)]\tLoss: 0.011807\n",
            "Train Epoch: 28 [5760/60000 (10%)]\tLoss: 0.091453\n",
            "Train Epoch: 28 [6400/60000 (11%)]\tLoss: 0.001673\n",
            "Train Epoch: 28 [7040/60000 (12%)]\tLoss: 0.037808\n",
            "Train Epoch: 28 [7680/60000 (13%)]\tLoss: 0.004079\n",
            "Train Epoch: 28 [8320/60000 (14%)]\tLoss: 0.023039\n",
            "Train Epoch: 28 [8960/60000 (15%)]\tLoss: 0.002268\n",
            "Train Epoch: 28 [9600/60000 (16%)]\tLoss: 0.194339\n",
            "Train Epoch: 28 [10240/60000 (17%)]\tLoss: 0.057374\n",
            "Train Epoch: 28 [10880/60000 (18%)]\tLoss: 0.002854\n",
            "Train Epoch: 28 [11520/60000 (19%)]\tLoss: 0.001900\n",
            "Train Epoch: 28 [12160/60000 (20%)]\tLoss: 0.004447\n",
            "Train Epoch: 28 [12800/60000 (21%)]\tLoss: 0.023151\n",
            "Train Epoch: 28 [13440/60000 (22%)]\tLoss: 0.185461\n",
            "Train Epoch: 28 [14080/60000 (23%)]\tLoss: 0.021325\n",
            "Train Epoch: 28 [14720/60000 (25%)]\tLoss: 0.000650\n",
            "Train Epoch: 28 [15360/60000 (26%)]\tLoss: 0.091059\n",
            "Train Epoch: 28 [16000/60000 (27%)]\tLoss: 0.014309\n",
            "Train Epoch: 28 [16640/60000 (28%)]\tLoss: 0.023786\n",
            "Train Epoch: 28 [17280/60000 (29%)]\tLoss: 0.003147\n",
            "Train Epoch: 28 [17920/60000 (30%)]\tLoss: 0.000969\n",
            "Train Epoch: 28 [18560/60000 (31%)]\tLoss: 0.054054\n",
            "Train Epoch: 28 [19200/60000 (32%)]\tLoss: 0.043257\n",
            "Train Epoch: 28 [19840/60000 (33%)]\tLoss: 0.025119\n",
            "Train Epoch: 28 [20480/60000 (34%)]\tLoss: 0.012366\n",
            "Train Epoch: 28 [21120/60000 (35%)]\tLoss: 0.100925\n",
            "Train Epoch: 28 [21760/60000 (36%)]\tLoss: 0.047065\n",
            "Train Epoch: 28 [22400/60000 (37%)]\tLoss: 0.001359\n",
            "Train Epoch: 28 [23040/60000 (38%)]\tLoss: 0.046607\n",
            "Train Epoch: 28 [23680/60000 (39%)]\tLoss: 0.034496\n",
            "Train Epoch: 28 [24320/60000 (41%)]\tLoss: 0.003888\n",
            "Train Epoch: 28 [24960/60000 (42%)]\tLoss: 0.003780\n",
            "Train Epoch: 28 [25600/60000 (43%)]\tLoss: 0.001082\n",
            "Train Epoch: 28 [26240/60000 (44%)]\tLoss: 0.184490\n",
            "Train Epoch: 28 [26880/60000 (45%)]\tLoss: 0.028187\n",
            "Train Epoch: 28 [27520/60000 (46%)]\tLoss: 0.001932\n",
            "Train Epoch: 28 [28160/60000 (47%)]\tLoss: 0.008730\n",
            "Train Epoch: 28 [28800/60000 (48%)]\tLoss: 0.011473\n",
            "Train Epoch: 28 [29440/60000 (49%)]\tLoss: 0.007524\n",
            "Train Epoch: 28 [30080/60000 (50%)]\tLoss: 0.034958\n",
            "Train Epoch: 28 [30720/60000 (51%)]\tLoss: 0.042781\n",
            "Train Epoch: 28 [31360/60000 (52%)]\tLoss: 0.011764\n",
            "Train Epoch: 28 [32000/60000 (53%)]\tLoss: 0.024469\n",
            "Train Epoch: 28 [32640/60000 (54%)]\tLoss: 0.016522\n",
            "Train Epoch: 28 [33280/60000 (55%)]\tLoss: 0.008455\n",
            "Train Epoch: 28 [33920/60000 (57%)]\tLoss: 0.005858\n",
            "Train Epoch: 28 [34560/60000 (58%)]\tLoss: 0.108241\n",
            "Train Epoch: 28 [35200/60000 (59%)]\tLoss: 0.001962\n",
            "Train Epoch: 28 [35840/60000 (60%)]\tLoss: 0.005185\n",
            "Train Epoch: 28 [36480/60000 (61%)]\tLoss: 0.008885\n",
            "Train Epoch: 28 [37120/60000 (62%)]\tLoss: 0.027325\n",
            "Train Epoch: 28 [37760/60000 (63%)]\tLoss: 0.003999\n",
            "Train Epoch: 28 [38400/60000 (64%)]\tLoss: 0.035506\n",
            "Train Epoch: 28 [39040/60000 (65%)]\tLoss: 0.050277\n",
            "Train Epoch: 28 [39680/60000 (66%)]\tLoss: 0.007012\n",
            "Train Epoch: 28 [40320/60000 (67%)]\tLoss: 0.133606\n",
            "Train Epoch: 28 [40960/60000 (68%)]\tLoss: 0.001398\n",
            "Train Epoch: 28 [41600/60000 (69%)]\tLoss: 0.011665\n",
            "Train Epoch: 28 [42240/60000 (70%)]\tLoss: 0.001957\n",
            "Train Epoch: 28 [42880/60000 (71%)]\tLoss: 0.007432\n",
            "Train Epoch: 28 [43520/60000 (72%)]\tLoss: 0.137357\n",
            "Train Epoch: 28 [44160/60000 (74%)]\tLoss: 0.004708\n",
            "Train Epoch: 28 [44800/60000 (75%)]\tLoss: 0.001734\n",
            "Train Epoch: 28 [45440/60000 (76%)]\tLoss: 0.001928\n",
            "Train Epoch: 28 [46080/60000 (77%)]\tLoss: 0.027296\n",
            "Train Epoch: 28 [46720/60000 (78%)]\tLoss: 0.000377\n",
            "Train Epoch: 28 [47360/60000 (79%)]\tLoss: 0.031207\n",
            "Train Epoch: 28 [48000/60000 (80%)]\tLoss: 0.001306\n",
            "Train Epoch: 28 [48640/60000 (81%)]\tLoss: 0.003537\n",
            "Train Epoch: 28 [49280/60000 (82%)]\tLoss: 0.055635\n",
            "Train Epoch: 28 [49920/60000 (83%)]\tLoss: 0.011877\n",
            "Train Epoch: 28 [50560/60000 (84%)]\tLoss: 0.092284\n",
            "Train Epoch: 28 [51200/60000 (85%)]\tLoss: 0.001385\n",
            "Train Epoch: 28 [51840/60000 (86%)]\tLoss: 0.010716\n",
            "Train Epoch: 28 [52480/60000 (87%)]\tLoss: 0.055715\n",
            "Train Epoch: 28 [53120/60000 (88%)]\tLoss: 0.002397\n",
            "Train Epoch: 28 [53760/60000 (90%)]\tLoss: 0.001317\n",
            "Train Epoch: 28 [54400/60000 (91%)]\tLoss: 0.007743\n",
            "Train Epoch: 28 [55040/60000 (92%)]\tLoss: 0.010538\n",
            "Train Epoch: 28 [55680/60000 (93%)]\tLoss: 0.046199\n",
            "Train Epoch: 28 [56320/60000 (94%)]\tLoss: 0.005069\n",
            "Train Epoch: 28 [56960/60000 (95%)]\tLoss: 0.002570\n",
            "Train Epoch: 28 [57600/60000 (96%)]\tLoss: 0.073524\n",
            "Train Epoch: 28 [58240/60000 (97%)]\tLoss: 0.045415\n",
            "Train Epoch: 28 [58880/60000 (98%)]\tLoss: 0.026489\n",
            "Train Epoch: 28 [59520/60000 (99%)]\tLoss: 0.023001\n",
            "\n",
            "Test set: Average loss: 0.0134, Accuracy: 9963/10000 (100%)\n",
            "\n",
            "Train Epoch: 29 [0/60000 (0%)]\tLoss: 0.002300\n",
            "Train Epoch: 29 [640/60000 (1%)]\tLoss: 0.018266\n",
            "Train Epoch: 29 [1280/60000 (2%)]\tLoss: 0.000815\n",
            "Train Epoch: 29 [1920/60000 (3%)]\tLoss: 0.003498\n",
            "Train Epoch: 29 [2560/60000 (4%)]\tLoss: 0.012683\n",
            "Train Epoch: 29 [3200/60000 (5%)]\tLoss: 0.157701\n",
            "Train Epoch: 29 [3840/60000 (6%)]\tLoss: 0.000788\n",
            "Train Epoch: 29 [4480/60000 (7%)]\tLoss: 0.029363\n",
            "Train Epoch: 29 [5120/60000 (9%)]\tLoss: 0.026346\n",
            "Train Epoch: 29 [5760/60000 (10%)]\tLoss: 0.139605\n",
            "Train Epoch: 29 [6400/60000 (11%)]\tLoss: 0.019966\n",
            "Train Epoch: 29 [7040/60000 (12%)]\tLoss: 0.002534\n",
            "Train Epoch: 29 [7680/60000 (13%)]\tLoss: 0.221018\n",
            "Train Epoch: 29 [8320/60000 (14%)]\tLoss: 0.005239\n",
            "Train Epoch: 29 [8960/60000 (15%)]\tLoss: 0.045713\n",
            "Train Epoch: 29 [9600/60000 (16%)]\tLoss: 0.002093\n",
            "Train Epoch: 29 [10240/60000 (17%)]\tLoss: 0.113968\n",
            "Train Epoch: 29 [10880/60000 (18%)]\tLoss: 0.144277\n",
            "Train Epoch: 29 [11520/60000 (19%)]\tLoss: 0.185417\n",
            "Train Epoch: 29 [12160/60000 (20%)]\tLoss: 0.004450\n",
            "Train Epoch: 29 [12800/60000 (21%)]\tLoss: 0.041283\n",
            "Train Epoch: 29 [13440/60000 (22%)]\tLoss: 0.014846\n",
            "Train Epoch: 29 [14080/60000 (23%)]\tLoss: 0.018610\n",
            "Train Epoch: 29 [14720/60000 (25%)]\tLoss: 0.001604\n",
            "Train Epoch: 29 [15360/60000 (26%)]\tLoss: 0.013661\n",
            "Train Epoch: 29 [16000/60000 (27%)]\tLoss: 0.004222\n",
            "Train Epoch: 29 [16640/60000 (28%)]\tLoss: 0.138067\n",
            "Train Epoch: 29 [17280/60000 (29%)]\tLoss: 0.010687\n",
            "Train Epoch: 29 [17920/60000 (30%)]\tLoss: 0.003513\n",
            "Train Epoch: 29 [18560/60000 (31%)]\tLoss: 0.009350\n",
            "Train Epoch: 29 [19200/60000 (32%)]\tLoss: 0.042004\n",
            "Train Epoch: 29 [19840/60000 (33%)]\tLoss: 0.000282\n",
            "Train Epoch: 29 [20480/60000 (34%)]\tLoss: 0.067729\n",
            "Train Epoch: 29 [21120/60000 (35%)]\tLoss: 0.027691\n",
            "Train Epoch: 29 [21760/60000 (36%)]\tLoss: 0.008007\n",
            "Train Epoch: 29 [22400/60000 (37%)]\tLoss: 0.005692\n",
            "Train Epoch: 29 [23040/60000 (38%)]\tLoss: 0.049648\n",
            "Train Epoch: 29 [23680/60000 (39%)]\tLoss: 0.048701\n",
            "Train Epoch: 29 [24320/60000 (41%)]\tLoss: 0.006192\n",
            "Train Epoch: 29 [24960/60000 (42%)]\tLoss: 0.030710\n",
            "Train Epoch: 29 [25600/60000 (43%)]\tLoss: 0.087171\n",
            "Train Epoch: 29 [26240/60000 (44%)]\tLoss: 0.004254\n",
            "Train Epoch: 29 [26880/60000 (45%)]\tLoss: 0.024368\n",
            "Train Epoch: 29 [27520/60000 (46%)]\tLoss: 0.016801\n",
            "Train Epoch: 29 [28160/60000 (47%)]\tLoss: 0.009935\n",
            "Train Epoch: 29 [28800/60000 (48%)]\tLoss: 0.025187\n",
            "Train Epoch: 29 [29440/60000 (49%)]\tLoss: 0.022742\n",
            "Train Epoch: 29 [30080/60000 (50%)]\tLoss: 0.069239\n",
            "Train Epoch: 29 [30720/60000 (51%)]\tLoss: 0.102528\n",
            "Train Epoch: 29 [31360/60000 (52%)]\tLoss: 0.014854\n",
            "Train Epoch: 29 [32000/60000 (53%)]\tLoss: 0.005312\n",
            "Train Epoch: 29 [32640/60000 (54%)]\tLoss: 0.047920\n",
            "Train Epoch: 29 [33280/60000 (55%)]\tLoss: 0.039438\n",
            "Train Epoch: 29 [33920/60000 (57%)]\tLoss: 0.001057\n",
            "Train Epoch: 29 [34560/60000 (58%)]\tLoss: 0.001904\n",
            "Train Epoch: 29 [35200/60000 (59%)]\tLoss: 0.047046\n",
            "Train Epoch: 29 [35840/60000 (60%)]\tLoss: 0.004241\n",
            "Train Epoch: 29 [36480/60000 (61%)]\tLoss: 0.002202\n",
            "Train Epoch: 29 [37120/60000 (62%)]\tLoss: 0.008523\n",
            "Train Epoch: 29 [37760/60000 (63%)]\tLoss: 0.003171\n",
            "Train Epoch: 29 [38400/60000 (64%)]\tLoss: 0.012958\n",
            "Train Epoch: 29 [39040/60000 (65%)]\tLoss: 0.063063\n",
            "Train Epoch: 29 [39680/60000 (66%)]\tLoss: 0.085428\n",
            "Train Epoch: 29 [40320/60000 (67%)]\tLoss: 0.010715\n",
            "Train Epoch: 29 [40960/60000 (68%)]\tLoss: 0.003944\n",
            "Train Epoch: 29 [41600/60000 (69%)]\tLoss: 0.062780\n",
            "Train Epoch: 29 [42240/60000 (70%)]\tLoss: 0.005008\n",
            "Train Epoch: 29 [42880/60000 (71%)]\tLoss: 0.003565\n",
            "Train Epoch: 29 [43520/60000 (72%)]\tLoss: 0.093607\n",
            "Train Epoch: 29 [44160/60000 (74%)]\tLoss: 0.058475\n",
            "Train Epoch: 29 [44800/60000 (75%)]\tLoss: 0.013997\n",
            "Train Epoch: 29 [45440/60000 (76%)]\tLoss: 0.034775\n",
            "Train Epoch: 29 [46080/60000 (77%)]\tLoss: 0.086212\n",
            "Train Epoch: 29 [46720/60000 (78%)]\tLoss: 0.015134\n",
            "Train Epoch: 29 [47360/60000 (79%)]\tLoss: 0.035946\n",
            "Train Epoch: 29 [48000/60000 (80%)]\tLoss: 0.070196\n",
            "Train Epoch: 29 [48640/60000 (81%)]\tLoss: 0.009383\n",
            "Train Epoch: 29 [49280/60000 (82%)]\tLoss: 0.000479\n",
            "Train Epoch: 29 [49920/60000 (83%)]\tLoss: 0.000697\n",
            "Train Epoch: 29 [50560/60000 (84%)]\tLoss: 0.005391\n",
            "Train Epoch: 29 [51200/60000 (85%)]\tLoss: 0.009830\n",
            "Train Epoch: 29 [51840/60000 (86%)]\tLoss: 0.001857\n",
            "Train Epoch: 29 [52480/60000 (87%)]\tLoss: 0.000525\n",
            "Train Epoch: 29 [53120/60000 (88%)]\tLoss: 0.003981\n",
            "Train Epoch: 29 [53760/60000 (90%)]\tLoss: 0.006509\n",
            "Train Epoch: 29 [54400/60000 (91%)]\tLoss: 0.004767\n",
            "Train Epoch: 29 [55040/60000 (92%)]\tLoss: 0.008534\n",
            "Train Epoch: 29 [55680/60000 (93%)]\tLoss: 0.003311\n",
            "Train Epoch: 29 [56320/60000 (94%)]\tLoss: 0.006256\n",
            "Train Epoch: 29 [56960/60000 (95%)]\tLoss: 0.033146\n",
            "Train Epoch: 29 [57600/60000 (96%)]\tLoss: 0.122354\n",
            "Train Epoch: 29 [58240/60000 (97%)]\tLoss: 0.082807\n",
            "Train Epoch: 29 [58880/60000 (98%)]\tLoss: 0.011392\n",
            "Train Epoch: 29 [59520/60000 (99%)]\tLoss: 0.000727\n",
            "\n",
            "Test set: Average loss: 0.0132, Accuracy: 9963/10000 (100%)\n",
            "\n",
            "Train Epoch: 30 [0/60000 (0%)]\tLoss: 0.006951\n",
            "Train Epoch: 30 [640/60000 (1%)]\tLoss: 0.081028\n",
            "Train Epoch: 30 [1280/60000 (2%)]\tLoss: 0.009692\n",
            "Train Epoch: 30 [1920/60000 (3%)]\tLoss: 0.002098\n",
            "Train Epoch: 30 [2560/60000 (4%)]\tLoss: 0.005513\n",
            "Train Epoch: 30 [3200/60000 (5%)]\tLoss: 0.083434\n",
            "Train Epoch: 30 [3840/60000 (6%)]\tLoss: 0.013345\n",
            "Train Epoch: 30 [4480/60000 (7%)]\tLoss: 0.056571\n",
            "Train Epoch: 30 [5120/60000 (9%)]\tLoss: 0.120294\n",
            "Train Epoch: 30 [5760/60000 (10%)]\tLoss: 0.006732\n",
            "Train Epoch: 30 [6400/60000 (11%)]\tLoss: 0.020032\n",
            "Train Epoch: 30 [7040/60000 (12%)]\tLoss: 0.002803\n",
            "Train Epoch: 30 [7680/60000 (13%)]\tLoss: 0.004821\n",
            "Train Epoch: 30 [8320/60000 (14%)]\tLoss: 0.107072\n",
            "Train Epoch: 30 [8960/60000 (15%)]\tLoss: 0.091427\n",
            "Train Epoch: 30 [9600/60000 (16%)]\tLoss: 0.027570\n",
            "Train Epoch: 30 [10240/60000 (17%)]\tLoss: 0.035597\n",
            "Train Epoch: 30 [10880/60000 (18%)]\tLoss: 0.153838\n",
            "Train Epoch: 30 [11520/60000 (19%)]\tLoss: 0.000514\n",
            "Train Epoch: 30 [12160/60000 (20%)]\tLoss: 0.006207\n",
            "Train Epoch: 30 [12800/60000 (21%)]\tLoss: 0.004667\n",
            "Train Epoch: 30 [13440/60000 (22%)]\tLoss: 0.005036\n",
            "Train Epoch: 30 [14080/60000 (23%)]\tLoss: 0.078295\n",
            "Train Epoch: 30 [14720/60000 (25%)]\tLoss: 0.027380\n",
            "Train Epoch: 30 [15360/60000 (26%)]\tLoss: 0.100145\n",
            "Train Epoch: 30 [16000/60000 (27%)]\tLoss: 0.131105\n",
            "Train Epoch: 30 [16640/60000 (28%)]\tLoss: 0.114474\n",
            "Train Epoch: 30 [17280/60000 (29%)]\tLoss: 0.034058\n",
            "Train Epoch: 30 [17920/60000 (30%)]\tLoss: 0.132990\n",
            "Train Epoch: 30 [18560/60000 (31%)]\tLoss: 0.012751\n",
            "Train Epoch: 30 [19200/60000 (32%)]\tLoss: 0.000936\n",
            "Train Epoch: 30 [19840/60000 (33%)]\tLoss: 0.151485\n",
            "Train Epoch: 30 [20480/60000 (34%)]\tLoss: 0.009781\n",
            "Train Epoch: 30 [21120/60000 (35%)]\tLoss: 0.067034\n",
            "Train Epoch: 30 [21760/60000 (36%)]\tLoss: 0.069628\n",
            "Train Epoch: 30 [22400/60000 (37%)]\tLoss: 0.051444\n",
            "Train Epoch: 30 [23040/60000 (38%)]\tLoss: 0.001075\n",
            "Train Epoch: 30 [23680/60000 (39%)]\tLoss: 0.003716\n",
            "Train Epoch: 30 [24320/60000 (41%)]\tLoss: 0.003177\n",
            "Train Epoch: 30 [24960/60000 (42%)]\tLoss: 0.005869\n",
            "Train Epoch: 30 [25600/60000 (43%)]\tLoss: 0.002652\n",
            "Train Epoch: 30 [26240/60000 (44%)]\tLoss: 0.002881\n",
            "Train Epoch: 30 [26880/60000 (45%)]\tLoss: 0.044090\n",
            "Train Epoch: 30 [27520/60000 (46%)]\tLoss: 0.302678\n",
            "Train Epoch: 30 [28160/60000 (47%)]\tLoss: 0.029640\n",
            "Train Epoch: 30 [28800/60000 (48%)]\tLoss: 0.005815\n",
            "Train Epoch: 30 [29440/60000 (49%)]\tLoss: 0.002491\n",
            "Train Epoch: 30 [30080/60000 (50%)]\tLoss: 0.001181\n",
            "Train Epoch: 30 [30720/60000 (51%)]\tLoss: 0.081213\n",
            "Train Epoch: 30 [31360/60000 (52%)]\tLoss: 0.006646\n",
            "Train Epoch: 30 [32000/60000 (53%)]\tLoss: 0.020387\n",
            "Train Epoch: 30 [32640/60000 (54%)]\tLoss: 0.017566\n",
            "Train Epoch: 30 [33280/60000 (55%)]\tLoss: 0.151342\n",
            "Train Epoch: 30 [33920/60000 (57%)]\tLoss: 0.011735\n",
            "Train Epoch: 30 [34560/60000 (58%)]\tLoss: 0.028042\n",
            "Train Epoch: 30 [35200/60000 (59%)]\tLoss: 0.022372\n",
            "Train Epoch: 30 [35840/60000 (60%)]\tLoss: 0.037756\n",
            "Train Epoch: 30 [36480/60000 (61%)]\tLoss: 0.007184\n",
            "Train Epoch: 30 [37120/60000 (62%)]\tLoss: 0.099084\n",
            "Train Epoch: 30 [37760/60000 (63%)]\tLoss: 0.029949\n",
            "Train Epoch: 30 [38400/60000 (64%)]\tLoss: 0.003632\n",
            "Train Epoch: 30 [39040/60000 (65%)]\tLoss: 0.033994\n",
            "Train Epoch: 30 [39680/60000 (66%)]\tLoss: 0.003496\n",
            "Train Epoch: 30 [40320/60000 (67%)]\tLoss: 0.015244\n",
            "Train Epoch: 30 [40960/60000 (68%)]\tLoss: 0.001932\n",
            "Train Epoch: 30 [41600/60000 (69%)]\tLoss: 0.000676\n",
            "Train Epoch: 30 [42240/60000 (70%)]\tLoss: 0.027045\n",
            "Train Epoch: 30 [42880/60000 (71%)]\tLoss: 0.070470\n",
            "Train Epoch: 30 [43520/60000 (72%)]\tLoss: 0.044579\n",
            "Train Epoch: 30 [44160/60000 (74%)]\tLoss: 0.000843\n",
            "Train Epoch: 30 [44800/60000 (75%)]\tLoss: 0.012462\n",
            "Train Epoch: 30 [45440/60000 (76%)]\tLoss: 0.094157\n",
            "Train Epoch: 30 [46080/60000 (77%)]\tLoss: 0.009242\n",
            "Train Epoch: 30 [46720/60000 (78%)]\tLoss: 0.002483\n",
            "Train Epoch: 30 [47360/60000 (79%)]\tLoss: 0.029405\n",
            "Train Epoch: 30 [48000/60000 (80%)]\tLoss: 0.012159\n",
            "Train Epoch: 30 [48640/60000 (81%)]\tLoss: 0.075361\n",
            "Train Epoch: 30 [49280/60000 (82%)]\tLoss: 0.001336\n",
            "Train Epoch: 30 [49920/60000 (83%)]\tLoss: 0.003209\n",
            "Train Epoch: 30 [50560/60000 (84%)]\tLoss: 0.073301\n",
            "Train Epoch: 30 [51200/60000 (85%)]\tLoss: 0.019950\n",
            "Train Epoch: 30 [51840/60000 (86%)]\tLoss: 0.004764\n",
            "Train Epoch: 30 [52480/60000 (87%)]\tLoss: 0.044741\n",
            "Train Epoch: 30 [53120/60000 (88%)]\tLoss: 0.064392\n",
            "Train Epoch: 30 [53760/60000 (90%)]\tLoss: 0.000672\n",
            "Train Epoch: 30 [54400/60000 (91%)]\tLoss: 0.001920\n",
            "Train Epoch: 30 [55040/60000 (92%)]\tLoss: 0.007710\n",
            "Train Epoch: 30 [55680/60000 (93%)]\tLoss: 0.001197\n",
            "Train Epoch: 30 [56320/60000 (94%)]\tLoss: 0.030312\n",
            "Train Epoch: 30 [56960/60000 (95%)]\tLoss: 0.000701\n",
            "Train Epoch: 30 [57600/60000 (96%)]\tLoss: 0.037704\n",
            "Train Epoch: 30 [58240/60000 (97%)]\tLoss: 0.040744\n",
            "Train Epoch: 30 [58880/60000 (98%)]\tLoss: 0.036653\n",
            "Train Epoch: 30 [59520/60000 (99%)]\tLoss: 0.007869\n",
            "\n",
            "Test set: Average loss: 0.0140, Accuracy: 9963/10000 (100%)\n",
            "\n",
            "Train Epoch: 31 [0/60000 (0%)]\tLoss: 0.000586\n",
            "Train Epoch: 31 [640/60000 (1%)]\tLoss: 0.062645\n",
            "Train Epoch: 31 [1280/60000 (2%)]\tLoss: 0.137105\n",
            "Train Epoch: 31 [1920/60000 (3%)]\tLoss: 0.008635\n",
            "Train Epoch: 31 [2560/60000 (4%)]\tLoss: 0.038444\n",
            "Train Epoch: 31 [3200/60000 (5%)]\tLoss: 0.003889\n",
            "Train Epoch: 31 [3840/60000 (6%)]\tLoss: 0.025262\n",
            "Train Epoch: 31 [4480/60000 (7%)]\tLoss: 0.001822\n",
            "Train Epoch: 31 [5120/60000 (9%)]\tLoss: 0.354699\n",
            "Train Epoch: 31 [5760/60000 (10%)]\tLoss: 0.034083\n",
            "Train Epoch: 31 [6400/60000 (11%)]\tLoss: 0.122585\n",
            "Train Epoch: 31 [7040/60000 (12%)]\tLoss: 0.002618\n",
            "Train Epoch: 31 [7680/60000 (13%)]\tLoss: 0.010046\n",
            "Train Epoch: 31 [8320/60000 (14%)]\tLoss: 0.040825\n",
            "Train Epoch: 31 [8960/60000 (15%)]\tLoss: 0.074285\n",
            "Train Epoch: 31 [9600/60000 (16%)]\tLoss: 0.038290\n",
            "Train Epoch: 31 [10240/60000 (17%)]\tLoss: 0.270277\n",
            "Train Epoch: 31 [10880/60000 (18%)]\tLoss: 0.059854\n",
            "Train Epoch: 31 [11520/60000 (19%)]\tLoss: 0.022016\n",
            "Train Epoch: 31 [12160/60000 (20%)]\tLoss: 0.006106\n",
            "Train Epoch: 31 [12800/60000 (21%)]\tLoss: 0.050033\n",
            "Train Epoch: 31 [13440/60000 (22%)]\tLoss: 0.004513\n",
            "Train Epoch: 31 [14080/60000 (23%)]\tLoss: 0.048841\n",
            "Train Epoch: 31 [14720/60000 (25%)]\tLoss: 0.016711\n",
            "Train Epoch: 31 [15360/60000 (26%)]\tLoss: 0.107384\n",
            "Train Epoch: 31 [16000/60000 (27%)]\tLoss: 0.000303\n",
            "Train Epoch: 31 [16640/60000 (28%)]\tLoss: 0.004810\n",
            "Train Epoch: 31 [17280/60000 (29%)]\tLoss: 0.002527\n",
            "Train Epoch: 31 [17920/60000 (30%)]\tLoss: 0.001943\n",
            "Train Epoch: 31 [18560/60000 (31%)]\tLoss: 0.017625\n",
            "Train Epoch: 31 [19200/60000 (32%)]\tLoss: 0.005563\n",
            "Train Epoch: 31 [19840/60000 (33%)]\tLoss: 0.029383\n",
            "Train Epoch: 31 [20480/60000 (34%)]\tLoss: 0.002756\n",
            "Train Epoch: 31 [21120/60000 (35%)]\tLoss: 0.002113\n",
            "Train Epoch: 31 [21760/60000 (36%)]\tLoss: 0.013323\n",
            "Train Epoch: 31 [22400/60000 (37%)]\tLoss: 0.016373\n",
            "Train Epoch: 31 [23040/60000 (38%)]\tLoss: 0.001323\n",
            "Train Epoch: 31 [23680/60000 (39%)]\tLoss: 0.005223\n",
            "Train Epoch: 31 [24320/60000 (41%)]\tLoss: 0.003359\n",
            "Train Epoch: 31 [24960/60000 (42%)]\tLoss: 0.005293\n",
            "Train Epoch: 31 [25600/60000 (43%)]\tLoss: 0.150909\n",
            "Train Epoch: 31 [26240/60000 (44%)]\tLoss: 0.004204\n",
            "Train Epoch: 31 [26880/60000 (45%)]\tLoss: 0.015150\n",
            "Train Epoch: 31 [27520/60000 (46%)]\tLoss: 0.020393\n",
            "Train Epoch: 31 [28160/60000 (47%)]\tLoss: 0.012760\n",
            "Train Epoch: 31 [28800/60000 (48%)]\tLoss: 0.009588\n",
            "Train Epoch: 31 [29440/60000 (49%)]\tLoss: 0.030801\n",
            "Train Epoch: 31 [30080/60000 (50%)]\tLoss: 0.001576\n",
            "Train Epoch: 31 [30720/60000 (51%)]\tLoss: 0.001551\n",
            "Train Epoch: 31 [31360/60000 (52%)]\tLoss: 0.002187\n",
            "Train Epoch: 31 [32000/60000 (53%)]\tLoss: 0.103695\n",
            "Train Epoch: 31 [32640/60000 (54%)]\tLoss: 0.002814\n",
            "Train Epoch: 31 [33280/60000 (55%)]\tLoss: 0.005383\n",
            "Train Epoch: 31 [33920/60000 (57%)]\tLoss: 0.133737\n",
            "Train Epoch: 31 [34560/60000 (58%)]\tLoss: 0.389619\n",
            "Train Epoch: 31 [35200/60000 (59%)]\tLoss: 0.000992\n",
            "Train Epoch: 31 [35840/60000 (60%)]\tLoss: 0.092920\n",
            "Train Epoch: 31 [36480/60000 (61%)]\tLoss: 0.001759\n",
            "Train Epoch: 31 [37120/60000 (62%)]\tLoss: 0.136079\n",
            "Train Epoch: 31 [37760/60000 (63%)]\tLoss: 0.008450\n",
            "Train Epoch: 31 [38400/60000 (64%)]\tLoss: 0.042383\n",
            "Train Epoch: 31 [39040/60000 (65%)]\tLoss: 0.104139\n",
            "Train Epoch: 31 [39680/60000 (66%)]\tLoss: 0.012926\n",
            "Train Epoch: 31 [40320/60000 (67%)]\tLoss: 0.117090\n",
            "Train Epoch: 31 [40960/60000 (68%)]\tLoss: 0.006378\n",
            "Train Epoch: 31 [41600/60000 (69%)]\tLoss: 0.031459\n",
            "Train Epoch: 31 [42240/60000 (70%)]\tLoss: 0.000854\n",
            "Train Epoch: 31 [42880/60000 (71%)]\tLoss: 0.007907\n",
            "Train Epoch: 31 [43520/60000 (72%)]\tLoss: 0.012210\n",
            "Train Epoch: 31 [44160/60000 (74%)]\tLoss: 0.003424\n",
            "Train Epoch: 31 [44800/60000 (75%)]\tLoss: 0.000490\n",
            "Train Epoch: 31 [45440/60000 (76%)]\tLoss: 0.015698\n",
            "Train Epoch: 31 [46080/60000 (77%)]\tLoss: 0.168351\n",
            "Train Epoch: 31 [46720/60000 (78%)]\tLoss: 0.047982\n",
            "Train Epoch: 31 [47360/60000 (79%)]\tLoss: 0.001197\n",
            "Train Epoch: 31 [48000/60000 (80%)]\tLoss: 0.006177\n",
            "Train Epoch: 31 [48640/60000 (81%)]\tLoss: 0.109772\n",
            "Train Epoch: 31 [49280/60000 (82%)]\tLoss: 0.001421\n",
            "Train Epoch: 31 [49920/60000 (83%)]\tLoss: 0.002682\n",
            "Train Epoch: 31 [50560/60000 (84%)]\tLoss: 0.067271\n",
            "Train Epoch: 31 [51200/60000 (85%)]\tLoss: 0.055084\n",
            "Train Epoch: 31 [51840/60000 (86%)]\tLoss: 0.011681\n",
            "Train Epoch: 31 [52480/60000 (87%)]\tLoss: 0.046460\n",
            "Train Epoch: 31 [53120/60000 (88%)]\tLoss: 0.194824\n",
            "Train Epoch: 31 [53760/60000 (90%)]\tLoss: 0.053440\n",
            "Train Epoch: 31 [54400/60000 (91%)]\tLoss: 0.007397\n",
            "Train Epoch: 31 [55040/60000 (92%)]\tLoss: 0.011042\n",
            "Train Epoch: 31 [55680/60000 (93%)]\tLoss: 0.001413\n",
            "Train Epoch: 31 [56320/60000 (94%)]\tLoss: 0.030878\n",
            "Train Epoch: 31 [56960/60000 (95%)]\tLoss: 0.015226\n",
            "Train Epoch: 31 [57600/60000 (96%)]\tLoss: 0.001900\n",
            "Train Epoch: 31 [58240/60000 (97%)]\tLoss: 0.032937\n",
            "Train Epoch: 31 [58880/60000 (98%)]\tLoss: 0.003113\n",
            "Train Epoch: 31 [59520/60000 (99%)]\tLoss: 0.000821\n",
            "\n",
            "Test set: Average loss: 0.0140, Accuracy: 9964/10000 (100%)\n",
            "\n",
            "Train Epoch: 32 [0/60000 (0%)]\tLoss: 0.001669\n",
            "Train Epoch: 32 [640/60000 (1%)]\tLoss: 0.006411\n",
            "Train Epoch: 32 [1280/60000 (2%)]\tLoss: 0.003694\n",
            "Train Epoch: 32 [1920/60000 (3%)]\tLoss: 0.003542\n",
            "Train Epoch: 32 [2560/60000 (4%)]\tLoss: 0.012124\n",
            "Train Epoch: 32 [3200/60000 (5%)]\tLoss: 0.095851\n",
            "Train Epoch: 32 [3840/60000 (6%)]\tLoss: 0.001235\n",
            "Train Epoch: 32 [4480/60000 (7%)]\tLoss: 0.000813\n",
            "Train Epoch: 32 [5120/60000 (9%)]\tLoss: 0.000421\n",
            "Train Epoch: 32 [5760/60000 (10%)]\tLoss: 0.033198\n",
            "Train Epoch: 32 [6400/60000 (11%)]\tLoss: 0.006493\n",
            "Train Epoch: 32 [7040/60000 (12%)]\tLoss: 0.000467\n",
            "Train Epoch: 32 [7680/60000 (13%)]\tLoss: 0.022377\n",
            "Train Epoch: 32 [8320/60000 (14%)]\tLoss: 0.000404\n",
            "Train Epoch: 32 [8960/60000 (15%)]\tLoss: 0.018533\n",
            "Train Epoch: 32 [9600/60000 (16%)]\tLoss: 0.001993\n",
            "Train Epoch: 32 [10240/60000 (17%)]\tLoss: 0.073058\n",
            "Train Epoch: 32 [10880/60000 (18%)]\tLoss: 0.053010\n",
            "Train Epoch: 32 [11520/60000 (19%)]\tLoss: 0.004189\n",
            "Train Epoch: 32 [12160/60000 (20%)]\tLoss: 0.039083\n",
            "Train Epoch: 32 [12800/60000 (21%)]\tLoss: 0.035027\n",
            "Train Epoch: 32 [13440/60000 (22%)]\tLoss: 0.001331\n",
            "Train Epoch: 32 [14080/60000 (23%)]\tLoss: 0.004553\n",
            "Train Epoch: 32 [14720/60000 (25%)]\tLoss: 0.055983\n",
            "Train Epoch: 32 [15360/60000 (26%)]\tLoss: 0.053019\n",
            "Train Epoch: 32 [16000/60000 (27%)]\tLoss: 0.003640\n",
            "Train Epoch: 32 [16640/60000 (28%)]\tLoss: 0.003965\n",
            "Train Epoch: 32 [17280/60000 (29%)]\tLoss: 0.003752\n",
            "Train Epoch: 32 [17920/60000 (30%)]\tLoss: 0.034013\n",
            "Train Epoch: 32 [18560/60000 (31%)]\tLoss: 0.043178\n",
            "Train Epoch: 32 [19200/60000 (32%)]\tLoss: 0.000340\n",
            "Train Epoch: 32 [19840/60000 (33%)]\tLoss: 0.027197\n",
            "Train Epoch: 32 [20480/60000 (34%)]\tLoss: 0.006394\n",
            "Train Epoch: 32 [21120/60000 (35%)]\tLoss: 0.015717\n",
            "Train Epoch: 32 [21760/60000 (36%)]\tLoss: 0.206215\n",
            "Train Epoch: 32 [22400/60000 (37%)]\tLoss: 0.004052\n",
            "Train Epoch: 32 [23040/60000 (38%)]\tLoss: 0.005198\n",
            "Train Epoch: 32 [23680/60000 (39%)]\tLoss: 0.007968\n",
            "Train Epoch: 32 [24320/60000 (41%)]\tLoss: 0.065527\n",
            "Train Epoch: 32 [24960/60000 (42%)]\tLoss: 0.006995\n",
            "Train Epoch: 32 [25600/60000 (43%)]\tLoss: 0.041055\n",
            "Train Epoch: 32 [26240/60000 (44%)]\tLoss: 0.006496\n",
            "Train Epoch: 32 [26880/60000 (45%)]\tLoss: 0.001683\n",
            "Train Epoch: 32 [27520/60000 (46%)]\tLoss: 0.089501\n",
            "Train Epoch: 32 [28160/60000 (47%)]\tLoss: 0.019793\n",
            "Train Epoch: 32 [28800/60000 (48%)]\tLoss: 0.014839\n",
            "Train Epoch: 32 [29440/60000 (49%)]\tLoss: 0.042270\n",
            "Train Epoch: 32 [30080/60000 (50%)]\tLoss: 0.001715\n",
            "Train Epoch: 32 [30720/60000 (51%)]\tLoss: 0.003867\n",
            "Train Epoch: 32 [31360/60000 (52%)]\tLoss: 0.278530\n",
            "Train Epoch: 32 [32000/60000 (53%)]\tLoss: 0.000765\n",
            "Train Epoch: 32 [32640/60000 (54%)]\tLoss: 0.026410\n",
            "Train Epoch: 32 [33280/60000 (55%)]\tLoss: 0.010741\n",
            "Train Epoch: 32 [33920/60000 (57%)]\tLoss: 0.003598\n",
            "Train Epoch: 32 [34560/60000 (58%)]\tLoss: 0.002980\n",
            "Train Epoch: 32 [35200/60000 (59%)]\tLoss: 0.029652\n",
            "Train Epoch: 32 [35840/60000 (60%)]\tLoss: 0.006885\n",
            "Train Epoch: 32 [36480/60000 (61%)]\tLoss: 0.030695\n",
            "Train Epoch: 32 [37120/60000 (62%)]\tLoss: 0.009511\n",
            "Train Epoch: 32 [37760/60000 (63%)]\tLoss: 0.005225\n",
            "Train Epoch: 32 [38400/60000 (64%)]\tLoss: 0.000252\n",
            "Train Epoch: 32 [39040/60000 (65%)]\tLoss: 0.005594\n",
            "Train Epoch: 32 [39680/60000 (66%)]\tLoss: 0.037157\n",
            "Train Epoch: 32 [40320/60000 (67%)]\tLoss: 0.006668\n",
            "Train Epoch: 32 [40960/60000 (68%)]\tLoss: 0.025435\n",
            "Train Epoch: 32 [41600/60000 (69%)]\tLoss: 0.013129\n",
            "Train Epoch: 32 [42240/60000 (70%)]\tLoss: 0.165123\n",
            "Train Epoch: 32 [42880/60000 (71%)]\tLoss: 0.014531\n",
            "Train Epoch: 32 [43520/60000 (72%)]\tLoss: 0.025421\n",
            "Train Epoch: 32 [44160/60000 (74%)]\tLoss: 0.004697\n",
            "Train Epoch: 32 [44800/60000 (75%)]\tLoss: 0.003563\n",
            "Train Epoch: 32 [45440/60000 (76%)]\tLoss: 0.009635\n",
            "Train Epoch: 32 [46080/60000 (77%)]\tLoss: 0.006569\n",
            "Train Epoch: 32 [46720/60000 (78%)]\tLoss: 0.085208\n",
            "Train Epoch: 32 [47360/60000 (79%)]\tLoss: 0.029951\n",
            "Train Epoch: 32 [48000/60000 (80%)]\tLoss: 0.004081\n",
            "Train Epoch: 32 [48640/60000 (81%)]\tLoss: 0.024382\n",
            "Train Epoch: 32 [49280/60000 (82%)]\tLoss: 0.011834\n",
            "Train Epoch: 32 [49920/60000 (83%)]\tLoss: 0.128728\n",
            "Train Epoch: 32 [50560/60000 (84%)]\tLoss: 0.027910\n",
            "Train Epoch: 32 [51200/60000 (85%)]\tLoss: 0.021330\n",
            "Train Epoch: 32 [51840/60000 (86%)]\tLoss: 0.046536\n",
            "Train Epoch: 32 [52480/60000 (87%)]\tLoss: 0.002944\n",
            "Train Epoch: 32 [53120/60000 (88%)]\tLoss: 0.015367\n",
            "Train Epoch: 32 [53760/60000 (90%)]\tLoss: 0.027955\n",
            "Train Epoch: 32 [54400/60000 (91%)]\tLoss: 0.008644\n",
            "Train Epoch: 32 [55040/60000 (92%)]\tLoss: 0.000557\n",
            "Train Epoch: 32 [55680/60000 (93%)]\tLoss: 0.039684\n",
            "Train Epoch: 32 [56320/60000 (94%)]\tLoss: 0.008034\n",
            "Train Epoch: 32 [56960/60000 (95%)]\tLoss: 0.002660\n",
            "Train Epoch: 32 [57600/60000 (96%)]\tLoss: 0.022101\n",
            "Train Epoch: 32 [58240/60000 (97%)]\tLoss: 0.020950\n",
            "Train Epoch: 32 [58880/60000 (98%)]\tLoss: 0.000683\n",
            "Train Epoch: 32 [59520/60000 (99%)]\tLoss: 0.020313\n",
            "\n",
            "Test set: Average loss: 0.0137, Accuracy: 9966/10000 (100%)\n",
            "\n",
            "\n",
            "Early stopping triggered after 32 epochs. No improvement in test loss for 10 consecutive epochs.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'MNIST_Model'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-cc308632fd7d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-1-cc308632fd7d>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0;31m# Compress the folder into a zip file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m     \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MNIST_Model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'zip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'MNIST_Model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;31m# Download the zip file in Google Colab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/shutil.py\u001b[0m in \u001b[0;36mmake_archive\u001b[0;34m(base_name, format, root_dir, base_dir, verbose, dry_run, owner, group, logger)\u001b[0m\n\u001b[1;32m   1146\u001b[0m     \u001b[0msave_cwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mroot_dir\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1148\u001b[0;31m         \u001b[0mstmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mst_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mS_ISDIR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mNotADirectoryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mENOTDIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Not a directory'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'MNIST_Model'"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}